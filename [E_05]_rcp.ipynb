{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcb76486",
   "metadata": {},
   "source": [
    "# 가위바위보\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0b0a667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "1.21.4\n"
     ]
    }
   ],
   "source": [
    "# 사용할 라이브러리 버전확인\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "911292b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 준비\n",
    "# 클래스 분류된 사진 찍기\n",
    "# https://teachablemachine.withgoogle.com/\n",
    "\n",
    "# 디렉토리 만들기 \n",
    "#(-p 옵션을 주어 생성하게되면 자동으로 중간단계의 디렉토리를 생성하면서 그 하위 디렉토리를 생성)\n",
    "# $ mkdir -p ~/aiffel/rock_scissor_paper/scissor\n",
    "# $ mkdir -p ~/aiffel/rock_scissor_paper/rock\n",
    "# $ mkdir -p ~/aiffel/rock_scissor_paper/paper\n",
    "\n",
    "# $ ls -l ~/aiffel/rock_scissor_paper\n",
    "\n",
    "#클라우드 이미지 압축해제\n",
    "#(찍은 사진이 압축파일(zip)로 저장되어있다)\n",
    "# # 원하는 디렉토리로 이동 =3\n",
    "# $ cd  ~/aiffel/rock_scissor_paper/rock\n",
    "\n",
    "# # 압축 해제 명령어 : unzip <파일명>.zip\n",
    "# $ unzip rock.zip\n",
    "\n",
    "# # 가위, 보에 대해서도 똑같이 실행!\n",
    "# $ cd  ~/aiffel/rock_scissor_paper/scissor\n",
    "# $ unzip scissor.zip\n",
    "\n",
    "# $ cd  ~/aiffel/rock_scissor_paper/paper\n",
    "# $ unzip paper.zip\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb74c0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "#받은 이미지의 크기가 \"224X224\"\n",
    "# \"28X28\" 로 만들어야함 손글씨의 경우 이미지 2828이었기때문에\n",
    "\n",
    "#라이브러리 불러오기 PIL\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd7cffbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "#이미지 사이즈 변환\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcf12d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위와 보도 이미지 사이즈변경 28X28으로\n",
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51af8afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지 사이즈 변경 28X28으로\n",
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00eab456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# load_data() 함수로 임의의 사진 데이터 읽어오기\n",
    "# 3개의 클리스 가위 :0 ,바위:1, 보:2로 라벨링\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c52feb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#이미지 불러보기\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdddaa59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#딥러닝 네트워크 설계하기\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "#input_shape 입력값 RGB (28, 28, 3) \n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "#가위 바위 보 3가지로 최종 분기\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83a9617a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 34s 20ms/step - loss: 22.0469 - accuracy: 0.3300\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 3.2299 - accuracy: 0.3733\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.7464 - accuracy: 0.4400\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.3212 - accuracy: 0.5033\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7859 - accuracy: 0.6700\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6621 - accuracy: 0.7067\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6660 - accuracy: 0.7467\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5794 - accuracy: 0.7767\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5633 - accuracy: 0.7833\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6290 - accuracy: 0.7233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f066688a280>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 딥러닝 네트워크 학습시키기\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b949d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "보 이미지 resize 완료!\n",
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "#Test 이미지로 Test하기\n",
    "#Test 이미지 data 준비\n",
    "\n",
    "# 224X224 data 28X28 사이즈 이미지로로 만들기\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b667e686",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 4.0821 - accuracy: 0.3400\n",
      "test_loss: 4.0820794105529785 \n",
      "test_accuracy: 0.3400000035762787\n"
     ]
    }
   ],
   "source": [
    "#test_accuracy 측정\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52cdb0f",
   "metadata": {},
   "source": [
    "# 더 좋은 네트워크 만들기\n",
    "\n",
    "- 하이퍼 파라미터 변경하여 딥러닝 네트워크 설계\n",
    "- 층의 깊이와 epoch 수변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a59e3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 35,875\n",
      "Trainable params: 35,875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#더 좋은 네트워크 만들기\n",
    "\n",
    "\n",
    "#하이퍼 파라미터 변경하여 딥러닝 네트워크 설계\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "#input_shape 입력값 RGB (28, 28, 3) \n",
    "# 더다양한 입력 이미지의 특징을 살펴봄 16에서 32로 변경\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "#가위 바위 보 3가지로 최종 분기\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02c44d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 총 파라미터 35,875개 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8c04155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 1s 12ms/step - loss: 27.2133 - accuracy: 0.2767\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 8.0641 - accuracy: 0.3567\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 3.3863 - accuracy: 0.4300\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.3932 - accuracy: 0.4433\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9073 - accuracy: 0.6167\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7301 - accuracy: 0.6767\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7233\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.8133\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5458 - accuracy: 0.7433\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f05a5e1fd30>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 하기\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f98385dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 4.3170 - accuracy: 0.3433\n",
      "test_loss: 4.317043781280518 \n",
      "test_accuracy: 0.34333333373069763\n"
     ]
    }
   ],
   "source": [
    "#test_accuracy 측정\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "058a4dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                12832     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 15,699\n",
      "Trainable params: 15,699\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 22.4227 - accuracy: 0.2933\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.1866 - accuracy: 0.3033\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.7767 - accuracy: 0.3167\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.5068 - accuracy: 0.4167\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0935 - accuracy: 0.4233\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9023 - accuracy: 0.5700\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8037 - accuracy: 0.6233\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6789 - accuracy: 0.6667\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7087 - accuracy: 0.7133\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.7467\n",
      "10/10 - 0s - loss: 2.8173 - accuracy: 0.5567\n",
      "test_loss: 2.817342758178711 \n",
      "test_accuracy: 0.5566666722297668\n"
     ]
    }
   ],
   "source": [
    "#더 좋은 네트워크 만들기\n",
    "\n",
    "\n",
    "#하이퍼 파라미터 변경하여 딥러닝 네트워크 설계 (16, 16)으로 변경\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "#input_shape 입력값 RGB (28, 28, 3) \n",
    "# 더다양한 입력 이미지의 특징을 살펴봄 16에서 32로 변경\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "#가위 바위 보 3가지로 최종 분기\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 학습\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "#test_accuracy 측정\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd381db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 39.5994 - accuracy: 0.3233\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 23.0480 - accuracy: 0.3567\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 8.4447 - accuracy: 0.4233\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.6529 - accuracy: 0.4100\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.2614 - accuracy: 0.5067\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7177 - accuracy: 0.7233\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6763 - accuracy: 0.7400\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5617 - accuracy: 0.7900\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.8267\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3656 - accuracy: 0.8600\n",
      "10/10 - 0s - loss: 5.4229 - accuracy: 0.4100\n",
      "test_loss: 5.422941207885742 \n",
      "test_accuracy: 0.4099999964237213\n"
     ]
    }
   ],
   "source": [
    "#  0.55 accuracy를 보인 원래의 하이퍼파라미터(16.32) 에서 epoch 수 조정\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "#input_shape 입력값 RGB (28, 28, 3) \n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "#가위 바위 보 3가지로 최종 분기\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 학습\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "#test_accuracy 측정\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "937857f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 35.0637 - accuracy: 0.3633\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 11.7079 - accuracy: 0.3300\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.9179 - accuracy: 0.3433\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 3.4900 - accuracy: 0.3467\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.9291 - accuracy: 0.3933\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.3462 - accuracy: 0.4600\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.4000 - accuracy: 0.5367\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9125 - accuracy: 0.6567\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8107 - accuracy: 0.6667\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7467\n",
      "10/10 - 0s - loss: 4.8487 - accuracy: 0.3867\n",
      "test_loss: 4.848706245422363 \n",
      "test_accuracy: 0.3866666555404663\n"
     ]
    }
   ],
   "source": [
    "# 16, 32, 32 (Conv2D, Conv2D, Dense) 변경\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "#input_shape 입력값 RGB (28, 28, 3) \n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "#가위 바위 보 3가지로 최종 분기\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 학습\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "#test_accuracy 측정\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce51f1d",
   "metadata": {},
   "source": [
    "### 층의 깊이를 조절하는 것만으로는 accuracy를 높이는데 한계가 있어 보인다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9808318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 20, 20, 16)        3904      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 10, 10, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 6, 6, 32)          12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                9248      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 26,083\n",
      "Trainable params: 26,083\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 1s 14ms/step - loss: 13.2986 - accuracy: 0.3600\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.0344 - accuracy: 0.3400\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.2758 - accuracy: 0.4267\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0491 - accuracy: 0.4167\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9082 - accuracy: 0.5467\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7401 - accuracy: 0.7067\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.7600\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7733\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.8067\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3884 - accuracy: 0.8533\n",
      "10/10 - 0s - loss: 2.5433 - accuracy: 0.3367\n",
      "test_loss: 2.543308973312378 \n",
      "test_accuracy: 0.33666667342185974\n"
     ]
    }
   ],
   "source": [
    "# 커널 크기 변경 9X9\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (9,9), activation='relu', input_shape=(28,28,3)))\n",
    "#input_shape 입력값 RGB (28, 28, 3) \n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (5,5), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "#가위 바위 보 3가지로 최종 분기\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 학습\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "#test_accuracy 측정\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a876b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 24, 24, 16)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 8, 8, 32)          12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                8208      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 22,307\n",
      "Trainable params: 22,307\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 12.1583 - accuracy: 0.3000\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.9940 - accuracy: 0.3067\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.9559 - accuracy: 0.3433\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.5160 - accuracy: 0.3333\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.3126 - accuracy: 0.4067\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1312 - accuracy: 0.4433\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0803 - accuracy: 0.4800\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0315 - accuracy: 0.5333\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8595 - accuracy: 0.6100\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8128 - accuracy: 0.5967\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6836 - accuracy: 0.6800\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7319 - accuracy: 0.6967\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7748 - accuracy: 0.6733\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6165 - accuracy: 0.7633\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.7833\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.8267\n",
      "Epoch 17/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.8433\n",
      "Epoch 18/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.8600\n",
      "Epoch 19/30\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.8233\n",
      "Epoch 20/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4043 - accuracy: 0.8567\n",
      "Epoch 21/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3616 - accuracy: 0.8967\n",
      "Epoch 22/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3660 - accuracy: 0.8933\n",
      "Epoch 23/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3312 - accuracy: 0.8933\n",
      "Epoch 24/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3099 - accuracy: 0.9100\n",
      "Epoch 25/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2989 - accuracy: 0.9200\n",
      "Epoch 26/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2798 - accuracy: 0.9200\n",
      "Epoch 27/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2774 - accuracy: 0.9133\n",
      "Epoch 28/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2755 - accuracy: 0.9067\n",
      "Epoch 29/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2764 - accuracy: 0.9167\n",
      "Epoch 30/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3005 - accuracy: 0.8933\n",
      "10/10 - 0s - loss: 2.4862 - accuracy: 0.5033\n",
      "test_loss: 2.486182928085327 \n",
      "test_accuracy: 0.503333330154419\n"
     ]
    }
   ],
   "source": [
    "# 커널 크기 변경  5X5\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (5,5), activation='relu', input_shape=(28,28,3)))\n",
    "\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (5,5), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 학습\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=30)\n",
    "\n",
    "#test_accuracy 측정\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86c17477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 22, 22, 16)        2368      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 11, 11, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 9, 9, 32)          4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                8208      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 15,267\n",
      "Trainable params: 15,267\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 8.5531 - accuracy: 0.3767\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.5056 - accuracy: 0.4100\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0289 - accuracy: 0.4867\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8740 - accuracy: 0.5733\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8000 - accuracy: 0.6033\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7064 - accuracy: 0.7267\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7008 - accuracy: 0.6767\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6092 - accuracy: 0.7467\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.7233\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6047 - accuracy: 0.7300\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5595 - accuracy: 0.7667\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.7933\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7767\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.8300\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3856 - accuracy: 0.8567\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3222 - accuracy: 0.8567\n",
      "Epoch 17/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2762 - accuracy: 0.9100\n",
      "Epoch 18/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2800 - accuracy: 0.9000\n",
      "Epoch 19/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2377 - accuracy: 0.9300\n",
      "Epoch 20/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2029 - accuracy: 0.9433\n",
      "Epoch 21/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1697 - accuracy: 0.9400\n",
      "Epoch 22/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1323 - accuracy: 0.9800\n",
      "Epoch 23/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1268 - accuracy: 0.9867\n",
      "Epoch 24/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1009 - accuracy: 0.9733\n",
      "Epoch 25/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0852 - accuracy: 0.9900\n",
      "Epoch 26/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0821 - accuracy: 0.9900\n",
      "Epoch 27/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0705 - accuracy: 0.9933\n",
      "Epoch 28/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0763 - accuracy: 0.9833\n",
      "Epoch 29/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0452 - accuracy: 1.0000\n",
      "10/10 - 0s - loss: 10.9985 - accuracy: 0.4767\n",
      "test_loss: 10.998479843139648 \n",
      "test_accuracy: 0.476666659116745\n"
     ]
    }
   ],
   "source": [
    "# 커널 크기변경 7X7\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (7,7), activation='relu', input_shape=(28,28,3)))\n",
    "\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 학습\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=30)\n",
    "\n",
    "#test_accuracy 측정\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492a4767",
   "metadata": {},
   "source": [
    "###  kernel의 크기 증가\n",
    "- kernel의 크기가(3X3) 너무 작아 유의미한 feature를 잡아내지 못할 수 있음\n",
    "- (5X5)...(9X9)까지 늘려 시험해 보았으나 테스트 정확도에서 유의미한 차이는 보이지 않았다\n",
    "\n",
    "### 학습 Epoch 횟수를 늘려 학습\n",
    "- 일정 횟수(위에서는30)를 넘어가면 학습데이터에 과적합(over-fitted)되어 오히려 test 데이터에 대하여 accracy가 떨어지는 경향을 나타내는 것으로 보임.\n",
    "- 학습 자료의 양 자체가 작고, \n",
    "- 뽑아낼 유의미한 feature의 수가 적은 것으로 판단\n",
    "\n",
    "### kernel의 크기와 Epoch 수를 조절 하여 결과를 확인해 보았으나, 크게 accuracy의 변화는 보이지 않았다.\n",
    "\n",
    "### 제공된 이미지 원본 데이터를 확인\n",
    "- 데이터 자체가 육안으로 보았을 때도 굉장히 불분명하고 질(해상도)이 좋지 않음\n",
    "- 직접 사진을 찍은 가위, 바위 보 손모양 사진을 가지고 진행시도(가위,바위,보 각각 700장씩 2100장)\n",
    "- 기존의 제공된 데이터셋의 수(300)가 적어서 다양한 feature뽑아 내고, 효과적으로 구분할 수 있는 학습이 되지 않았을 것 같은 점도 고려\n",
    "- 데이터셋의 사진 수를 7배 늘려 학습을 진행.\n",
    "- 데이터의 over-fitting 을 극복하기 위해 다양한 모양과 위치의 손 사진과 7명의 각기다른 사람의 손 사진을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "367f8523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700  images to be resized.\n",
      "700  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "700  images to be resized.\n",
      "700  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "700  images to be resized.\n",
      "700  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 직접 찍은 데이터 불러오기\n",
    "\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# 28X28 사이즈로 변환\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/N_data/scissors\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/N_data/rock\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/N_data/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67ff9b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 2100 입니다.\n",
      "x_train shape: (2100, 28, 28, 3)\n",
      "y_train shape: (2100,)\n"
     ]
    }
   ],
   "source": [
    "# 각 가위, 바위, 보 에 0,1,2 label을 붙여 load_data로 불러오기\n",
    "\n",
    "def load_data(img_path, number_of_data=2100):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissors/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/N_data\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dddbff8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 이미지 확인\n",
    "\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0cfefa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "66/66 [==============================] - 1s 4ms/step - loss: 5.7187 - accuracy: 0.3471\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.5089 - accuracy: 0.4271\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.2366 - accuracy: 0.4881\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.2535 - accuracy: 0.4900\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.9682 - accuracy: 0.5771\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.8868 - accuracy: 0.6005\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.8096 - accuracy: 0.6338\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.8327 - accuracy: 0.6271\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.7418 - accuracy: 0.6776\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.6995 - accuracy: 0.6876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f05a44ad190>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모델 설계및 학습\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f4cd62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 22, 22, 16)        2368      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 11, 11, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 5, 5, 32)          25120     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 31,715\n",
      "Trainable params: 31,715\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "66/66 [==============================] - 1s 4ms/step - loss: 2.8324 - accuracy: 0.3181\n",
      "Epoch 2/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.1387 - accuracy: 0.3348\n",
      "Epoch 3/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.1043 - accuracy: 0.3890\n",
      "Epoch 4/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0815 - accuracy: 0.4071\n",
      "Epoch 5/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0589 - accuracy: 0.4390\n",
      "Epoch 6/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0222 - accuracy: 0.4890\n",
      "Epoch 7/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.9810 - accuracy: 0.5152\n",
      "Epoch 8/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.9511 - accuracy: 0.5619\n",
      "Epoch 9/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.9203 - accuracy: 0.5714\n",
      "Epoch 10/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.8861 - accuracy: 0.5910\n",
      "Epoch 11/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.8601 - accuracy: 0.6071\n",
      "Epoch 12/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.8283 - accuracy: 0.6276\n",
      "Epoch 13/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.8560 - accuracy: 0.5995\n",
      "Epoch 14/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.7953 - accuracy: 0.6348\n",
      "Epoch 15/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.7645 - accuracy: 0.6581\n",
      "Epoch 16/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.7485 - accuracy: 0.6762\n",
      "Epoch 17/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.7082 - accuracy: 0.6886\n",
      "Epoch 18/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.7228 - accuracy: 0.6900\n",
      "Epoch 19/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.7148 - accuracy: 0.6852\n",
      "Epoch 20/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.6726 - accuracy: 0.7133\n",
      "Epoch 21/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.6719 - accuracy: 0.7067\n",
      "Epoch 22/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.6254 - accuracy: 0.7438\n",
      "Epoch 23/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.6619 - accuracy: 0.7129\n",
      "Epoch 24/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.5881 - accuracy: 0.7571\n",
      "Epoch 25/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.6755 - accuracy: 0.7205\n",
      "Epoch 26/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.6391 - accuracy: 0.7276\n",
      "Epoch 27/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.5896 - accuracy: 0.7500\n",
      "Epoch 28/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.7610\n",
      "Epoch 29/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.5585 - accuracy: 0.7771\n",
      "Epoch 30/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4905 - accuracy: 0.7995\n",
      "Epoch 31/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.5225 - accuracy: 0.7819\n",
      "Epoch 32/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4951 - accuracy: 0.8086\n",
      "Epoch 33/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7943\n",
      "Epoch 34/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.8095\n",
      "Epoch 35/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.8357\n",
      "Epoch 36/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7843\n",
      "Epoch 37/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.8414\n",
      "Epoch 38/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.8300\n",
      "Epoch 39/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.8381\n",
      "Epoch 40/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3814 - accuracy: 0.8552\n",
      "Epoch 41/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3910 - accuracy: 0.8505\n",
      "Epoch 42/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3945 - accuracy: 0.8533\n",
      "Epoch 43/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4032 - accuracy: 0.8357\n",
      "Epoch 44/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3964 - accuracy: 0.8443\n",
      "Epoch 45/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.8324\n",
      "Epoch 46/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3657 - accuracy: 0.8557\n",
      "Epoch 47/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3727 - accuracy: 0.8576\n",
      "Epoch 48/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3293 - accuracy: 0.8729\n",
      "Epoch 49/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3168 - accuracy: 0.8810\n",
      "Epoch 50/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3404 - accuracy: 0.8710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f05a5e2bc10>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 accuracy 가 0.6876 매우 떨어져 학습 하이퍼 파리미터 조정\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (7,7), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (7,7), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "992d95b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 5.2647 - accuracy: 0.3767\n",
      "test_loss: 5.264707088470459 \n",
      "test_accuracy: 0.3766666650772095\n"
     ]
    }
   ],
   "source": [
    "# 학습 accuracy 0.87\n",
    "# kernel 7X7로 설정 \n",
    "# 이미지크기 28X28 에서 손모양이 차지하는 공간이 약 10X10 내부에 들어 가는 것으로 보임\n",
    "# 하위 epoch 에서 accuracy가  steady-state에 도달 되는 것으로 보아 50이면 충분\n",
    "# 뽑아낼 feature 수와 분류 알고리즘 복잡도 조정\n",
    "# 위 모델으로 test에 test_accuracy 확인\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")\n",
    "\n",
    "# accuracy 0.37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68d29652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 22, 22, 32)        4736      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 5, 5, 32)          50208     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 57,059\n",
      "Trainable params: 57,059\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "66/66 [==============================] - 1s 4ms/step - loss: 5.3713 - accuracy: 0.3376\n",
      "Epoch 2/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.1052 - accuracy: 0.3471\n",
      "Epoch 3/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0825 - accuracy: 0.3700\n",
      "Epoch 4/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0690 - accuracy: 0.4062\n",
      "Epoch 5/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0514 - accuracy: 0.4162\n",
      "Epoch 6/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0296 - accuracy: 0.4514\n",
      "Epoch 7/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0260 - accuracy: 0.4319\n",
      "Epoch 8/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0148 - accuracy: 0.4448\n",
      "Epoch 9/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.9706 - accuracy: 0.4662\n",
      "Epoch 10/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.9661 - accuracy: 0.4729\n",
      "Epoch 11/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.9512 - accuracy: 0.4724\n",
      "Epoch 12/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.9187 - accuracy: 0.4862\n",
      "Epoch 13/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.9263 - accuracy: 0.4919\n",
      "Epoch 14/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.9016 - accuracy: 0.5181\n",
      "Epoch 15/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.8973 - accuracy: 0.5214\n",
      "Epoch 16/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.8593 - accuracy: 0.5495\n",
      "Epoch 17/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.8733 - accuracy: 0.5719\n",
      "Epoch 18/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.8373 - accuracy: 0.5824\n",
      "Epoch 19/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.8282 - accuracy: 0.5733\n",
      "Epoch 20/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.8242 - accuracy: 0.5981\n",
      "Epoch 21/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.8069 - accuracy: 0.5967\n",
      "Epoch 22/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.8293 - accuracy: 0.6267\n",
      "Epoch 23/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.8511 - accuracy: 0.5862\n",
      "Epoch 24/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.8295 - accuracy: 0.6200\n",
      "Epoch 25/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.8211 - accuracy: 0.6052\n",
      "Epoch 26/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.8096 - accuracy: 0.6133\n",
      "Epoch 27/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.7557 - accuracy: 0.6671\n",
      "Epoch 28/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.7299 - accuracy: 0.6857\n",
      "Epoch 29/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.7545 - accuracy: 0.6786\n",
      "Epoch 30/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.7133 - accuracy: 0.6910\n",
      "Epoch 31/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.6959 - accuracy: 0.6976\n",
      "Epoch 32/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.6676 - accuracy: 0.7224\n",
      "Epoch 33/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.6598 - accuracy: 0.7110\n",
      "Epoch 34/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.6915 - accuracy: 0.7105\n",
      "Epoch 35/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.6460 - accuracy: 0.7224\n",
      "Epoch 36/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.6452 - accuracy: 0.7200\n",
      "Epoch 37/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.6452 - accuracy: 0.7243\n",
      "Epoch 38/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.6524 - accuracy: 0.7281\n",
      "Epoch 39/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.6079 - accuracy: 0.7552\n",
      "Epoch 40/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.6056 - accuracy: 0.7586\n",
      "Epoch 41/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 0.7590\n",
      "Epoch 42/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.5430 - accuracy: 0.7776\n",
      "Epoch 43/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.5236 - accuracy: 0.7890\n",
      "Epoch 44/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.7581\n",
      "Epoch 45/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.7757\n",
      "Epoch 46/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7986\n",
      "Epoch 47/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.5418 - accuracy: 0.7824\n",
      "Epoch 48/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.7905\n",
      "Epoch 49/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.8071\n",
      "Epoch 50/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.7790\n",
      "10/10 - 0s - loss: 2.2120 - accuracy: 0.4133\n",
      "test_loss: 2.212017297744751 \n",
      "test_accuracy: 0.41333332657814026\n"
     ]
    }
   ],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (7,7), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (7,7), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=50)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")\n",
    "\n",
    "# test accuracy 0.41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c433498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 20, 20, 8)         1952      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 10, 10, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 2, 2, 16)          10384     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 1, 1, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 12,659\n",
      "Trainable params: 12,659\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "66/66 [==============================] - 1s 4ms/step - loss: 3.2245 - accuracy: 0.3224\n",
      "Epoch 2/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.1009 - accuracy: 0.3500\n",
      "Epoch 3/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.1042 - accuracy: 0.3338\n",
      "Epoch 4/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.1000 - accuracy: 0.3343\n",
      "Epoch 5/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0996 - accuracy: 0.3505\n",
      "Epoch 6/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0955 - accuracy: 0.3495\n",
      "Epoch 7/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0961 - accuracy: 0.3524\n",
      "Epoch 8/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0906 - accuracy: 0.3819\n",
      "Epoch 9/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0947 - accuracy: 0.3448\n",
      "Epoch 10/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0913 - accuracy: 0.3943\n",
      "Epoch 11/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0904 - accuracy: 0.3838\n",
      "Epoch 12/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0758 - accuracy: 0.4019\n",
      "Epoch 13/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0683 - accuracy: 0.4305\n",
      "Epoch 14/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0637 - accuracy: 0.4271\n",
      "Epoch 15/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0711 - accuracy: 0.4171\n",
      "Epoch 16/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0506 - accuracy: 0.4443\n",
      "Epoch 17/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0538 - accuracy: 0.4457\n",
      "Epoch 18/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0460 - accuracy: 0.4395\n",
      "Epoch 19/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0634 - accuracy: 0.4414\n",
      "Epoch 20/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0585 - accuracy: 0.4462\n",
      "Epoch 21/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0900 - accuracy: 0.3757\n",
      "Epoch 22/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0754 - accuracy: 0.4029\n",
      "Epoch 23/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0645 - accuracy: 0.4110\n",
      "Epoch 24/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0974 - accuracy: 0.3486\n",
      "Epoch 25/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.1003 - accuracy: 0.3381\n",
      "Epoch 26/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0991 - accuracy: 0.3329\n",
      "Epoch 27/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0990 - accuracy: 0.3200\n",
      "Epoch 28/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0989 - accuracy: 0.3219\n",
      "Epoch 29/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0989 - accuracy: 0.3290\n",
      "Epoch 30/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0988 - accuracy: 0.3262\n",
      "Epoch 31/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0988 - accuracy: 0.3324\n",
      "Epoch 32/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0989 - accuracy: 0.3329\n",
      "Epoch 33/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0988 - accuracy: 0.3186\n",
      "Epoch 34/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0992 - accuracy: 0.3333\n",
      "Epoch 35/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0988 - accuracy: 0.3248\n",
      "Epoch 36/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0989 - accuracy: 0.3224\n",
      "Epoch 37/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0988 - accuracy: 0.3195\n",
      "Epoch 38/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0990 - accuracy: 0.3133\n",
      "Epoch 39/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0989 - accuracy: 0.3157\n",
      "Epoch 40/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0988 - accuracy: 0.3210\n",
      "Epoch 41/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0990 - accuracy: 0.3243\n",
      "Epoch 42/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0989 - accuracy: 0.3195\n",
      "Epoch 43/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0990 - accuracy: 0.3267\n",
      "Epoch 44/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0989 - accuracy: 0.3219\n",
      "Epoch 45/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0988 - accuracy: 0.3210\n",
      "Epoch 46/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0989 - accuracy: 0.3243\n",
      "Epoch 47/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3171\n",
      "Epoch 48/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0989 - accuracy: 0.3286\n",
      "Epoch 49/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0990 - accuracy: 0.3167\n",
      "Epoch 50/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0990 - accuracy: 0.3086\n",
      "10/10 - 0s - loss: 1.0978 - accuracy: 0.2933\n",
      "test_loss: 1.0977503061294556 \n",
      "test_accuracy: 0.2933333218097687\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼 파라미터 변경 (8, 16, 16) 커널 9X9 epoch= 50\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(8, (9,9), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(16, (9,9), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=50)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "498934b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 22, 22, 16)        2368      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 11, 11, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 5, 5, 32)          25120     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 35,939\n",
      "Trainable params: 35,939\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "66/66 [==============================] - 1s 3ms/step - loss: 3.9943 - accuracy: 0.3781\n",
      "Epoch 2/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.9744 - accuracy: 0.5343\n",
      "Epoch 3/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.8874 - accuracy: 0.5952\n",
      "Epoch 4/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.8354 - accuracy: 0.6300\n",
      "Epoch 5/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.8962 - accuracy: 0.5786\n",
      "Epoch 6/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.7782 - accuracy: 0.6595\n",
      "Epoch 7/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.7760 - accuracy: 0.6452\n",
      "Epoch 8/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.7023 - accuracy: 0.6933\n",
      "Epoch 9/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.6867 - accuracy: 0.7010\n",
      "Epoch 10/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.7098 - accuracy: 0.6886\n",
      "Epoch 11/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.6877 - accuracy: 0.7029\n",
      "Epoch 12/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.6670 - accuracy: 0.7157\n",
      "Epoch 13/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.6173 - accuracy: 0.7395\n",
      "Epoch 14/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.6126 - accuracy: 0.7481\n",
      "Epoch 15/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.5661 - accuracy: 0.7714\n",
      "Epoch 16/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.6152 - accuracy: 0.7395\n",
      "Epoch 17/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.5384 - accuracy: 0.7786\n",
      "Epoch 18/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.5320 - accuracy: 0.7890\n",
      "Epoch 19/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4987 - accuracy: 0.8033\n",
      "Epoch 20/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.5251 - accuracy: 0.7890\n",
      "Epoch 21/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4987 - accuracy: 0.7890\n",
      "Epoch 22/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4832 - accuracy: 0.8019\n",
      "Epoch 23/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.8119\n",
      "Epoch 24/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.8033\n",
      "Epoch 25/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.8224\n",
      "Epoch 26/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4049 - accuracy: 0.8471\n",
      "Epoch 27/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.8224\n",
      "Epoch 28/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4121 - accuracy: 0.8352\n",
      "Epoch 29/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.8224\n",
      "Epoch 30/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3864 - accuracy: 0.8457\n",
      "Epoch 31/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4006 - accuracy: 0.8424\n",
      "Epoch 32/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3994 - accuracy: 0.8433\n",
      "Epoch 33/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3229 - accuracy: 0.8738\n",
      "Epoch 34/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3355 - accuracy: 0.8710\n",
      "Epoch 35/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3268 - accuracy: 0.8648\n",
      "Epoch 36/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2951 - accuracy: 0.8829\n",
      "Epoch 37/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.8248\n",
      "Epoch 38/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3706 - accuracy: 0.8538\n",
      "Epoch 39/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3111 - accuracy: 0.8805\n",
      "Epoch 40/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3426 - accuracy: 0.8681\n",
      "Epoch 41/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3165 - accuracy: 0.8790\n",
      "Epoch 42/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2443 - accuracy: 0.9033\n",
      "Epoch 43/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2526 - accuracy: 0.9000\n",
      "Epoch 44/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2205 - accuracy: 0.9143\n",
      "Epoch 45/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2342 - accuracy: 0.9090\n",
      "Epoch 46/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.8467\n",
      "Epoch 47/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.3245 - accuracy: 0.8705\n",
      "Epoch 48/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2322 - accuracy: 0.9152\n",
      "Epoch 49/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2527 - accuracy: 0.9033\n",
      "Epoch 50/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 0.2198 - accuracy: 0.9181\n",
      "10/10 - 0s - loss: 5.3506 - accuracy: 0.3700\n",
      "test_loss: 5.3506388664245605 \n",
      "test_accuracy: 0.3700000047683716\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼 파라미터 변경 (16, 32, 64) 커널 7X7 epoch= 50\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (7,7), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (7,7), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=50)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67e7a4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_26 (Conv2D)           (None, 22, 22, 16)        2368      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 11, 11, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 5, 5, 32)          25120     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 35,939\n",
      "Trainable params: 35,939\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 6.7141 - accuracy: 0.3367\n",
      "Epoch 2/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0988 - accuracy: 0.3233\n",
      "Epoch 3/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3176\n",
      "Epoch 4/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3133\n",
      "Epoch 5/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3276\n",
      "Epoch 6/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3205\n",
      "Epoch 7/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3176\n",
      "Epoch 8/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3295\n",
      "Epoch 9/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3333\n",
      "Epoch 10/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3205\n",
      "Epoch 11/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3229\n",
      "Epoch 12/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3314\n",
      "Epoch 13/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0988 - accuracy: 0.3314\n",
      "Epoch 14/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3252\n",
      "Epoch 15/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3319\n",
      "Epoch 16/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3114\n",
      "Epoch 17/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3100\n",
      "Epoch 18/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3014\n",
      "Epoch 19/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3319\n",
      "Epoch 20/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3076\n",
      "Epoch 21/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3143\n",
      "Epoch 22/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3229\n",
      "Epoch 23/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3152\n",
      "Epoch 24/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3176\n",
      "Epoch 25/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3038\n",
      "Epoch 26/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3262\n",
      "Epoch 27/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3162\n",
      "Epoch 28/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3224\n",
      "Epoch 29/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3352\n",
      "Epoch 30/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0988 - accuracy: 0.3305\n",
      "Epoch 31/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3281\n",
      "Epoch 32/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3333\n",
      "Epoch 33/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3267\n",
      "Epoch 34/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3286\n",
      "Epoch 35/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3210\n",
      "Epoch 36/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3195\n",
      "Epoch 37/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3195\n",
      "Epoch 38/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3276\n",
      "Epoch 39/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3190\n",
      "Epoch 40/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3171\n",
      "Epoch 41/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0988 - accuracy: 0.3152\n",
      "Epoch 42/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3176\n",
      "Epoch 43/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3133\n",
      "Epoch 44/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3143\n",
      "Epoch 45/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3129\n",
      "Epoch 46/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3310\n",
      "Epoch 47/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0988 - accuracy: 0.3205\n",
      "Epoch 48/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3181\n",
      "Epoch 49/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3238\n",
      "Epoch 50/50\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.3295\n",
      "10/10 - 0s - loss: 1.0845 - accuracy: 0.3967\n",
      "test_loss: 1.0845495462417603 \n",
      "test_accuracy: 0.39666667580604553\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼 파라미터 변경 (16, 32, 64) 커널 7X7 epoch= 50\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (7,7), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (7,7), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=50)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79440a6",
   "metadata": {},
   "source": [
    "### 데이터 셋의 양을 증가 시켜 학습했지만, 오히려 제공된 test sample 에 대한 accuracy 가 떨어졌다.\n",
    "- 범용적인 가위바위보 이미지 분류에 대한 모델 학습이 이루어 지지 않았다. (원하는 정도의 accuray 달성 못함)\n",
    "- 2100장의 데이터셋자체중 일부(20%)를 test셋으로 설정, 2100장의 이미지를 train과 test로 나누어 데이터 모집단 안에서 accuracy 측정\n",
    "- (일종의 validation 느낌)\n",
    "- 데이터의 over-fitting 을 극복하기 위해 정규화를 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75f5c69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn 의 트레인 테스트 스플릿 모듈을 이용해 데이터 셋 분리\n",
    "# 대문자 X Y 로 할당\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=17 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6c4fee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 7, 7, 32)          25120     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 64)                18496     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 44,259\n",
      "Trainable params: 44,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "42/42 [==============================] - 1s 7ms/step - loss: 6.3797 - accuracy: 0.3624 - val_loss: 1.5123 - val_accuracy: 0.4107\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.3246 - accuracy: 0.4137 - val_loss: 1.1031 - val_accuracy: 0.4583\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 1.1029 - accuracy: 0.4762 - val_loss: 1.0438 - val_accuracy: 0.5060\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.9934 - accuracy: 0.5290 - val_loss: 0.9703 - val_accuracy: 0.5446\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.9769 - accuracy: 0.5446 - val_loss: 1.3339 - val_accuracy: 0.4494\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.9450 - accuracy: 0.5521 - val_loss: 1.1460 - val_accuracy: 0.4851\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.8938 - accuracy: 0.5923 - val_loss: 0.9986 - val_accuracy: 0.5387\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.8261 - accuracy: 0.6376 - val_loss: 0.9653 - val_accuracy: 0.5625\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.7816 - accuracy: 0.6607 - val_loss: 0.8556 - val_accuracy: 0.6220\n",
      "Epoch 10/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.7582 - accuracy: 0.6711 - val_loss: 0.8321 - val_accuracy: 0.6399\n",
      "Epoch 11/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.7294 - accuracy: 0.6882 - val_loss: 0.8133 - val_accuracy: 0.6637\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.7176 - accuracy: 0.6875 - val_loss: 0.8237 - val_accuracy: 0.6518\n",
      "Epoch 13/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.7676 - accuracy: 0.6570 - val_loss: 0.8809 - val_accuracy: 0.6101\n",
      "Epoch 14/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.7140 - accuracy: 0.6793 - val_loss: 0.8105 - val_accuracy: 0.6696\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6401 - accuracy: 0.7411 - val_loss: 0.7594 - val_accuracy: 0.6726\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6377 - accuracy: 0.7359 - val_loss: 0.7587 - val_accuracy: 0.6875\n",
      "Epoch 17/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6303 - accuracy: 0.7299 - val_loss: 0.7778 - val_accuracy: 0.6488\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5952 - accuracy: 0.7470 - val_loss: 0.7508 - val_accuracy: 0.6935\n",
      "Epoch 19/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6503 - accuracy: 0.7188 - val_loss: 0.7809 - val_accuracy: 0.6875\n",
      "Epoch 20/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.5836 - accuracy: 0.7597 - val_loss: 0.8086 - val_accuracy: 0.6518\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5674 - accuracy: 0.7649 - val_loss: 0.7302 - val_accuracy: 0.6964\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7984 - val_loss: 0.6996 - val_accuracy: 0.7143\n",
      "Epoch 23/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.8051 - val_loss: 0.6939 - val_accuracy: 0.7083\n",
      "Epoch 24/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.8132 - val_loss: 0.6532 - val_accuracy: 0.7202\n",
      "Epoch 25/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.8147 - val_loss: 0.7718 - val_accuracy: 0.7024\n",
      "Epoch 26/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.8036 - val_loss: 0.6211 - val_accuracy: 0.7321\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.8430 - val_loss: 0.6332 - val_accuracy: 0.7411\n",
      "Epoch 28/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4027 - accuracy: 0.8482 - val_loss: 0.6264 - val_accuracy: 0.7411\n",
      "Epoch 29/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3974 - accuracy: 0.8475 - val_loss: 0.6146 - val_accuracy: 0.7500\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3587 - accuracy: 0.8713 - val_loss: 0.6696 - val_accuracy: 0.7411\n",
      "Epoch 31/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3693 - accuracy: 0.8534 - val_loss: 0.6347 - val_accuracy: 0.7292\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3635 - accuracy: 0.8713 - val_loss: 0.6691 - val_accuracy: 0.7292\n",
      "Epoch 33/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3270 - accuracy: 0.8981 - val_loss: 0.6746 - val_accuracy: 0.7351\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3218 - accuracy: 0.8876 - val_loss: 0.6754 - val_accuracy: 0.7440\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3151 - accuracy: 0.8817 - val_loss: 0.7477 - val_accuracy: 0.7411\n",
      "Epoch 36/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2956 - accuracy: 0.8936 - val_loss: 0.6851 - val_accuracy: 0.7530\n",
      "Epoch 37/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2885 - accuracy: 0.8996 - val_loss: 0.6966 - val_accuracy: 0.7411\n",
      "Epoch 38/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2655 - accuracy: 0.9152 - val_loss: 0.6685 - val_accuracy: 0.7679\n",
      "Epoch 39/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2486 - accuracy: 0.9211 - val_loss: 0.6926 - val_accuracy: 0.7440\n",
      "Epoch 40/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2351 - accuracy: 0.9137 - val_loss: 0.6699 - val_accuracy: 0.7470\n",
      "Epoch 41/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2818 - accuracy: 0.8951 - val_loss: 0.6888 - val_accuracy: 0.7470\n",
      "Epoch 42/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2353 - accuracy: 0.9241 - val_loss: 0.7428 - val_accuracy: 0.7292\n",
      "Epoch 43/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2451 - accuracy: 0.9100 - val_loss: 0.8430 - val_accuracy: 0.6994\n",
      "Epoch 44/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2449 - accuracy: 0.9100 - val_loss: 0.6630 - val_accuracy: 0.7470\n",
      "Epoch 45/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1945 - accuracy: 0.9435 - val_loss: 0.6748 - val_accuracy: 0.7589\n",
      "Epoch 46/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1687 - accuracy: 0.9531 - val_loss: 0.7308 - val_accuracy: 0.7440\n",
      "Epoch 47/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1728 - accuracy: 0.9501 - val_loss: 0.6853 - val_accuracy: 0.7679\n",
      "Epoch 48/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1704 - accuracy: 0.9501 - val_loss: 0.7398 - val_accuracy: 0.7738\n",
      "Epoch 49/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9643 - val_loss: 0.6931 - val_accuracy: 0.7768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1406 - accuracy: 0.9650 - val_loss: 0.7556 - val_accuracy: 0.7589\n",
      "14/14 - 0s - loss: 0.8824 - accuracy: 0.7214\n",
      "test_loss: 0.8824141621589661 \n",
      "test_accuracy: 0.7214285731315613\n"
     ]
    }
   ],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (7,7), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=50, validation_split=0.2) #train 내에서 validation 0.2잡아서 수행\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, Y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ebb9f3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss: 0.1406 - accuracy: 0.9650 - val_loss: 0.7556 - val_accuracy: 0.7589\n",
    "# ttest_loss: 0.8824141621589661 test_accuracy: 0.7214285731315613"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bdfafb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# over-fitting 방지하기위해 정규화\n",
    "X_train_norm = X_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "X_test_norm = X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39d4332f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_30 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 7, 7, 32)          25120     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 64)                18496     \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 44,259\n",
      "Trainable params: 44,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "42/42 [==============================] - 1s 7ms/step - loss: 1.1064 - accuracy: 0.3326 - val_loss: 1.0967 - val_accuracy: 0.3304\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.0948 - accuracy: 0.3787 - val_loss: 1.0891 - val_accuracy: 0.4018\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.0835 - accuracy: 0.4330 - val_loss: 1.0722 - val_accuracy: 0.4375\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.0593 - accuracy: 0.4710 - val_loss: 1.0399 - val_accuracy: 0.5030\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.0258 - accuracy: 0.5060 - val_loss: 1.0050 - val_accuracy: 0.4940\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.9915 - accuracy: 0.5216 - val_loss: 0.9810 - val_accuracy: 0.5268\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.9505 - accuracy: 0.5670 - val_loss: 0.9186 - val_accuracy: 0.5655\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.9057 - accuracy: 0.5856 - val_loss: 0.8840 - val_accuracy: 0.5595\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.8720 - accuracy: 0.6042 - val_loss: 0.8621 - val_accuracy: 0.5804\n",
      "Epoch 10/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.8434 - accuracy: 0.6228 - val_loss: 0.9122 - val_accuracy: 0.5417\n",
      "Epoch 11/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.8592 - accuracy: 0.6101 - val_loss: 0.8553 - val_accuracy: 0.6071\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.8014 - accuracy: 0.6324 - val_loss: 0.8073 - val_accuracy: 0.6220\n",
      "Epoch 13/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.7764 - accuracy: 0.6615 - val_loss: 0.8262 - val_accuracy: 0.6042\n",
      "Epoch 14/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.7740 - accuracy: 0.6600 - val_loss: 0.8315 - val_accuracy: 0.6429\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.6711 - val_loss: 0.7594 - val_accuracy: 0.6667\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.7310 - accuracy: 0.6741 - val_loss: 0.7305 - val_accuracy: 0.6875\n",
      "Epoch 17/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.7196 - accuracy: 0.6905 - val_loss: 0.7571 - val_accuracy: 0.6577\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.7039 - accuracy: 0.6964 - val_loss: 0.7342 - val_accuracy: 0.6577\n",
      "Epoch 19/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.7088 - accuracy: 0.6860 - val_loss: 0.7272 - val_accuracy: 0.6607\n",
      "Epoch 20/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6751 - accuracy: 0.7121 - val_loss: 0.7121 - val_accuracy: 0.6815\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6782 - accuracy: 0.7083 - val_loss: 0.7522 - val_accuracy: 0.6310\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6517 - accuracy: 0.7336 - val_loss: 0.6692 - val_accuracy: 0.7173\n",
      "Epoch 23/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.7240 - val_loss: 0.6651 - val_accuracy: 0.6905\n",
      "Epoch 24/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6433 - accuracy: 0.7321 - val_loss: 0.8026 - val_accuracy: 0.6399\n",
      "Epoch 25/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6276 - accuracy: 0.7307 - val_loss: 0.6439 - val_accuracy: 0.7113\n",
      "Epoch 26/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5905 - accuracy: 0.7455 - val_loss: 0.6470 - val_accuracy: 0.7143\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5765 - accuracy: 0.7537 - val_loss: 0.6233 - val_accuracy: 0.7292\n",
      "Epoch 28/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.5662 - accuracy: 0.7671 - val_loss: 0.7720 - val_accuracy: 0.6786\n",
      "Epoch 29/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5763 - accuracy: 0.7597 - val_loss: 0.6027 - val_accuracy: 0.7202\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5600 - accuracy: 0.7574 - val_loss: 0.6391 - val_accuracy: 0.7619\n",
      "Epoch 31/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5295 - accuracy: 0.7723 - val_loss: 0.5714 - val_accuracy: 0.7738\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.7984 - val_loss: 0.5628 - val_accuracy: 0.7917\n",
      "Epoch 33/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.8118 - val_loss: 0.5879 - val_accuracy: 0.7411\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.8095 - val_loss: 0.5128 - val_accuracy: 0.7827\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.8185 - val_loss: 0.5628 - val_accuracy: 0.7619\n",
      "Epoch 36/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.8192 - val_loss: 0.6082 - val_accuracy: 0.7619\n",
      "Epoch 37/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.8132 - val_loss: 0.5184 - val_accuracy: 0.8006\n",
      "Epoch 38/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.8400 - val_loss: 0.4913 - val_accuracy: 0.8125\n",
      "Epoch 39/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.8356 - val_loss: 0.5005 - val_accuracy: 0.8155\n",
      "Epoch 40/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8564 - val_loss: 0.5310 - val_accuracy: 0.8006\n",
      "Epoch 41/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8557 - val_loss: 0.4807 - val_accuracy: 0.8125\n",
      "Epoch 42/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3783 - accuracy: 0.8616 - val_loss: 0.4611 - val_accuracy: 0.8452\n",
      "Epoch 43/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3763 - accuracy: 0.8609 - val_loss: 0.4575 - val_accuracy: 0.8363\n",
      "Epoch 44/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3843 - accuracy: 0.8557 - val_loss: 0.4633 - val_accuracy: 0.8095\n",
      "Epoch 45/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3637 - accuracy: 0.8705 - val_loss: 0.4508 - val_accuracy: 0.8214\n",
      "Epoch 46/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3391 - accuracy: 0.8802 - val_loss: 0.4265 - val_accuracy: 0.8214\n",
      "Epoch 47/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3440 - accuracy: 0.8750 - val_loss: 0.4628 - val_accuracy: 0.8185\n",
      "Epoch 48/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3312 - accuracy: 0.8802 - val_loss: 0.4265 - val_accuracy: 0.8214\n",
      "Epoch 49/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3200 - accuracy: 0.8884 - val_loss: 0.4262 - val_accuracy: 0.8423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3138 - accuracy: 0.8921 - val_loss: 0.4594 - val_accuracy: 0.8274\n",
      "14/14 - 0s - loss: 0.4477 - accuracy: 0.8333\n",
      "test_loss: 0.4477120637893677 \n",
      "test_accuracy: 0.8333333134651184\n"
     ]
    }
   ],
   "source": [
    "# 정규화한 X\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (7,7), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_norm, Y_train, epochs=50, validation_split=0.2) #train 내에서 validation 0.2잡아서 수행\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test_norm, Y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")\n",
    "\n",
    "#ttest_loss: 0.4477120637893677 test_accuracy: 0.8333333134651184"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "45545e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_32 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 7, 7, 32)          25120     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 64)                18496     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 44,259\n",
      "Trainable params: 44,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "42/42 [==============================] - 1s 6ms/step - loss: 5.8782 - accuracy: 0.3624 - val_loss: 1.2814 - val_accuracy: 0.4048\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 1.0612 - accuracy: 0.5179 - val_loss: 0.9541 - val_accuracy: 0.5506\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.8332 - accuracy: 0.6295 - val_loss: 0.8136 - val_accuracy: 0.6518\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.7341 - accuracy: 0.6801 - val_loss: 0.7700 - val_accuracy: 0.6667\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6439 - accuracy: 0.7240 - val_loss: 0.7745 - val_accuracy: 0.6577\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6046 - accuracy: 0.7433 - val_loss: 0.7414 - val_accuracy: 0.6756\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5715 - accuracy: 0.7760 - val_loss: 0.6630 - val_accuracy: 0.7411\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.8118 - val_loss: 0.6850 - val_accuracy: 0.7232\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.8259 - val_loss: 0.6078 - val_accuracy: 0.7589\n",
      "Epoch 10/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3745 - accuracy: 0.8534 - val_loss: 0.5477 - val_accuracy: 0.7619\n",
      "Epoch 11/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2616 - accuracy: 0.9048 - val_loss: 0.5009 - val_accuracy: 0.7857\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2283 - accuracy: 0.9256 - val_loss: 0.4859 - val_accuracy: 0.7857\n",
      "Epoch 13/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2129 - accuracy: 0.9226 - val_loss: 0.4451 - val_accuracy: 0.8065\n",
      "Epoch 14/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1759 - accuracy: 0.9487 - val_loss: 0.5119 - val_accuracy: 0.8006\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1753 - accuracy: 0.9420 - val_loss: 0.5140 - val_accuracy: 0.8006\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1632 - accuracy: 0.9405 - val_loss: 0.4779 - val_accuracy: 0.8304\n",
      "Epoch 17/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1122 - accuracy: 0.9680 - val_loss: 0.5613 - val_accuracy: 0.8274\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0965 - accuracy: 0.9710 - val_loss: 0.4686 - val_accuracy: 0.8512\n",
      "Epoch 19/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.9874 - val_loss: 0.5603 - val_accuracy: 0.8333\n",
      "Epoch 20/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9881 - val_loss: 0.4690 - val_accuracy: 0.8512\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9859 - val_loss: 0.4665 - val_accuracy: 0.8571\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 0.9955 - val_loss: 0.4999 - val_accuracy: 0.8571\n",
      "Epoch 23/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0294 - accuracy: 0.9933 - val_loss: 0.4750 - val_accuracy: 0.8452\n",
      "Epoch 24/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.0224 - accuracy: 0.9970 - val_loss: 0.4957 - val_accuracy: 0.8512\n",
      "Epoch 25/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0219 - accuracy: 0.9978 - val_loss: 0.5207 - val_accuracy: 0.8423\n",
      "Epoch 26/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.4834 - val_accuracy: 0.8542\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.4751 - val_accuracy: 0.8661\n",
      "Epoch 28/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.4818 - val_accuracy: 0.8631\n",
      "Epoch 29/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4947 - val_accuracy: 0.8720\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.5167 - val_accuracy: 0.8631\n",
      "Epoch 31/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5066 - val_accuracy: 0.8542\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5095 - val_accuracy: 0.8571\n",
      "Epoch 33/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5106 - val_accuracy: 0.8601\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5296 - val_accuracy: 0.8661\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5163 - val_accuracy: 0.8542\n",
      "Epoch 36/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5173 - val_accuracy: 0.8542\n",
      "Epoch 37/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5280 - val_accuracy: 0.8661\n",
      "Epoch 38/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5274 - val_accuracy: 0.8512\n",
      "Epoch 39/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5309 - val_accuracy: 0.8542\n",
      "Epoch 40/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5398 - val_accuracy: 0.8571\n",
      "Epoch 41/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5399 - val_accuracy: 0.8571\n",
      "Epoch 42/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5422 - val_accuracy: 0.8542\n",
      "Epoch 43/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5396 - val_accuracy: 0.8542\n",
      "Epoch 44/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 9.5965e-04 - accuracy: 1.0000 - val_loss: 0.5343 - val_accuracy: 0.8601\n",
      "Epoch 45/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 9.0162e-04 - accuracy: 1.0000 - val_loss: 0.5496 - val_accuracy: 0.8601\n",
      "Epoch 46/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 8.5577e-04 - accuracy: 1.0000 - val_loss: 0.5252 - val_accuracy: 0.8750\n",
      "Epoch 47/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 7.9332e-04 - accuracy: 1.0000 - val_loss: 0.5262 - val_accuracy: 0.8750\n",
      "Epoch 48/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 7.4742e-04 - accuracy: 1.0000 - val_loss: 0.5243 - val_accuracy: 0.8810\n",
      "Epoch 49/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 7.0885e-04 - accuracy: 1.0000 - val_loss: 0.5241 - val_accuracy: 0.8839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 6.5124e-04 - accuracy: 1.0000 - val_loss: 0.5223 - val_accuracy: 0.8780\n",
      "14/14 - 0s - loss: 0.5847 - accuracy: 0.8881\n",
      "test_loss: 0.5847157835960388 \n",
      "test_accuracy: 0.8880952596664429\n"
     ]
    }
   ],
   "source": [
    "# 정규화 하지 않은 X  trial 2\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (7,7), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=50, validation_split=0.2) #train 내에서 validation 0.2잡아서 수행\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, Y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")\n",
    "\n",
    "#test_loss: 0.5847157835960388 test_accuracy: 0.8880952596664429"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0fd68770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_34 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 7, 7, 32)          25120     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 64)                18496     \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 44,259\n",
      "Trainable params: 44,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "42/42 [==============================] - 1s 6ms/step - loss: 1.0994 - accuracy: 0.3564 - val_loss: 1.0970 - val_accuracy: 0.3155\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.0978 - accuracy: 0.3475 - val_loss: 1.0859 - val_accuracy: 0.4464\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.0834 - accuracy: 0.4033 - val_loss: 1.0661 - val_accuracy: 0.5179\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.0533 - accuracy: 0.4487 - val_loss: 1.0445 - val_accuracy: 0.4315\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.0003 - accuracy: 0.5141 - val_loss: 0.9660 - val_accuracy: 0.5536\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.9704 - accuracy: 0.5193 - val_loss: 0.9677 - val_accuracy: 0.5208\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.9341 - accuracy: 0.5707 - val_loss: 0.8845 - val_accuracy: 0.5774\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.8844 - accuracy: 0.5915 - val_loss: 0.8475 - val_accuracy: 0.6131\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.8526 - accuracy: 0.6101 - val_loss: 0.8201 - val_accuracy: 0.6310\n",
      "Epoch 10/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.8205 - accuracy: 0.6086 - val_loss: 0.7864 - val_accuracy: 0.6518\n",
      "Epoch 11/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.7880 - accuracy: 0.6280 - val_loss: 0.7752 - val_accuracy: 0.6667\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.7683 - accuracy: 0.6540 - val_loss: 0.7574 - val_accuracy: 0.6607\n",
      "Epoch 13/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.7458 - accuracy: 0.6607 - val_loss: 0.7541 - val_accuracy: 0.6577\n",
      "Epoch 14/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.7324 - accuracy: 0.6637 - val_loss: 0.7567 - val_accuracy: 0.6607\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.7152 - accuracy: 0.6912 - val_loss: 0.7381 - val_accuracy: 0.6845\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.7010 - accuracy: 0.6905 - val_loss: 0.7075 - val_accuracy: 0.7054\n",
      "Epoch 17/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6841 - accuracy: 0.7180 - val_loss: 0.6838 - val_accuracy: 0.7113\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.6568 - accuracy: 0.7321 - val_loss: 0.7309 - val_accuracy: 0.6964\n",
      "Epoch 19/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6543 - accuracy: 0.7269 - val_loss: 0.6846 - val_accuracy: 0.7202\n",
      "Epoch 20/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6178 - accuracy: 0.7500 - val_loss: 0.6620 - val_accuracy: 0.7054\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6128 - accuracy: 0.7485 - val_loss: 0.6343 - val_accuracy: 0.7202\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5915 - accuracy: 0.7656 - val_loss: 0.6475 - val_accuracy: 0.7500\n",
      "Epoch 23/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5651 - accuracy: 0.7790 - val_loss: 0.6927 - val_accuracy: 0.6935\n",
      "Epoch 24/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5711 - accuracy: 0.7686 - val_loss: 0.6197 - val_accuracy: 0.7589\n",
      "Epoch 25/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.7760 - val_loss: 0.6480 - val_accuracy: 0.7530\n",
      "Epoch 26/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.8110 - val_loss: 0.5595 - val_accuracy: 0.7798\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.8162 - val_loss: 0.5683 - val_accuracy: 0.7887\n",
      "Epoch 28/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.8147 - val_loss: 0.5529 - val_accuracy: 0.7530\n",
      "Epoch 29/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.8378 - val_loss: 0.5542 - val_accuracy: 0.7917\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.8415 - val_loss: 0.5153 - val_accuracy: 0.7827\n",
      "Epoch 31/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.8438 - val_loss: 0.5299 - val_accuracy: 0.7857\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4048 - accuracy: 0.8557 - val_loss: 0.5885 - val_accuracy: 0.7798\n",
      "Epoch 33/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4083 - accuracy: 0.8504 - val_loss: 0.4919 - val_accuracy: 0.7738\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3805 - accuracy: 0.8624 - val_loss: 0.4762 - val_accuracy: 0.8095\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3687 - accuracy: 0.8728 - val_loss: 0.5007 - val_accuracy: 0.8125\n",
      "Epoch 36/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3526 - accuracy: 0.8757 - val_loss: 0.4793 - val_accuracy: 0.8125\n",
      "Epoch 37/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3546 - accuracy: 0.8802 - val_loss: 0.4591 - val_accuracy: 0.8095\n",
      "Epoch 38/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3342 - accuracy: 0.8869 - val_loss: 0.4499 - val_accuracy: 0.8214\n",
      "Epoch 39/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3127 - accuracy: 0.8973 - val_loss: 0.4580 - val_accuracy: 0.8214\n",
      "Epoch 40/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8817 - val_loss: 0.5126 - val_accuracy: 0.8036\n",
      "Epoch 41/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3184 - accuracy: 0.8906 - val_loss: 0.4675 - val_accuracy: 0.8095\n",
      "Epoch 42/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2988 - accuracy: 0.9040 - val_loss: 0.4397 - val_accuracy: 0.8423\n",
      "Epoch 43/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2733 - accuracy: 0.9152 - val_loss: 0.4679 - val_accuracy: 0.8304\n",
      "Epoch 44/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2698 - accuracy: 0.9092 - val_loss: 0.4804 - val_accuracy: 0.8244\n",
      "Epoch 45/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2590 - accuracy: 0.9115 - val_loss: 0.4245 - val_accuracy: 0.8244\n",
      "Epoch 46/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2834 - accuracy: 0.8996 - val_loss: 0.4621 - val_accuracy: 0.8125\n",
      "Epoch 47/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2578 - accuracy: 0.9085 - val_loss: 0.4260 - val_accuracy: 0.8512\n",
      "Epoch 48/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.9182 - val_loss: 0.4363 - val_accuracy: 0.8690\n",
      "Epoch 49/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2403 - accuracy: 0.9189 - val_loss: 0.4596 - val_accuracy: 0.8423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2275 - accuracy: 0.9256 - val_loss: 0.4198 - val_accuracy: 0.8482\n",
      "14/14 - 0s - loss: 0.3907 - accuracy: 0.8714\n",
      "test_loss: 0.3906564712524414 \n",
      "test_accuracy: 0.8714285492897034\n"
     ]
    }
   ],
   "source": [
    "# 정규화한 X 모델링과 테스트 trial 2\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (7,7), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_norm, Y_train, epochs=50, validation_split=0.2) #train 내에서 validation 0.2잡아서 수행\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test_norm, Y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")\n",
    "#test_loss: 0.3906564712524414 test_accuracy: 0.8714285492897034"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d18b278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_36 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 7, 7, 32)          25120     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 64)                18496     \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 44,259\n",
      "Trainable params: 44,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "42/42 [==============================] - 1s 6ms/step - loss: 1.1000 - accuracy: 0.3423 - val_loss: 1.0966 - val_accuracy: 0.3720\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.0913 - accuracy: 0.4144 - val_loss: 1.0792 - val_accuracy: 0.5149\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.0646 - accuracy: 0.4479 - val_loss: 1.0460 - val_accuracy: 0.4940\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.0147 - accuracy: 0.4874 - val_loss: 0.9522 - val_accuracy: 0.5714\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.9315 - accuracy: 0.5632 - val_loss: 0.8652 - val_accuracy: 0.5595\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.8622 - accuracy: 0.6064 - val_loss: 0.8177 - val_accuracy: 0.5893\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.8373 - accuracy: 0.6064 - val_loss: 0.7912 - val_accuracy: 0.6250\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.8132 - accuracy: 0.6220 - val_loss: 0.7940 - val_accuracy: 0.6042\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.8020 - accuracy: 0.6228 - val_loss: 0.8443 - val_accuracy: 0.6131\n",
      "Epoch 10/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.7933 - accuracy: 0.6391 - val_loss: 0.8353 - val_accuracy: 0.6042\n",
      "Epoch 11/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.7756 - accuracy: 0.6615 - val_loss: 0.7844 - val_accuracy: 0.6250\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.7366 - accuracy: 0.6756 - val_loss: 0.7535 - val_accuracy: 0.6696\n",
      "Epoch 13/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.7401 - accuracy: 0.6741 - val_loss: 0.7470 - val_accuracy: 0.6637\n",
      "Epoch 14/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.6893 - accuracy: 0.7046 - val_loss: 0.7331 - val_accuracy: 0.6548\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6730 - accuracy: 0.7076 - val_loss: 0.7038 - val_accuracy: 0.6905\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6452 - accuracy: 0.7225 - val_loss: 0.6988 - val_accuracy: 0.6845\n",
      "Epoch 17/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6467 - accuracy: 0.7321 - val_loss: 0.7162 - val_accuracy: 0.6935\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6393 - accuracy: 0.7351 - val_loss: 0.6907 - val_accuracy: 0.6905\n",
      "Epoch 19/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5986 - accuracy: 0.7574 - val_loss: 0.6826 - val_accuracy: 0.6786\n",
      "Epoch 20/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5765 - accuracy: 0.7746 - val_loss: 0.6528 - val_accuracy: 0.6964\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.7649 - val_loss: 0.6456 - val_accuracy: 0.7113\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5523 - accuracy: 0.7842 - val_loss: 0.6307 - val_accuracy: 0.7292\n",
      "Epoch 23/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5249 - accuracy: 0.7939 - val_loss: 0.6801 - val_accuracy: 0.7292\n",
      "Epoch 24/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5350 - accuracy: 0.7969 - val_loss: 0.6229 - val_accuracy: 0.7351\n",
      "Epoch 25/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7961 - val_loss: 0.6349 - val_accuracy: 0.7440\n",
      "Epoch 26/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4928 - accuracy: 0.8207 - val_loss: 0.6109 - val_accuracy: 0.7262\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.8296 - val_loss: 0.6053 - val_accuracy: 0.7411\n",
      "Epoch 28/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.8318 - val_loss: 0.6151 - val_accuracy: 0.7381\n",
      "Epoch 29/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.8326 - val_loss: 0.6087 - val_accuracy: 0.7440\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.8371 - val_loss: 0.5956 - val_accuracy: 0.7351\n",
      "Epoch 31/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.8333 - val_loss: 0.5901 - val_accuracy: 0.7589\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3890 - accuracy: 0.8594 - val_loss: 0.5514 - val_accuracy: 0.7708\n",
      "Epoch 33/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3784 - accuracy: 0.8571 - val_loss: 0.5977 - val_accuracy: 0.7411\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3570 - accuracy: 0.8705 - val_loss: 0.5684 - val_accuracy: 0.7589\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3631 - accuracy: 0.8690 - val_loss: 0.5627 - val_accuracy: 0.7649\n",
      "Epoch 36/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3484 - accuracy: 0.8832 - val_loss: 0.5830 - val_accuracy: 0.7589\n",
      "Epoch 37/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3137 - accuracy: 0.8966 - val_loss: 0.6195 - val_accuracy: 0.7500\n",
      "Epoch 38/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3185 - accuracy: 0.8906 - val_loss: 0.5601 - val_accuracy: 0.7619\n",
      "Epoch 39/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3354 - accuracy: 0.8743 - val_loss: 0.6146 - val_accuracy: 0.7589\n",
      "Epoch 40/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2908 - accuracy: 0.9062 - val_loss: 0.5699 - val_accuracy: 0.7679\n",
      "Epoch 41/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2839 - accuracy: 0.9025 - val_loss: 0.5730 - val_accuracy: 0.7619\n",
      "Epoch 42/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2673 - accuracy: 0.9092 - val_loss: 0.5289 - val_accuracy: 0.7768\n",
      "Epoch 43/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2544 - accuracy: 0.9115 - val_loss: 0.5303 - val_accuracy: 0.7857\n",
      "Epoch 44/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2523 - accuracy: 0.9219 - val_loss: 0.5568 - val_accuracy: 0.8006\n",
      "Epoch 45/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2513 - accuracy: 0.9077 - val_loss: 0.5313 - val_accuracy: 0.7887\n",
      "Epoch 46/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2485 - accuracy: 0.9159 - val_loss: 0.5784 - val_accuracy: 0.7708\n",
      "Epoch 47/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2406 - accuracy: 0.9241 - val_loss: 0.5463 - val_accuracy: 0.7917\n",
      "Epoch 48/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2270 - accuracy: 0.9167 - val_loss: 0.5436 - val_accuracy: 0.7589\n",
      "Epoch 49/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1960 - accuracy: 0.9464 - val_loss: 0.5567 - val_accuracy: 0.7857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1829 - accuracy: 0.9435 - val_loss: 0.5841 - val_accuracy: 0.7738\n",
      "14/14 - 0s - loss: 0.6113 - accuracy: 0.7976\n",
      "test_loss: 0.6113263964653015 \n",
      "test_accuracy: 0.7976190447807312\n"
     ]
    }
   ],
   "source": [
    "# 정규화한 X 모델링과 테스트 trial 3\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (7,7), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "hist = model.fit(X_train_norm, Y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test_norm, Y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5189bceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA2vElEQVR4nO3dd3iUVfbA8e9NMumNFAIkgYROpHcEBEEUEGFtqLRVd8WGZS2r7Lq2/e2uZXXtDcECgmJDxAKoNIVQBaSXQEiBVNJ7cn9/3BECpEEmmWTmfJ4nT/KWeedcDWfe3Pfec5XWGiGEEM2fi70DEEIIYRuS0IUQwkFIQhdCCAchCV0IIRyEJHQhhHAQktCFEMJBSEIXQggHIQldODyl1FGl1GX2jkOIhiYJXQghHIQkdOGUlFIeSqmXlFLJ1q+XlFIe1mMhSqllSqkspVSmUmqdUsrFeuwRpVSSUipXKbVfKTXavi0R4jQ3ewcghJ38HRgM9AY08BXwGPAP4EEgEQi1njsY0EqpLsAsYIDWOlkpFQW4Nm7YQlRP7tCFs5oKPK21TtVapwFPAdOtx0qB1kA7rXWp1nqdNkWPygEPIEYpZdFaH9VaH7ZL9EJUQRK6cFZtgPhK2/HWfQDPA4eAFUqpOKXUowBa60PA/cCTQKpS6mOlVBuEaCIkoQtnlQy0q7Td1roPrXWu1vpBrXV7YCLwwO995VrrhVrrYdbXauDZxg1biOpJQhfOwqKU8vz9C1gEPKaUClVKhQCPAwsAlFITlFIdlVIKyMZ0tVQopboopUZZH54WAYVAhX2aI8S5JKELZ/EtJgH//uUJbAF2Ar8B24D/s57bCfgByAM2AG9orVdh+s+fAdKBE0BLYHbjNUGImilZ4EIIIRyD3KELIYSDkIQuhBAOQhK6EEI4CEnoQgjhIOw29T8kJERHRUXZ6+2FEKJZ2rp1a7rWOrSqY3ZL6FFRUWzZssVeby+EEM2SUiq+umPS5SKEEA5CEroQQjgISehCCOEgmlQ99NLSUhITEykqKrJ3KA3K09OTiIgILBaLvUMRQjiQJpXQExMT8fPzIyoqClMXyfForcnIyCAxMZHo6Gh7hyOEcCBNqsulqKiI4OBgh03mAEopgoODHf6vECFE42tSCR1w6GT+O2dooxCi8TW5hF6bgpIyUnOKKCwpRypFCiHEac0uoZfmZ+GTG0diagb7T+SSlFVIblEpFTZI7llZWbzxxhvn/brx48eTlZVV7/cXQoj6aHYJPcDTDW+Xcjq6JNFGZZCdX8iR9Hz2JOcQn5FPSdmFLyBTXUIvKyur8XXffvstgYGBF/y+QghhC01qlEudeAWiPHwh5zj+Bel0c82jyCuMjApfsgpKKSzJIzrEBw+L63lf+tFHH+Xw4cP07t0bi8WCp6cnLVq0YN++fRw4cIA//OEPJCQkUFRUxH333cfMmTOB02UM8vLyGDduHMOGDWP9+vWEh4fz1Vdf4eXlZev/CkIIcY4mm9Cf+no3e5Jzaj5JV0BZEegToFypcHWnyHoz7WlxweWsh48xbfx54qqLqr3cM888w65du9i+fTurV6/myiuvZNeuXaeGF86bN4+goCAKCwsZMGAA1157LcHBwWdc4+DBgyxatIg5c+YwefJkPv/8c6ZNm3b+/wGEEOI8NbsulzMoF7B4g5sH6ApcygrxcjV96UWl5ZTXs1994MCBZ4wVf+WVV+jVqxeDBw8mISGBgwcPnvOa6OhoevfuDUC/fv04evRovWIQQoi6arJ36DXdSVepvAwy46C0gNIWHYnL1pSWV9A2yBt/rwubkenj43Pq59WrV/PDDz+wYcMGvL29GTlyZJVjyT08PE797OrqSmFh4QW9txBCnK/mfYdemasbBEWDqwVL9hE6BFnwsLgQn1HAyYKSOl3Cz8+P3NzcKo9lZ2fTokULvL292bdvH7GxsbaMXggh6q3J3qFfEFcLBHWA9AO4nYyjfXAnjp4sJiGzAAUEervX+PLg4GCGDh1K9+7d8fLyIiws7NSxsWPH8tZbb9GtWze6dOnC4MGDG7gxQghxfpS9Juf0799fn73Axd69e+nWrVv9L16cBxmHwN2HiqD2HE4voKxc0znMD1eXpjFL02ZtFUI4FaXUVq11/6qOOU6XS2UevhDYFkrycMlOoE2AF6XlFaTlSv0UIYTjcsyEDuAdBH6tofAkPsVptPB2Jy2vhOKycntHJoQQDcJxEzqAbxh4B0PeCVp7FKOAE9lyly6EcEyOndCVgoAIcLHgVnSSln4eZBeWkldUau/IhBDC5hw7oYOZfOQVAMW5hPhYcHd1ITm7SCo1CiEcjuMndACPAKACl5I8Wgd4UlRaTmZ+3camCyFEc+EkCd0XlCsUZ+HvZcHHw42UnCLKys+szHih5XMBXnrpJQoKCmwRrRBCXBDnSOjKBTz8oSgHBbQJ8KK8QpOaW3zGaZLQhRDNmWPNFK2Jpz8UnYSSfLw8fAnycScjr4QgH3c8raV2K5fPHTNmDC1btmTx4sUUFxdz9dVX89RTT5Gfn8/kyZNJTEykvLycf/zjH6SkpJCcnMyll15KSEgIq1atsnNjhRDOqOkm9O8ehRO/2fCC2oxLv/xp8PAlzN+TrMJSUnKKaBdsinBVLp+7YsUKPvvsMzZt2oTWmokTJ7J27VrS0tJo06YN33zzDWBqvAQEBPDiiy+yatUqQkJCbBizEELUXa1dLkqpeUqpVKXUrmqOK6XUK0qpQ0qpnUqpvrYP0xaUqfVSlA2Am6sLLbzdySkqo7zi3FWOVqxYwYoVK+jTpw99+/Zl3759HDx4kB49erBy5UoeeeQR1q1bR0BAQGM3RAghqlSXO/T3gdeAD6s5Pg7oZP0aBLxp/V4/456p9yXOkZcGOYlQWgQWTwK8LKTnFZNdWEaQz5mFu7TWzJ49m9tvv/2cy2zbto1vv/2Wxx57jNGjR/P444/bPlYhhDhPtd6ha63XApk1nDIJ+FAbsUCgUqq1rQK0KU/r3XSxuUv3dnfF3dWF7EIz0ahy+dwrrriCefPmkZeXB0BSUhKpqakkJyfj7e3NtGnTePjhh9m2bds5rxVCCHuwRR96OJBQaTvRuu/42ScqpWYCMwHatm1rg7c+T27u4OZlul18w1BKEeBtIT23hLLyijPK544bN44pU6YwZMgQAHx9fVmwYAGHDh3i4YcfxsXFBYvFwptvvgnAzJkzGTt2LG3atJGHokIIu6hT+VylVBSwTGvdvYpjy4BntNY/W7d/BB7RWm85+9zKGrR8bk1yjkPeCQjrDq4WCkvKOZiaS3igF8G+HrW/3kakfK4Q4kI0dPncJCCy0naEdV/TdKrbxSxA7WlxwcPNlawCqe8ihGjebJHQlwIzrKNdBgPZWutzuluaDIsXuJwe7aKUItDbQn5JGSVl5452EUKI5qLWPnSl1CJgJBCilEoEngAsAFrrt4BvgfHAIaAAuKU+AWmtUaoBVxVSytylF2ZCRQW4uBDoZSElp4jswlJC/Rq+20UKgwkhGkKtCV1rfVMtxzVwty2C8fT0JCMjg+Dg4IZN6p4BUJAOJbngGYCHxRUviytZBSUNntC11mRkZODp6dmg7yOEcD5NaqZoREQEiYmJpKWlNewbaQ056XC8wKxsBOQWlZFdWEpRmgdurg1b4sbT05OIiIgGfQ8hhPNpUgndYrEQHR3dOG/26fNw9Gd4cD+4uHA8u5DJ//mJB8Z05t7RnRonBiGEsCHnqLZYla5XQn4qJJmhk60DvBgYFcTSHcnSxy2EaJacN6F3vAxc3GDfN6d2XdW7DYdS89h3QmZ8CiGaH+dN6F6BEDUc9n5t+tSB8d1b4eqiWLoj2b6xCSHEBXDehA4QMwkyD0OKKSQZ7OvB0I4hfC3dLkKIZsi5E3q3q8xqRnu+OrVrYq82JJ4s5NeELPvFJYQQF8C5E7pPCEQNg91LTnW7XH5RGO5uLizdLt0uQojmxbkTOkDMHyDjIKTuAcDf08KoLi1ZtjNZSgEIIZoVSejdJppul91LTu26YWAk6XklfL/7hP3iEkKI8yQJ3TcU2g09ox99RKdQ2gZ5s2BDvB0DE0KI8yMJHcxol/T9kLoXABcXxbTBbdl0NJN9J3LsHJwQQtSNJHQw3S6oM7pdru8XiYebC/PlLl0I0UxIQgfwC7N2uyw5tauFjztX9WrDl78mkVMki18IIZo+Sei/i5kEafsgdd+pXTOGtKOgpJwvtzXdBZiEEOJ3ktB/F2Ptdqn0cLRnRCC9IgKYHxsvM0eFEE2eJPTf+bWCtkPO6HYBmD4kikOpeWyIy7BPXEIIUUeS0CuLmWQmGKUdOLVrQs/WBHpb5OGoEKLJk4ReWcxE873SXbqnxZUb+keyYk8KJ7KL7BOXEELUgST0yvzbQOTgM/rRAaYOakeF1izcdMxOgQkhRO0koZ8tZpIpp5t+6NSutsHejOwcyqJNxygtl/ouQoimSRL62WImme97vjxj94whUaTlFrNc6rsIIZooSehnCwiHiIHw22dQUX5q9yWdQ4kM8pKHo0KIJksSelUG3W4mGW19/9QuVxfFjMFRbDySyQsr9su4dCFEkyMJvSrdrzXrjf74NOSlndp989Aobugfyas/HeIvn2ynuKy8hosIIUTjkoReFaXgyhegJA9+eOLUbourC89c24OHr+jCku3JTJ+7iayCEjsGKoQQp0lCr05oFxgyC7Z/BMdiT+1WSnH3pR155aY+bD+WxTVvric+I//8r5+yGw79CGXFNgxaCOHMJKHXZMRfwT8Clj0A5WVnHJrYqw0f3TaIzPwSrn5jPVvjT9b9ukXZ8MFEWHANPNcBPr3FPIQtyrZxA4QQzkQSek3cfWDcM5C6Gza9fc7hAVFBfHnXUPw93ZgyJ5ZlO+u4sPTa56Egw3TrdL8ajqyFz/9kkvuCa2HPUhs3RAjhDCSh16brBOg4Blb9G3LOTdjRIT58cddQekYEMGvhr7z0w4GaR8BkHIbYt6DPVBjwZ5j4Kjx0AG5dDoPvgPSDsHgGHN/ZgI0SQjgiSei1UQrGPwflpbD871WeEuTjzoI/D+K6fhG89MNB7ln0K0Wl1YyAWfEPcPOAUY+f3ufiCm0Hw+X/B7evBa8WsPxvIEMjhRDnQRJ6XQS1h+EPwO4vIG51lad4uLny/HU9mT2uK9/8dpwb3t5Aas5ZxbziVsP+b2D4g2aVpKp4BcKlf4Oj62D/d7ZshRDCwUlCr6uh90OLaPjmQSjMqvIUpRS3j+jA29P6cTA1j4mv/cKuJOuDzvIy+H42BLaDwXfV/F79boGQLrDiMSiTYZFCiLqRhF5XFk+46mU4GQ/vT4DclGpPvfyiVnx2x8W4KLj+rQ28vuoQOevnmlrrl//TXKsmrm5wxb8g8zBsftfGDRFCOKo6JXSl1Fil1H6l1CGl1KNVHG+rlFqllPpVKbVTKTXe9qE2Ae1HwJRPIDMO5l1uvlcjpo0/S2YNZUB0EG8v30bpD/9kv2cvVupBlNWlYmOnMdBhNKx5BgoybdgIIYSjqjWhK6VcgdeBcUAMcJNSKuas0x4DFmut+wA3Am/YOtAmo+No+ONSM2Z87hVw4rdqT23p58mHtw5k3aDNBKk8ni6bzm3ztzLkmZ949vt9HEzJrXlEzOX/B8W5sPqZBmiIEMLR1OUOfSBwSGsdp7UuAT4GJp11jgb8rT8HAHUckN1MRfQ3wwxdLfDelRC/vvpz0w8S8Ns8VN/pvD/7T8yZ0Z9eEQG8szaOMf9by8j/rubpr/ew/nD6ubXWw2Kg382m26XSsnhCCFEVVVvVQKXUdcBYrfWfrdvTgUFa61mVzmkNrABaAD7AZVrrrVVcayYwE6Bt27b94uObeSnarASYfzVkJ8D170O7i03fet6J0993L4G0/XDvNvBteeqlqTlFrNybwg97UvjlcAYlZRX4e7oxoktLrurZmjExYSilID8dXuljFrCeuthuTRVCNA1Kqa1a6/5VHrNRQn/Aeq0XlFJDgLlAd611tZ3F/fv311u2bDn/1jQ1+Rnw0XWQvK3q4xZvGPcs9J1R7SUKSspYdzCdH/em8NO+VNLzShjaMZinJ3WnQ6gv/PIyrHwcpn8JHUY1UEOEEM1BfRP6EOBJrfUV1u3ZAFrr/1Q6Zzcm6SdYt+OAwVrr1Oqu6zAJHUw/9+a5ZoKQbytzJ+7XCnzDwDPATE6qo/IKs3bpc9/vo7i0gttHtOfu4ZF4vj3YlCK4fa3p6hFCOKX6JnQ34AAwGkgCNgNTtNa7K53zHfCJ1vp9pVQ34EcgXNdwcYdK6A0gNbeIf3+zlyXbk2kb5M3r/ZLpse4u6HE9XP0OuMiIUyGcUU0JvdasoLUuA2YBy4G9mNEsu5VSTyulJlpPexC4TSm1A1gE3FxTMhe1a+nnyUs39mHhnwfh5qq4amUgS4Jvg98+hW8fkrIAQohz1HqH3lDkDr3uisvKeWdNHC+sPMAHkcsYkbbQlA8Y/XjtLxZCOJSa7tDdGjsYcf483Fy5Z3Qn8krK+OOaK1nTtYx2614Az0AYeq+9wxNCNBHSEduMPHR5F/q0bcHEI9eQ32kSrPwHbP3A3mEJIZoISejNiMXVhVdu7INWLkzPvIWKDpfB1/fBri/sHZoQogmQhN7MRAZ589x1PdmWVMBz/n83ddS/mAmf3Qob34bk7ecslyeEcA7Sh94Mje3emhlD2vHWhniGTHmNES1eMLXWd31uTrB4Q3g/iBwEF/0BWvWwZ7hCiEYio1yaqaLScq55Yz3Hswv59r7htPb3hOxESNgICZsgIRZO7AJdDp3HwvCHIHKAvcMWQtRTvSYWNRRJ6PUXl5bHhFd/pnubAG67pD1JJwtIyiok8WQhSVmF5GWl80xELANTPobCkxA9Ai55CKKGn9fsVSFE0yEJ3YF9sS2RBxbvOLXt4eZCeAsvwgO9yMwv4WBqHj/N6k9E3Mew/lXIS4GIgXDZkxA11H6BCyEuiCR0B7crKZuyCk14oBchvu6mSiOQnFXIqBdWc1m3MF6b0hdKi+DX+abYV+4JuGEBdBlr5+iFEOejXlP/RdPXPTyA3pGBhPp5nErmAG0CvZh5SQeW7TzO1vhMs/TdwNvgjp+hVXdYPB0OrrRj5EIIW5KE7uDuGNGeMH8Pnl62l4oK619jXoGmFG9oV/h4Khz60a4xCiFsQxK6g/N2d+PhK7qyIyGLpTsqLSTl1QJmfAUhneHjKRC35vwvnrAZFt4Ae5baLmAhxAWThO4ErukTTo/wAJ79fh+FJeWnD3gHmaQe1MEk5qM/1+2C+Rmw9B6Ye5npslk8A2LfbJjghRB1JgndCbi4KP4xIYbj2UW8szbuzIM+wSapt2gHH10PR9ZVf6GKctjyHrzWD7YvhIvvgQf3Q9cr4ftHYfnfoaLaRaqEEA1MZoo6iYHRQYzr3oq31hzmhgGRtArwPH3QNxRmLIX3r4QPJoB3iFmgumUMtOxmvusK+H62WWqv3TC48r/mGMDkD+G7R2DDa5B7HP7wJrh52KehQjgxSehOZPa4bvy4N5Xnl+/nhcm9zjzoFwa3fg87F0PqbkjdC9vmQ2n+6XN8WsI1c8yqSZUnJrm4wvjnISACfnjCLJB940fm4asQotFIQncibYO9uWVYFG+viePmi6PoERFw5gk+ITDkrtPbFRWQfQxS9kB+Klx0tVkjtSpKwbD7wT8cltwJ88bCdfPMXbzMShWiUcjEIieTW1TKyOdX4+vpxlMTL2Jkl5a2f5O4NfDJNCjOgcB20PEy8xV9CXj42v79hHAiMlNUnCE2LoNHPt9JfEYBIzqH8tiV3egU5mfbN8k5Dvu/MWPc49aYrhsXC7QbAn1mQM/rbft+QjgJSejiHMVl5Xy4Pp5XfjpIQUk5Uwa25S9jOhPk4277NysrhmOxcOgHOPA9pB+Acc/BoNtt/15am8lSgZEw7lnbX18IO5OELqqVkVfMSz8cZOGmY3i7u/LAmM7cfHHUGSUEbKq8FD69GfYtgwkvQf9bbHv9HZ/AlzMBBXeuN6N1hHAgUstFVCvY14N//qE73903nN6RgTz19R6eXraHBvugd7WYh6WdLodlfzHj2W2lOBdWPm4W9HD3hTXP2O7aQjQDktAFAJ3D/Pjw1oHcMjSK9345yt++3HW69outuXnA5PnQfgR8dTf89pltrrv2v5B3wtz5D74D9nxlFvkQwklIQhenKKV4fEIMd43swKJNx3jo0x2UlTfQzE+LJ9y4ENoOMWui7v26ftfLOAyxb0CvKRDRH4bcDR7+cpcunIokdHEGpRR/HduVB8d05otfk7jv4+2UNlRSd/eBKZ9AeF/49BbY//2FX2v538DVHS57wmx7tYDBd5oPiuM7bROvEE2cJHRRpXtGd+Lv47vxzW/HuXPBVopKy2t/0YXw8IOpn0HYRbDoBnilLyy9F3Z+CjnJtb8eTIGwA9/DiL+CX6vT+wffBR4BsEZGuwjnIKNcRI3mbzjKP77azcDoIHqGB5BfUkZecTn5xWXkFZdRVFpOp5Z+DO0YzMUdQs6sEXM+CrNg+0em4uPRX6A42+wP6gDRw2HgTJP0z1ZWAm8OMcMV74oFt7OGXa5+Blb/B25fC617nft6IZoZGbYo6mXxlgSe+Go3AD4ebvh6uFq/u+Hu5sKupGxOFpQC0D7Eh4utyf3SLi3xcnc9/zesKIeUXdbk/jMcWQsl+dD9Whg5G0I6nj53/auw4jGY8il0vvzcaxVlw0s9oN1QuGnRhTRfiCZFErqoN611tWPTKyo0e0/ksOFwBusPZ7AxLoP8knIGRLVg0W2DcXOtZ89eQSasfwU2vm0mKfW+CUY8Aq4e8Go/M/t06qfVv37N87Dq/2DmamjT59zjJfmQGWeGOwrRxElCF42qtLyCTzYn8NiSXTw4pjP3jO5kmwvnpcLP/4PNc0053+AOZnTLXbFn3rWfrSgHXu4JkYPMQ9jfpR+CLXPh149MF8/gu+Dy/zPVI4VoompK6FJtUdicxdWFaYPbselIJi/9eJDhnUPpHRlY/wv7toSx/zFDEtf+F36dD0PvqzmZA3j6w5BZ8NM/zbJ5+amwaQ7ErTL1ZWImmoezsW9A+kG4bm71VSWFaMLkDl00mOzCUsa/vA43V8W39w7Hx8PG9w9FOSYR16VMQXEuvNTT9KnrcvBrA/1vhb4zTC14gC3z4NuHIbgj3PQxBEXbNl4hbECm/gu7CPCy8OLkXhzLLOCpr3fb/g08/etea93Dz9zddxpjZqne/xuMePh0MgeT4Kd/CbknYM4oM9pGnFZWDAtvhNUyDLSpkoQuGtSg9sHcNbIDi7ck8t1vx+0bTK8bTR96zERwreavhehL4LafwDsYPpwE2z40QyJrorWZvPTDk/Byb/hvF1Px8eeXzIdCSYGNG2In3/0VDnwH6/4L2Ul1e82RtTD/avNgWzS4OnW5KKXGAi8DrsC7Wutz5lMrpSYDTwIa2KG1nlLTNaXLxXmUlldw7Zvric8o4Pv7h9M6wMveIdWuMAs+uwUO/wReQdC6pxnH3roXtO4NLaJNGeBdn8PuLyDjEChXU5/GJxQSN5uRM2D2t+puPiwG/BlaRNmxYRdo6wfw9b3Qeyrs+NjMCxhXS1mF8jIzRyD9APS6Ca5+q3FidXD1GuWilHIFDgBjgERgM3CT1npPpXM6AYuBUVrrk0qpllrr1JquKwnducSl5XHlKz/Tt10g828dhItLM1iWrrwMdiyCxE1wfIdZiq/CjLfHzRPKigAFUcOg+zXQbaJZxu93+RkmsSduNteI32D672MmwcX3mpIHzUHiVnhvrGnn1M9g6T2w6wu4f6d5UF2dbfNh6SxoezEcWw/TPjcrV4l6qW9CHwI8qbW+wro9G0Br/Z9K5zwHHNBav1vXoCShO5+PNx3j0S9+469ju3DXyFpGpjRFZSWQts+a3HeZWawxk87sh69JdhJsehu2vGeW52s3DIbeCx3HgIsNej+LcqC85MwPlfrKS4N3Rpi/Mm5fA95BZrjn6wPg4ntgzNNVv660yMwR8AuDm7+Ft4aZPvi7NsgyhPVU34ei4UBCpe1E677KOgOdlVK/KKVirV00VQUyUym1RSm1JS0trS6xCwdyw4BIxvdoxXPf7+fJpbspKWugol8Nxc3ddL30nW5WQxo0s+7JHCAg3CTAv+yGy/8FJ4/CwskmOS69xwylTNh8YX3u5WXw/pUmidqqGFl5mel2KsiAG+abZA5mmOhF15j5ANX1jW+ZCzmJMPoJU1lz4qtmwfGf/mmb2ESVbPVQ1A3oBIwEbgLmKKUCzz5Ja/2O1rq/1rp/aGiojd5aNBdKKV6+sQ+3Do3m/fVHueGdDSRnFdo7rMbn6Q8Xz4L7tsM1cyAg0lSF/PYhmHsZ/CccXh8EX94BWcfqds2Nb8IJayL/cBKk2GBU0Y9PwtF1MOF/0Kb3mceGPwglebCxin7xohxY9wK0v9Q8UwAzm3fAbWa2b8Km+scmqlSXhJ4ERFbajrDuqywRWKq1LtVaH8H0udtoeqBwJBZXFx6/KobXp/TlwIlcJrz6M+sOOulfa64W6DkZZiyBvx6B+3fBDR/BJQ+bB6d7lsIn00xXRU2yEmDVv6HzWJi5yvTvfzARUvddeGy7vjB1cgbcBr2rGN8QFgNdJ5iEXpR95rENr5u7+tGPn7n/sifAP9z8NVJbmxzZzk9NuYkGUJeEvhnopJSKVkq5AzcCS886Zwnm7hylVAimCybOdmEKR3Nlz9YsvWcYIb7uzJi3iZd/ONhwKyQ1B0qZha27TYBL/2aGV1431/TXr3is+tdpbSZDAYx/HoLawx+/Bhc3+OAqSDtwfnFobfr4l9xlSiVc8e/qz73kYZPMN805vS8/HTa8Zp4tnP3Q18PP3O2n7YN1L55fXI2lvKzhrq21+eD94s+w6Z0GeYtaE7rWugyYBSwH9gKLtda7lVJPK6UmWk9bDmQopfYAq4CHtdYZDRKxcBgdQn1ZcvdQru4dzv9+OMD1b2/gqa938+bqw3y2NZE1B9LYezyHrIISe4dqH13GmZIFm94xy+lVZd8yMzZ85GwIbGv2hXQ0SR1tknrG4bq9X14aLLoJlt0PbQeZvxbOLkdcWZveZm3YDa+fvuNc9wKUFsCl1XwIdb4celxvzkvZU/U59lKYBa/2NStoVdj4+Y7WsPzvpjZ/n2lmlFMDkKn/wu601izalMC7P8eRmlNMXvGZd0lKwczh7Xnoii5Y6lu5sbkpKzFDBtMPmVEmlcsRFOfCawPNw8qZq00XTmWpe82DUjdPuPmbmksZHFhu1nctyoExT8HA2+s28iZhE8wdYx7yxkw0D2V73gCTXqv+Nfnp8NoA0600cCbkJpvFTH7/yks1i5X0v6X297elbx6EzdaBeoPuNDOL6zoTuSYV5WZB9G0fwKA74Ir/1GtUk1RbFM1KQUkZabnFpOUWk5pbzJr9aXyyJYE+bQN55cY+RAZ52zvExnUyHt4eboZJ3rr89F3z97Mh9k3400qIHFD1a0/8Zu7SdYVZv7V1bzM5qk1v8GsNpYWmS2fLXAjrbh7ShsWcX3wfXAVp+yFquHm4e+82CIio+TU7PzVdD7/zDDT96/6tIee4mZR113rThdQYkraZcg8DZ5ruqtjXzYikoffV77rlpbDkTvjtUxj+EIx6rN4fEpLQRbP3zc7jPPr5TpSC567rxdjurWp/kSPZuww+mWpK/I79DyRvhzmXQr9bYEIt/dEpu+GXV+D4djNrU1u7E3xCzTqsOUlmTPmof4Cbx/nHdmQdfDDB/DxkFlzxr7q97vhOs66sX2twr/QhnZ0Irw82Hzp//No2d8k1qSg3yTz3OMzaDO5+5sNm1+dw9dumZMSFKC2Cz26F/d+Y4ZvDH7BJuJLQhUM4llHArEXb2JmYzc0XRzF7fFc83Jyodvl3j5hRJZPnw88vmu6JuzeBV2Ddr1GSDyd2mYetx3eYZD7sL6eHF14IrWHeWPPBcd8O8Am+8Gv9bst7pi9/wksX3vVSlG1qyXQZX3ON+01zzJDRa+dCj+vMvrJi+Og6iF8PUxZDx9Hn9955qaYvPm4VjHvezFmwEUnowmGUlFXwzHf7mPfLEbqH+/Pm1H7O0wVTVgxzLzfdKLr8zARkb7knoPAktOxmm+tp6wPd5O1w90YzKeu84kmBBdeYGb1dJ8C174KlihpCuSnwWn8zImf6kjP/GijKgffGm+6fm5fVrVRD2gHY8Crs+AQqysyEqj5Tzy/2Wkj5XOEw3N3MOPY5M/pzLKOA695az6HUXHuH1TjcPOD698Hd15QL6H6tvSM6za+V7ZI5mMQ68RWTFJfdX3vFy8oy42De5ZB5xPSJ7/vGjMvPr2Lg3YrHTE2e8S+c27Xj6Q/TPjN/cXx0vfmLpqrx81qbOj2LbjKzfnd8Ysbu373J5sm8NnKHLpqt/SdymfruRiq0Zv6fBnJRGydZZSg/HTz8ax5S6Cg2vAHLZ8PV70CvG2o//8RvMP8aU0Rt6mcQ0d8M+fz8NjPOf+pnp0f7xK2BDyfCJX+FUX+v/prpB81fRoXWMgeegaYomW+Y+X4yHpK2gFcLMxFr4EzwbbiZ8NLlIhzWkfR8ps6JJa+4jPduGUi/di3sHZKwpYpy0z+fcdDc8dZU3TF+Ayy8wRT/mv4lhHY5fexYLCy60YxgmbIYwi6CN4eaxH9XbNXdMZWdPGo+APJTTf94Xsrp767upixy7ynmIW8Dk4QuHFpSViFT58SSmlvMuzP6c3HHM6sNaq3ZnZzD0h3JlFdo7hnVkUBvJ7i7dRRp+021xi7jYfIHVZ9zYDksnmHq4kz/0tyNn3OdA/DRteYvnE5jzJ371M+hU/Mq6SsJXTi81Jwips3dyNGMAt6a1pdRXcOIS8tj6Y5klm5PJi49HzdrDfZgX3eeu64XIzpLgbhmY+1/TaXGIbNMd1NJnhmxU1pgJljt/85Uwpz6Wc3lg3NTYKG1PzxmEkz+sPHaYCOS0IVTOJlfwox5m9h7PIdOYX7sPZ6DUjAoOoiJvcIZ170VSVmFPLB4OwdS8pg2uC1/G98Nb3cbL14tbK+81Ix6ObbBbLt5me4Nd2/zkDisuxmP7+FX+7WK82Dre2YVJVvWjm8kktCF08gpKuXuj7aRU1TGVT1bM6FnG1oFeJ5xTlFpOS+uPMCcdXG0DfLmxcm96NcuyE4RizqrqDB35u4+NY8rd3CS0IWowsa4DB78dAfJWYXcPqIDD4zp7Hy1YkSzI+PQhajCoPbBfH//JVzfL5I3Vx9mypxYUnOK7B2WEBdMErpwar4ebjx7XU9evrE3u5JyGP/Kz2yMk8rPonmShC4EMKl3OEvuHoq/pxtT3t3InLVx2Ks7UogLJQldCKsurfz4atZQLuvWkn99u5e7F247pza7EE2ZJHQhKvHztPDWtH7MHteV73edYOJrP3M0vWHWfxTC1iShC3EWpRS3j+jAgj8P4mR+Cde9tZ5dSdm1v1AIO5OELkQ1Lu4Qwqd3XIzF1YWb3omVh6WiyZOELkQNOrb05fM7L6alvwcz5m3ihz0p9g5JiGpJQheiFm0Cvfj0jovp2sqP2xds5fOtifYOSYgqSUIXog6CfNz56LbBDG4fxIOf7mDuz0fsHZIQ55CELkQd+Xq4Me/mAYzr3op/LtvD9Lkb+WhjvMwuFU2G1HIR4jyVV2heX3WIz7clEp9RAEDvyEDGxIRxxUVhdAj1RTX0SvXCaUlxLiEagNaag6l5rNyTwordJ9iRaIY2dg/35/7RnRndraUkdmFzktCFaAQnsotYvvsEc38+wrHMAnpGBPCXMZ0Z2TlUEruwGUnoQjSi0vIKvtyWxCs/HSTxZCF92gbywJjODOsYIold1JuUzxWiEVlcXZg8IJKfHhzJv6/uQUp2EdPnbmL63E1kF5baOzzhwCShC9FA3N1cmDKoLaseHskTV8Ww8UgG0+duJKugxN6hCQclCV2IBubh5sotQ6N5a1o/9h3PZcqcjZzMl6QubE8SuhCNZHS3MOb8sT+H0/K4aU4s6XnF9g5JOBhJ6EI0ohGdQ5l38wCOZuRz0zuxpObKpCRhO5LQhWhkQzuG8N7NA0nKKuTGd2JJsc40rajQpOYU8euxkyzbmcyC2HgypWtGnAcZtiiEnWw+msnN8zbh5e6Gj4crx7OKKCmvOOOczmG+LLxtMCG+HnaKUjQ19R6HrpQaC7wMuALvaq2fqea8a4HPgAFa6xqztSR0IWDbsZO88uNB/DwthAd6ER7oSZtAL8JbeHE8u4g7F2ylbZC3JHVxSr0SulLKFTgAjAESgc3ATVrrPWed5wd8A7gDsyShC1F/Gw5ncMv7mySpi1PqO7FoIHBIax2ntS4BPgYmVXHeP4FnAXnKI4SNDOkQzHs3D+RYZgFTZGSMqEVdEno4kFBpO9G67xSlVF8gUmv9TU0XUkrNVEptUUptSUtLO+9ghXBGktRFXdV7lItSygV4EXiwtnO11u9orftrrfuHhobW962FcBpnJ/UT2fKHsDhXXRJ6EhBZaTvCuu93fkB3YLVS6igwGFiqlKqyj0cIcWEqJ/Vhz/7Enz/YzLe/HaeotNzeoYkmwq0O52wGOimlojGJ/EZgyu8HtdbZQMjv20qp1cBDtT0UFUKcvyEdgvn23uF8siWBJb8m8cPeVPw93ZjQqw3X9AmnX7sWUtHRidWa0LXWZUqpWcByzLDFeVrr3Uqpp4EtWuulDR2kEOK09qG+zB7Xjb9e0ZX1h9P5YlsSX25LYuHGY/QID+CVm/oQHeJj7zCFHcjEIiEcQF5xGct2JPOf7/ZRVl7Bv6/pwaTe4bW/UDQ7Ug9dCAfn6+HGjQPb8u19w+na2p/7Pt7O7C92Ulgi/evOpC596EKIZiI80IuPZw7mxZUHeHP1YbbFZ/H61D50bOl36pzswlJ2JmaxIyGLhMxCru4bzuD2wXaMWtiKdLkI4aDWHEjjgU+2U1BSzq3DojieVcT2hCzi0vNPnePt7kpBSTlDOwbzwJgu9GvXwo4Ri7qQNUWFcFIpOUXc9/GvxMZlEurnQe/IQHpHBtIrIpAeEQF4uLmwIDaet9YcJj2vhBGdQ/nLmM70jgy0d+iiGpLQhXBiWmuyCkoJ9LZUO6SxoKSMDzfE8/aaw5wsKOWybi15alJ3wgO9GjlaURt5KCqEE1NK0cLHvcbx6d7ubtwxogPrHhnFw1d0ITbOlPbNLZJFrZsTSehCiFN8Pdy4+9KOvDO9H3Hp+dy76FfKK+zzV7w4f5LQhRDnuLhjCE9OvIhV+9N49vt9F3QNrTVf70jm8a92SXmCRiLDFoUQVZo+uB0HU3J5Z20cnVr6cn3/yNpfZLUnOYcnv97NpiOZAPh7Wnjoii4NFaqwkoQuhKjW4xNiiEvL529f/kZ0iA/9o4JqPP9kfgkvrjzARxvjCfCy8O+re7DlaCZvrTnM+B6tiWnj30iROyfpchFCVMvN1YXXp/QlooU3t8/fSkJmQZXnlZVXMH/DUS59YTULNx1jxpAoVj90KVMGteXxq2II9LbwyOc7KTtrzVRhWzJsUQhRq8NpeVz9+i+0CfTi5Rv7EJ+Rz8HUPA6k5HIgJY/DaXmUlFVwcYdgnrjqIrq08jvj9ct2JjNr4a/8bXxXZl7SwU6tcAwyDl0IUW/rDqZx83ubzxj1Eh7oRacwXzq19GVIh2Au7dKyyuGRWmtmzt/KuoNpfH/fJURJNcgLJgldCGETm45kcjQ93yTxMD98Per+GO5EdhFjXlxD9/AAFt42SOq2XyCZWCSEsImB0UFMHhBJn7YtziuZA7QK8GT2+G5siMvgk80Jtb9AnDdJ6EKIRnPjgEgGRQfxr2/3kpIj66LamiR0IUSjcXFRPHNtT0rKKvjHkl3Yq8vXUck4dCFEo4oO8eEvYzrzzHf7GPrMTwyIDqJ/VBADo4Lo1NIXFxfpW79QktCFEI3utuHtCfSysO5QOhsOZ/DV9mQAArws9G/XgpsGtmV0t6pHzIjqySgXIYRdaa1JyCxk89FMNh/NZN3BdJKyChneKYTHJ8TQKcyv9os4ERm2KIRoNkrLK1gQG8//Vh4gv6Sc6YPb8ZfLOhPgbbF3aE2CDFsUQjQbFlcXbhkazaqHRnLjgEg+3HCUkf9dxfzYeCkdUAu5QxdCNGl7knN46uvdbDySSXSID7cOi+a6vhF4ubvaOzS7kC4XIUSzprVm+e4U3lx9iB2J2QR6W5g2qB0zhrSjpb+nvcNrVJLQhRAOQWvNlviTvLsujhV7UnBzUUzsFc61fcNp6e9BoLc7gV4W3Fwdtze5poQuwxaFEM2GUooBUUEMiAoiPiOf9345yuItCXy+LfGM8/w83Aj0sRDgZcHL4opn5S83F7zdXQny8SDUz4OWftbv/h4E+3jg7tZ8PwzkDl0I0axlF5SyIzGLkwUlZBWUklVQav25hOzCUopKKygsLaeotJzisgqKSsspKCknu7DqBbC7tvJjeKcQLukcyoCoIDwtTauvXu7QhRAOK8DbwiWdQ8/7dSVlFaTnFZOWa75Sc4s5kVPElqOZfLA+njnrjuBpcWFQdDDDO4VwxUWtiAzyboAW2I7coQshxFkKSsqIjctg7YF01h5MIy4tHxcFV/Zsw50jOth1KT25QxdCiPPg7e7GqK5hjOoaBkBCZgELYuNZEBvP1zuSubRLKHdd2pEBtayx2tjkDl0IIeoou6CUDzcc5b31R8nML2FAVAvuG92ZYZ1CGi0GmSkqhBA2EOBt4Z7RnfjlkVE8eVUMyVlFTJ+3kaU7ku0dGiAJXQghzpuXuys3D43mxwdHMCAqiAc+2c6qfan2DksSuhBCXChPiyvv/rE/XVv7cedHW9l8NNOu8dQpoSulxiql9iulDimlHq3i+ANKqT1KqZ1KqR+VUu1sH6oQQjQ9/p4WPrhlIG0Cvbj1/c3sTs62Wyy1JnSllCvwOjAOiAFuUkrFnHXar0B/rXVP4DPgOVsHKoQQTVWwrwcL/jQIPw83ZszdRFxanl3iqMsd+kDgkNY6TmtdAnwMTKp8gtZ6lda6wLoZC0TYNkwhhGja2gR6Mf/PgwCYPncTx7MLGz2GuiT0cCCh0naidV91/gR8V9UBpdRMpdQWpdSWtLS0ukcphBDNQIdQXz64dSA5haVMfXcj6w+nN+pC2DZ9KKqUmgb0B56v6rjW+h2tdX+tdf/Q0POfqiuEEE1d9/AA5t48gJzCUqbM2cjE135h6Y7kRlmcoy4JPQmIrLQdYd13BqXUZcDfgYla62LbhCeEEM3PwOggfn5kFP++ugf5xWXcu+hXRjy/mnk/HyGvuKzB3rfWmaJKKTfgADAak8g3A1O01rsrndMH8zB0rNb6YF3eWGaKCiGcQUWF5sd9qbyz9jCbj57E39ONf/6hO5N619RzXb161XLRWpcppWYBywFXYJ7WerdS6mlgi9Z6KaaLxRf4VCkFcExrPfGCohVCCAfi4qIYExPGmJgwth0zi3O0baCqjVLLRQghmhGp5SKEEE5AEroQQjgISehCCOEgJKELIYSDkIQuhBAOQhK6EEI4CEnoQgjhICShCyGEg7DbxCKlVBoQf4EvDwHSbRhOc+Gs7Qbnbbu027nUpd3ttNZVVje0W0KvD6XUlupmSjkyZ203OG/bpd3Opb7tli4XIYRwEJLQhRDCQTTXhP6OvQOwE2dtNzhv26XdzqVe7W6WfehCCCHO1Vzv0IUQQpxFEroQQjiIZpfQlVJjlVL7lVKHlFKP2juehqKUmqeUSlVK7aq0L0gptVIpddD6vYU9Y2wISqlIpdQqpdQepdRupdR91v0O3XallKdSapNSaoe13U9Z90crpTZaf98/UUq52zvWhqCUclVK/aqUWmbddvh2K6WOKqV+U0ptV0ptse6r1+95s0roSilX4HVgHBAD3KSUirFvVA3mfWDsWfseBX7UWncCfrRuO5oy4EGtdQwwGLjb+v/Y0dteDIzSWvcCegNjlVKDgWeB/2mtOwIngT/ZL8QGdR+wt9K2s7T7Uq1170pjz+v1e96sEjowEDiktY7TWpcAHwOT7BxTg9BarwUyz9o9CfjA+vMHwB8aM6bGoLU+rrXeZv05F/OPPBwHb7s28qybFuuXBkZhFmAHB2w3gFIqArgSeNe6rXCCdlejXr/nzS2hhwMJlbYTrfucRZjW+rj15xNAmD2DaWhKqSigD7ARJ2i7tdthO5AKrAQOA1la6zLrKY76+/4S8FegwrodjHO0WwMrlFJblVIzrfvq9XvuZsvoROPRWmullMOOOVVK+QKfA/drrXPMTZvhqG3XWpcDvZVSgcCXQFf7RtTwlFITgFSt9Val1Eg7h9PYhmmtk5RSLYGVSql9lQ9eyO95c7tDTwIiK21HWPc5ixSlVGsA6/dUO8fTIJRSFkwy/0hr/YV1t1O0HUBrnQWsAoYAgUqp32+8HPH3fSgwUSl1FNOFOgp4GcdvN1rrJOv3VMwH+EDq+Xve3BL6ZqCT9Qm4O3AjsNTOMTWmpcAfrT//EfjKjrE0CGv/6Vxgr9b6xUqHHLrtSqlQ6505SikvYAzm+cEq4DrraQ7Xbq31bK11hNY6CvPv+Set9VQcvN1KKR+llN/vPwOXA7uo5+95s5spqpQaj+lzcwXmaa3/Zd+IGoZSahEwElNOMwV4AlgCLAbaYkoPT9Zan/3gtFlTSg0D1gG/cbpP9W+YfnSHbbtSqifmIZgr5kZrsdb6aaVUe8ydaxDwKzBNa11sv0gbjrXL5SGt9QRHb7e1fV9aN92AhVrrfymlgqnH73mzS+hCCCGq1ty6XIQQQlRDEroQQjgISehCCOEgJKELIYSDkIQuhBAOQhK6EEI4CEnoQgjhIP4f6cfdr9MuqowAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 정규화한 데이터의 epoch 횟수에따른  train test 의 accuracy 와 loss\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef66a25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_38 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 7, 7, 32)          25120     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 64)                18496     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 44,259\n",
      "Trainable params: 44,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "42/42 [==============================] - 1s 6ms/step - loss: 3.2573 - accuracy: 0.3750 - val_loss: 1.2225 - val_accuracy: 0.4315\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 1.1488 - accuracy: 0.4345 - val_loss: 1.1174 - val_accuracy: 0.4464\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 1.1049 - accuracy: 0.4472 - val_loss: 1.1111 - val_accuracy: 0.4315\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 1.0298 - accuracy: 0.4814 - val_loss: 1.0864 - val_accuracy: 0.4613\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.0408 - accuracy: 0.5022 - val_loss: 1.0551 - val_accuracy: 0.4613\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.9867 - accuracy: 0.5350 - val_loss: 1.0345 - val_accuracy: 0.4494\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.9406 - accuracy: 0.5469 - val_loss: 0.9622 - val_accuracy: 0.5536\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.9076 - accuracy: 0.5796 - val_loss: 0.9341 - val_accuracy: 0.5744\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.8599 - accuracy: 0.6057 - val_loss: 0.9099 - val_accuracy: 0.5685\n",
      "Epoch 10/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.8425 - accuracy: 0.6183 - val_loss: 0.8893 - val_accuracy: 0.6042\n",
      "Epoch 11/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.8053 - accuracy: 0.6481 - val_loss: 0.8582 - val_accuracy: 0.6310\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.7738 - accuracy: 0.6548 - val_loss: 0.8174 - val_accuracy: 0.6369\n",
      "Epoch 13/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.7252 - accuracy: 0.6853 - val_loss: 0.8366 - val_accuracy: 0.6637\n",
      "Epoch 14/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6953 - accuracy: 0.7083 - val_loss: 0.8313 - val_accuracy: 0.6280\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6842 - accuracy: 0.7113 - val_loss: 0.7596 - val_accuracy: 0.6905\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6305 - accuracy: 0.7478 - val_loss: 0.7463 - val_accuracy: 0.6637\n",
      "Epoch 17/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.5969 - accuracy: 0.7589 - val_loss: 0.7279 - val_accuracy: 0.6994\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.6062 - accuracy: 0.7478 - val_loss: 0.7605 - val_accuracy: 0.6726\n",
      "Epoch 19/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.5863 - accuracy: 0.7738 - val_loss: 0.6996 - val_accuracy: 0.7173\n",
      "Epoch 20/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5395 - accuracy: 0.7917 - val_loss: 0.6889 - val_accuracy: 0.7113\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7827 - val_loss: 0.6809 - val_accuracy: 0.7321\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4864 - accuracy: 0.8132 - val_loss: 0.6844 - val_accuracy: 0.7083\n",
      "Epoch 23/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.8304 - val_loss: 0.7430 - val_accuracy: 0.6726\n",
      "Epoch 24/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.8274 - val_loss: 0.6928 - val_accuracy: 0.6905\n",
      "Epoch 25/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7954 - val_loss: 0.7336 - val_accuracy: 0.6756\n",
      "Epoch 26/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8438 - val_loss: 0.6597 - val_accuracy: 0.6964\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3940 - accuracy: 0.8586 - val_loss: 0.6843 - val_accuracy: 0.7113\n",
      "Epoch 28/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.8408 - val_loss: 0.6594 - val_accuracy: 0.7351\n",
      "Epoch 29/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3464 - accuracy: 0.8743 - val_loss: 0.6896 - val_accuracy: 0.7440\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3282 - accuracy: 0.8743 - val_loss: 0.6748 - val_accuracy: 0.7083\n",
      "Epoch 31/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2975 - accuracy: 0.8981 - val_loss: 0.6766 - val_accuracy: 0.7411\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2991 - accuracy: 0.8839 - val_loss: 0.6742 - val_accuracy: 0.7619\n",
      "Epoch 33/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2668 - accuracy: 0.9070 - val_loss: 0.6889 - val_accuracy: 0.7500\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2813 - accuracy: 0.9003 - val_loss: 0.6912 - val_accuracy: 0.7560\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2408 - accuracy: 0.9122 - val_loss: 0.6412 - val_accuracy: 0.7500\n",
      "Epoch 36/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2512 - accuracy: 0.9085 - val_loss: 0.6936 - val_accuracy: 0.7530\n",
      "Epoch 37/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2175 - accuracy: 0.9241 - val_loss: 0.7297 - val_accuracy: 0.7351\n",
      "Epoch 38/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1856 - accuracy: 0.9457 - val_loss: 0.7047 - val_accuracy: 0.7440\n",
      "Epoch 39/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1490 - accuracy: 0.9628 - val_loss: 0.6465 - val_accuracy: 0.7589\n",
      "Epoch 40/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1763 - accuracy: 0.9397 - val_loss: 0.8831 - val_accuracy: 0.7173\n",
      "Epoch 41/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2270 - accuracy: 0.9226 - val_loss: 0.7224 - val_accuracy: 0.7619\n",
      "Epoch 42/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.9568 - val_loss: 0.7896 - val_accuracy: 0.7530\n",
      "Epoch 43/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.9509 - val_loss: 0.7026 - val_accuracy: 0.7589\n",
      "Epoch 44/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1223 - accuracy: 0.9628 - val_loss: 0.6797 - val_accuracy: 0.7500\n",
      "Epoch 45/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1381 - accuracy: 0.9561 - val_loss: 0.7501 - val_accuracy: 0.7619\n",
      "Epoch 46/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1174 - accuracy: 0.9613 - val_loss: 0.7608 - val_accuracy: 0.7619\n",
      "Epoch 47/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1206 - accuracy: 0.9613 - val_loss: 0.8104 - val_accuracy: 0.7440\n",
      "Epoch 48/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0765 - accuracy: 0.9851 - val_loss: 0.7803 - val_accuracy: 0.7589\n",
      "Epoch 49/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.0972 - accuracy: 0.9695 - val_loss: 0.7992 - val_accuracy: 0.7440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1183 - accuracy: 0.9628 - val_loss: 0.7827 - val_accuracy: 0.7619\n",
      "14/14 - 0s - loss: 0.7173 - accuracy: 0.7952\n",
      "test_loss: 0.71726393699646 \n",
      "test_accuracy: 0.7952380776405334\n"
     ]
    }
   ],
   "source": [
    "# 정규화하지 않은 X 모델링과 테스트 trial 3\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (7,7), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "hist = model.fit(X_train, Y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, Y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")\n",
    "\n",
    "#test_loss: 0.71726393699646 test_accuracy: 0.7952380776405334"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "113b0a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 정규화하지 않은 모델링 시각화\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1578f647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화 하였을때 over-fitting 이 줄어드는 것을 알수 있었다. (원인 discussion 필요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1800a40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 7, 7, 32)          25120     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 64)                18496     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 44,259\n",
      "Trainable params: 44,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "42/42 [==============================] - 1s 6ms/step - loss: 1.0974 - accuracy: 0.3266 - val_loss: 1.0924 - val_accuracy: 0.4405\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.0833 - accuracy: 0.4204 - val_loss: 1.0645 - val_accuracy: 0.5089\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 1.0311 - accuracy: 0.5179 - val_loss: 1.0312 - val_accuracy: 0.4792\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.9737 - accuracy: 0.5387 - val_loss: 0.9586 - val_accuracy: 0.5536\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.9135 - accuracy: 0.5856 - val_loss: 0.8987 - val_accuracy: 0.6012\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.8996 - accuracy: 0.5952 - val_loss: 0.9243 - val_accuracy: 0.5268\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.8541 - accuracy: 0.6190 - val_loss: 0.8408 - val_accuracy: 0.6131\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.7931 - accuracy: 0.6518 - val_loss: 0.7863 - val_accuracy: 0.6518\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.7558 - accuracy: 0.6719 - val_loss: 0.7733 - val_accuracy: 0.6369\n",
      "Epoch 10/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.7561 - accuracy: 0.6622 - val_loss: 0.7707 - val_accuracy: 0.6429\n",
      "Epoch 11/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.7266 - accuracy: 0.6771 - val_loss: 0.7608 - val_accuracy: 0.6518\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.7230 - accuracy: 0.6786 - val_loss: 0.7267 - val_accuracy: 0.6786\n",
      "Epoch 13/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.6962 - accuracy: 0.7024 - val_loss: 0.7217 - val_accuracy: 0.6696\n",
      "Epoch 14/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6946 - accuracy: 0.7009 - val_loss: 0.7290 - val_accuracy: 0.6696\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6664 - accuracy: 0.7180 - val_loss: 0.6911 - val_accuracy: 0.7024\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.6292 - accuracy: 0.7336 - val_loss: 0.6884 - val_accuracy: 0.7173\n",
      "Epoch 17/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6136 - accuracy: 0.7440 - val_loss: 0.6739 - val_accuracy: 0.6994\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6054 - accuracy: 0.7381 - val_loss: 0.6594 - val_accuracy: 0.7113\n",
      "Epoch 19/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5651 - accuracy: 0.7716 - val_loss: 0.6566 - val_accuracy: 0.7143\n",
      "Epoch 20/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5685 - accuracy: 0.7723 - val_loss: 0.6015 - val_accuracy: 0.7411\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5367 - accuracy: 0.7827 - val_loss: 0.6240 - val_accuracy: 0.7232\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5281 - accuracy: 0.7976 - val_loss: 0.5933 - val_accuracy: 0.7411\n",
      "Epoch 23/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.8222 - val_loss: 0.5938 - val_accuracy: 0.7619\n",
      "Epoch 24/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.8251 - val_loss: 0.5915 - val_accuracy: 0.7679\n",
      "Epoch 25/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.8251 - val_loss: 0.6290 - val_accuracy: 0.7381\n",
      "Epoch 26/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.8281 - val_loss: 0.5750 - val_accuracy: 0.7679\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.8356 - val_loss: 0.5673 - val_accuracy: 0.7649\n",
      "Epoch 28/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4080 - accuracy: 0.8482 - val_loss: 0.6071 - val_accuracy: 0.7292\n",
      "Epoch 29/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4057 - accuracy: 0.8490 - val_loss: 0.5994 - val_accuracy: 0.7470\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.8497 - val_loss: 0.5588 - val_accuracy: 0.7589\n",
      "Epoch 31/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3726 - accuracy: 0.8728 - val_loss: 0.5396 - val_accuracy: 0.7649\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3826 - accuracy: 0.8601 - val_loss: 0.5396 - val_accuracy: 0.7827\n",
      "Epoch 33/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3793 - accuracy: 0.8579 - val_loss: 0.5480 - val_accuracy: 0.7679\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3436 - accuracy: 0.8698 - val_loss: 0.5368 - val_accuracy: 0.7679\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3291 - accuracy: 0.8862 - val_loss: 0.5471 - val_accuracy: 0.7857\n",
      "Epoch 36/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3315 - accuracy: 0.8869 - val_loss: 0.4901 - val_accuracy: 0.7857\n",
      "Epoch 37/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3068 - accuracy: 0.8958 - val_loss: 0.4890 - val_accuracy: 0.7946\n",
      "Epoch 38/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3047 - accuracy: 0.8899 - val_loss: 0.4953 - val_accuracy: 0.7857\n",
      "Epoch 39/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2889 - accuracy: 0.8981 - val_loss: 0.5254 - val_accuracy: 0.7857\n",
      "Epoch 40/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2725 - accuracy: 0.9025 - val_loss: 0.5611 - val_accuracy: 0.7857\n",
      "Epoch 41/50\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2734 - accuracy: 0.9137 - val_loss: 0.5186 - val_accuracy: 0.7887\n",
      "Epoch 42/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2564 - accuracy: 0.9115 - val_loss: 0.4913 - val_accuracy: 0.8006\n",
      "Epoch 43/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2410 - accuracy: 0.9211 - val_loss: 0.4521 - val_accuracy: 0.8214\n",
      "Epoch 44/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2617 - accuracy: 0.9115 - val_loss: 0.4598 - val_accuracy: 0.8155\n",
      "Epoch 45/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2342 - accuracy: 0.9226 - val_loss: 0.4712 - val_accuracy: 0.8125\n",
      "Epoch 46/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2240 - accuracy: 0.9308 - val_loss: 0.4592 - val_accuracy: 0.8185\n",
      "Epoch 47/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2610 - accuracy: 0.9100 - val_loss: 0.4706 - val_accuracy: 0.8065\n",
      "Epoch 48/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2018 - accuracy: 0.9382 - val_loss: 0.4634 - val_accuracy: 0.8095\n",
      "Epoch 49/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9405 - val_loss: 0.5583 - val_accuracy: 0.7976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1771 - accuracy: 0.9531 - val_loss: 0.4993 - val_accuracy: 0.8006\n",
      "test_loss: 0.4493526220321655 \n",
      "test_accuracy: 0.8452380895614624\n"
     ]
    }
   ],
   "source": [
    "# 정규화한 X 모델링과 테스트 trial 4\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (7,7), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "hist = model.fit(X_train_norm, Y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test_norm, Y_test, verbose=0)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")\n",
    "\n",
    "#test_loss: 0.4493526220321655 test_accuracy: 0.8452380895614624"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "456423ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 를 n번 독립시행할때, n 이 충분히 크면 test_accuracy값의 분포는 정규 분포를 따를 것이다.\n",
    "# test_accuracy 가 0.6 이상인 확률을 구해 보자.\n",
    "# 한번의 시행에서 0.6 이상의 test_accuracy가 나왔다고 하여 이모델이 항상 0.6을 넘는다고 생각할 수는 없다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "85cb2566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_42 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 7, 7, 32)          25120     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 64)                18496     \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 44,259\n",
      "Trainable params: 44,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "test_loss: 0.6042587161064148 \n",
      "test_accuracy: 0.776190459728241\n"
     ]
    }
   ],
   "source": [
    "# 정규화한 X 모델링과 테스트 trial 5\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (7,7), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "hist = model.fit(X_train_norm, Y_train, epochs=50, validation_split=0.2, verbose=0)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test_norm, Y_test, verbose=0)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e456b330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.45888757705688477 \n",
      "test_accuracy: 0.8428571224212646\n",
      "test_loss: 0.4329274594783783 \n",
      "test_accuracy: 0.8380952477455139\n",
      "test_loss: 0.4097953140735626 \n",
      "test_accuracy: 0.8523809313774109\n",
      "test_loss: 0.46976277232170105 \n",
      "test_accuracy: 0.8190476298332214\n",
      "test_loss: 0.4304163157939911 \n",
      "test_accuracy: 0.8404762148857117\n",
      "test_loss: 0.4055953025817871 \n",
      "test_accuracy: 0.8619047403335571\n",
      "test_loss: 0.5068597793579102 \n",
      "test_accuracy: 0.8047618865966797\n",
      "test_loss: 0.5226251482963562 \n",
      "test_accuracy: 0.8476190567016602\n",
      "test_loss: 0.46643784642219543 \n",
      "test_accuracy: 0.8452380895614624\n",
      "test_loss: 0.4761861562728882 \n",
      "test_accuracy: 0.8142856955528259\n",
      "test_loss: 0.44347596168518066 \n",
      "test_accuracy: 0.8547618985176086\n",
      "test_loss: 0.6066605448722839 \n",
      "test_accuracy: 0.7404761910438538\n",
      "test_loss: 0.46108731627464294 \n",
      "test_accuracy: 0.8214285969734192\n",
      "test_loss: 0.46538665890693665 \n",
      "test_accuracy: 0.8428571224212646\n",
      "test_loss: 0.3737727105617523 \n",
      "test_accuracy: 0.8595238327980042\n",
      "test_loss: 0.4251616299152374 \n",
      "test_accuracy: 0.8428571224212646\n",
      "test_loss: 0.4669453203678131 \n",
      "test_accuracy: 0.8523809313774109\n",
      "test_loss: 0.6964863538742065 \n",
      "test_accuracy: 0.7095237970352173\n",
      "test_loss: 0.3782573640346527 \n",
      "test_accuracy: 0.8714285492897034\n",
      "test_loss: 0.5171773433685303 \n",
      "test_accuracy: 0.8261904716491699\n",
      "test_loss: 0.45242413878440857 \n",
      "test_accuracy: 0.8333333134651184\n",
      "test_loss: 0.7311984896659851 \n",
      "test_accuracy: 0.7404761910438538\n",
      "test_loss: 0.452518492937088 \n",
      "test_accuracy: 0.8428571224212646\n",
      "test_loss: 0.5084973573684692 \n",
      "test_accuracy: 0.8404762148857117\n",
      "test_loss: 0.4224604368209839 \n",
      "test_accuracy: 0.8500000238418579\n",
      "test_loss: 0.5158257484436035 \n",
      "test_accuracy: 0.8238095045089722\n",
      "test_loss: 0.5203203558921814 \n",
      "test_accuracy: 0.8071428537368774\n",
      "test_loss: 0.5256378650665283 \n",
      "test_accuracy: 0.8071428537368774\n",
      "test_loss: 0.6140490770339966 \n",
      "test_accuracy: 0.7404761910438538\n",
      "test_loss: 0.45924514532089233 \n",
      "test_accuracy: 0.8238095045089722\n",
      "test_loss: 0.4682771563529968 \n",
      "test_accuracy: 0.8500000238418579\n",
      "test_loss: 0.3702058792114258 \n",
      "test_accuracy: 0.8833333253860474\n",
      "test_loss: 0.4072880744934082 \n",
      "test_accuracy: 0.8595238327980042\n",
      "test_loss: 0.48296916484832764 \n",
      "test_accuracy: 0.800000011920929\n",
      "test_loss: 0.3902130126953125 \n",
      "test_accuracy: 0.8666666746139526\n",
      "test_loss: 0.5391668081283569 \n",
      "test_accuracy: 0.8285714387893677\n",
      "test_loss: 0.6391010284423828 \n",
      "test_accuracy: 0.7714285850524902\n",
      "test_loss: 0.576108455657959 \n",
      "test_accuracy: 0.7428571581840515\n",
      "test_loss: 0.49066460132598877 \n",
      "test_accuracy: 0.8166666626930237\n",
      "test_loss: 0.366798996925354 \n",
      "test_accuracy: 0.8809523582458496\n",
      "test_loss: 0.598522961139679 \n",
      "test_accuracy: 0.7833333611488342\n",
      "test_loss: 0.44397255778312683 \n",
      "test_accuracy: 0.8190476298332214\n",
      "test_loss: 0.4313805103302002 \n",
      "test_accuracy: 0.8309524059295654\n",
      "test_loss: 0.48035478591918945 \n",
      "test_accuracy: 0.8190476298332214\n",
      "test_loss: 0.5821133255958557 \n",
      "test_accuracy: 0.7857142686843872\n",
      "test_loss: 0.34629446268081665 \n",
      "test_accuracy: 0.8785714507102966\n",
      "test_loss: 0.738300621509552 \n",
      "test_accuracy: 0.726190447807312\n",
      "test_loss: 0.6152942180633545 \n",
      "test_accuracy: 0.7404761910438538\n",
      "test_loss: 0.546492338180542 \n",
      "test_accuracy: 0.7857142686843872\n",
      "test_loss: 0.4425749182701111 \n",
      "test_accuracy: 0.8261904716491699\n",
      "test_loss: 0.4911353290081024 \n",
      "test_accuracy: 0.8333333134651184\n",
      "test_loss: 0.4428698718547821 \n",
      "test_accuracy: 0.8523809313774109\n",
      "test_loss: 0.5239753127098083 \n",
      "test_accuracy: 0.7690476179122925\n",
      "test_loss: 0.4648621082305908 \n",
      "test_accuracy: 0.8285714387893677\n",
      "test_loss: 0.48544207215309143 \n",
      "test_accuracy: 0.811904788017273\n",
      "test_loss: 0.4324205815792084 \n",
      "test_accuracy: 0.8547618985176086\n",
      "test_loss: 0.4988378882408142 \n",
      "test_accuracy: 0.8023809790611267\n",
      "test_loss: 0.5690889358520508 \n",
      "test_accuracy: 0.8071428537368774\n",
      "test_loss: 0.44610393047332764 \n",
      "test_accuracy: 0.8261904716491699\n",
      "test_loss: 0.49907705187797546 \n",
      "test_accuracy: 0.8166666626930237\n",
      "test_loss: 0.541373610496521 \n",
      "test_accuracy: 0.7833333611488342\n",
      "test_loss: 0.48714515566825867 \n",
      "test_accuracy: 0.7976190447807312\n",
      "test_loss: 0.6609775424003601 \n",
      "test_accuracy: 0.7428571581840515\n",
      "test_loss: 0.47049909830093384 \n",
      "test_accuracy: 0.8309524059295654\n",
      "test_loss: 0.5257144570350647 \n",
      "test_accuracy: 0.8357142806053162\n",
      "test_loss: 0.7371243238449097 \n",
      "test_accuracy: 0.6785714030265808\n",
      "test_loss: 0.45602381229400635 \n",
      "test_accuracy: 0.8333333134651184\n",
      "test_loss: 0.546607255935669 \n",
      "test_accuracy: 0.811904788017273\n",
      "test_loss: 0.45262011885643005 \n",
      "test_accuracy: 0.8357142806053162\n",
      "test_loss: 0.5307815074920654 \n",
      "test_accuracy: 0.7976190447807312\n",
      "test_loss: 0.4773139953613281 \n",
      "test_accuracy: 0.8142856955528259\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_177/153433082.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m                  \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                  metrics=['accuracy'])\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 정규화한 X 모델링과 테스트 trial n =100\n",
    "test_accuracy_list = [] # test_accuracy_list 에 test_accuracy 값 취합\n",
    "for i in range(100):\n",
    "    model=keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "    model.add(keras.layers.MaxPool2D(2,2))\n",
    "    model.add(keras.layers.Conv2D(32, (7,7), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                 loss='sparse_categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    hist = model.fit(X_train_norm, Y_train, epochs=50, validation_split=0.2, verbose=0)\n",
    "\n",
    "    test_loss, test_accuracy = model.evaluate(X_test_norm, Y_test, verbose=0)\n",
    "    print(f\"test_loss: {test_loss} \")\n",
    "    print(f\"test_accuracy: {test_accuracy}\")\n",
    "    test_accuracy_list.append(test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3d32cc25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8428571224212646,\n",
       " 0.8380952477455139,\n",
       " 0.8523809313774109,\n",
       " 0.8190476298332214,\n",
       " 0.8404762148857117,\n",
       " 0.8619047403335571,\n",
       " 0.8047618865966797,\n",
       " 0.8476190567016602,\n",
       " 0.8452380895614624,\n",
       " 0.8142856955528259,\n",
       " 0.8547618985176086,\n",
       " 0.7404761910438538,\n",
       " 0.8214285969734192,\n",
       " 0.8428571224212646,\n",
       " 0.8595238327980042,\n",
       " 0.8428571224212646,\n",
       " 0.8523809313774109,\n",
       " 0.7095237970352173,\n",
       " 0.8714285492897034,\n",
       " 0.8261904716491699,\n",
       " 0.8333333134651184,\n",
       " 0.7404761910438538,\n",
       " 0.8428571224212646,\n",
       " 0.8404762148857117,\n",
       " 0.8500000238418579,\n",
       " 0.8238095045089722,\n",
       " 0.8071428537368774,\n",
       " 0.8071428537368774,\n",
       " 0.7404761910438538,\n",
       " 0.8238095045089722,\n",
       " 0.8500000238418579,\n",
       " 0.8833333253860474,\n",
       " 0.8595238327980042,\n",
       " 0.800000011920929,\n",
       " 0.8666666746139526,\n",
       " 0.8285714387893677,\n",
       " 0.7714285850524902,\n",
       " 0.7428571581840515,\n",
       " 0.8166666626930237,\n",
       " 0.8809523582458496,\n",
       " 0.7833333611488342,\n",
       " 0.8190476298332214,\n",
       " 0.8309524059295654,\n",
       " 0.8190476298332214,\n",
       " 0.7857142686843872,\n",
       " 0.8785714507102966,\n",
       " 0.726190447807312,\n",
       " 0.7404761910438538,\n",
       " 0.7857142686843872,\n",
       " 0.8261904716491699,\n",
       " 0.8333333134651184,\n",
       " 0.8523809313774109,\n",
       " 0.7690476179122925,\n",
       " 0.8285714387893677,\n",
       " 0.811904788017273,\n",
       " 0.8547618985176086,\n",
       " 0.8023809790611267,\n",
       " 0.8071428537368774,\n",
       " 0.8261904716491699,\n",
       " 0.8166666626930237,\n",
       " 0.7833333611488342,\n",
       " 0.7976190447807312,\n",
       " 0.7428571581840515,\n",
       " 0.8309524059295654,\n",
       " 0.8357142806053162,\n",
       " 0.6785714030265808,\n",
       " 0.8333333134651184,\n",
       " 0.811904788017273,\n",
       " 0.8357142806053162,\n",
       " 0.7976190447807312,\n",
       " 0.8142856955528259]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9c86c8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8162977863365496 0.041845974259723036\n"
     ]
    }
   ],
   "source": [
    "# 평균과 표준편차\n",
    "import numpy as np\n",
    "print(np.mean(test_accuracy_list), np.std(test_accuracy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e5bada3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 독립시행의 확률밀도함수가 정규 분포를 따른다고 가정하였을 때, n=100 n 이 충분히 크므로\n",
    "# 모델의 test_accuracy의 확률 밀도 함수\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (6, 3)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['lines.linewidth'] = 5\n",
    "\n",
    "mu1, sigma1 = 0.8162977863365496, 0.041845974259723036\n",
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "y1 = (1 / np.sqrt(2 * np.pi * sigma1**2)) * np.exp(-(x-mu1)**2 / (2 * sigma1**2))\n",
    "\n",
    "plt.plot(x, y1, alpha=0.7)\n",
    "\n",
    "plt.xlabel('test_accuracy')\n",
    "plt.ylabel('P(x)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c0fa6721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델의 test_accuracy의 누적 분포함수\n",
    "from scipy.special import erf\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (6, 3)\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['lines.linewidth'] = 5\n",
    "\n",
    "mu1, sigma1 = 0.8162977863365496, 0.041845974259723036\n",
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "y_cum = 0.5 * (1 + erf((x - mu1)/(np.sqrt(2 * sigma1**2))))\n",
    "\n",
    "plt.plot(x, y_cum, alpha=0.7)\n",
    "\n",
    "plt.xlabel('test_accuracy')\n",
    "plt.ylabel('f(x)')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d0c4c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "# 평균 = 0.8162977863365496, 표준편차 = 0.041845974259723036인 정규분포 객체 정의\n",
    "norm_dist = scipy.stats.norm(loc = 0.8162977863365496, scale = 0.041845974259723036)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e3a08a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1773596632215724e-07"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x = 0.6까지의 누적분포함수 값 탐색\n",
    "norm_dist.cdf(0.6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3708f8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999998822640337"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x > 0.6 확률\n",
    "1-norm_dist.cdf(0.6) # 약 99.999% 확률로 위 모델의 test_accuracy는 60%(0.6) 보다 큰값을 나타낸다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
