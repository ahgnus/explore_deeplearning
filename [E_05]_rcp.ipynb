{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b30d96b",
   "metadata": {},
   "source": [
    "# 가위바위보\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "726f62d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "1.22.2\n"
     ]
    }
   ],
   "source": [
    "# 사용할 라이브러리 버전확인\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e08970d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 준비\n",
    "# 클래스 분류된 사진 찍기\n",
    "# https://teachablemachine.withgoogle.com/\n",
    "\n",
    "# 디렉토리 만들기 \n",
    "#(-p 옵션을 주어 생성하게되면 자동으로 중간단계의 디렉토리를 생성하면서 그 하위 디렉토리를 생성)\n",
    "# $ mkdir -p ~/aiffel/rock_scissor_paper/scissor\n",
    "# $ mkdir -p ~/aiffel/rock_scissor_paper/rock\n",
    "# $ mkdir -p ~/aiffel/rock_scissor_paper/paper\n",
    "\n",
    "# $ ls -l ~/aiffel/rock_scissor_paper\n",
    "\n",
    "#클라우드 이미지 압축해제\n",
    "#(찍은 사진이 압축파일(zip)로 저장되어있다)\n",
    "# # 원하는 디렉토리로 이동 =3\n",
    "# $ cd  ~/aiffel/rock_scissor_paper/rock\n",
    "\n",
    "# # 압축 해제 명령어 : unzip <파일명>.zip\n",
    "# $ unzip rock.zip\n",
    "\n",
    "# # 가위, 보에 대해서도 똑같이 실행!\n",
    "# $ cd  ~/aiffel/rock_scissor_paper/scissor\n",
    "# $ unzip scissor.zip\n",
    "\n",
    "# $ cd  ~/aiffel/rock_scissor_paper/paper\n",
    "# $ unzip paper.zip\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c11f002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "#받은 이미지의 크기가 \"224X224\"\n",
    "# \"28X28\" 로 만들어야함 손글씨의 경우 이미지 2828이었기때문에\n",
    "\n",
    "#라이브러리 불러오기 PIL\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85b1240a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "#이미지 사이즈 변환\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3abfcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위와 보도 이미지 사이즈변경 28X28으로\n",
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4143fb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지 사이즈 변경 28X28으로\n",
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dac47fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# load_data() 함수로 임의의 사진 데이터 읽어오기\n",
    "# 3개의 클리스 가위 :0 ,바위:1, 보:2로 라벨링\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29d610ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#이미지 불러보기\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "848dd217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#딥러닝 네트워크 설계하기\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "#input_shape 입력값 RGB (28, 28, 3) \n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "#가위 바위 보 3가지로 최종 분기\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a443a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 2s 19ms/step - loss: 32.1718 - accuracy: 0.3000\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 9.2616 - accuracy: 0.3433\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 4.3155 - accuracy: 0.3567\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 2.1627 - accuracy: 0.3700\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 1.3290 - accuracy: 0.4333\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.2160 - accuracy: 0.5133\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.9973 - accuracy: 0.5467\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 1.0310 - accuracy: 0.5400\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.8940 - accuracy: 0.5633\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.7889 - accuracy: 0.6233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62d44331f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 딥러닝 네트워크 학습시키기\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec14d8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "보 이미지 resize 완료!\n",
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "#Test 이미지로 Test하기\n",
    "#Test 이미지 data 준비\n",
    "\n",
    "# 224X224 data 28X28 사이즈 이미지로로 만들기\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93de9244",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 5.4516 - accuracy: 0.3233\n",
      "test_loss: 5.451635837554932 \n",
      "test_accuracy: 0.3233333230018616\n"
     ]
    }
   ],
   "source": [
    "#test_accuracy 측정\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3447702e",
   "metadata": {},
   "source": [
    "# 더 좋은 네트워크 만들기\n",
    "\n",
    "- 하이퍼 파라미터 변경하여 딥러닝 네트워크 설계\n",
    "- 층의 깊이와 epoch 수변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03c1894e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 35,875\n",
      "Trainable params: 35,875\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#더 좋은 네트워크 만들기\n",
    "\n",
    "\n",
    "#하이퍼 파라미터 변경하여 딥러닝 네트워크 설계\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "#input_shape 입력값 RGB (28, 28, 3) \n",
    "# 더다양한 입력 이미지의 특징을 살펴봄 16에서 32로 변경\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "#가위 바위 보 3가지로 최종 분기\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a69f2218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 총 파라미터 35,875개 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fc1f352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 1s 29ms/step - loss: 9.6833 - accuracy: 0.3333\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 1.5758 - accuracy: 0.3667\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 1.1247 - accuracy: 0.4933\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 1.1937 - accuracy: 0.5167\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.7744 - accuracy: 0.6367\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.5656 - accuracy: 0.7900\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.4890 - accuracy: 0.8067\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.4786 - accuracy: 0.7900\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.3785 - accuracy: 0.8567\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.3237 - accuracy: 0.8767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62d5598370>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 하기\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff128f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 4.8902 - accuracy: 0.4133\n",
      "test_loss: 4.89018440246582 \n",
      "test_accuracy: 0.41333332657814026\n"
     ]
    }
   ],
   "source": [
    "#test_accuracy 측정\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7ee661f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                12832     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 15,699\n",
      "Trainable params: 15,699\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 1s 18ms/step - loss: 41.5671 - accuracy: 0.3433\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 5.1804 - accuracy: 0.3567\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 2.4524 - accuracy: 0.3967\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.3502 - accuracy: 0.4433\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.3696 - accuracy: 0.5067\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.9768 - accuracy: 0.5533\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.0954 - accuracy: 0.5500\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.8607 - accuracy: 0.5933\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.8171 - accuracy: 0.6167\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.8683 - accuracy: 0.6100\n",
      "10/10 - 0s - loss: 2.4908 - accuracy: 0.4267\n",
      "test_loss: 2.490767478942871 \n",
      "test_accuracy: 0.4266666769981384\n"
     ]
    }
   ],
   "source": [
    "#더 좋은 네트워크 만들기\n",
    "\n",
    "\n",
    "#하이퍼 파라미터 변경하여 딥러닝 네트워크 설계 (16, 16)으로 변경\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "#input_shape 입력값 RGB (28, 28, 3) \n",
    "# 더다양한 입력 이미지의 특징을 살펴봄 16에서 32로 변경\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "#가위 바위 보 3가지로 최종 분기\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 학습\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "#test_accuracy 측정\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cf4dc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 1s 21ms/step - loss: 46.9636 - accuracy: 0.3067\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 11.1706 - accuracy: 0.3367\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 4.0623 - accuracy: 0.3333\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 2.7595 - accuracy: 0.3167\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 1.8441 - accuracy: 0.4567\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.6138 - accuracy: 0.4433\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 1.1838 - accuracy: 0.5500\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 1.0089 - accuracy: 0.6067\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.8827 - accuracy: 0.6533\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.9356 - accuracy: 0.6467\n",
      "10/10 - 0s - loss: 5.8867 - accuracy: 0.3900\n",
      "test_loss: 5.886699676513672 \n",
      "test_accuracy: 0.38999998569488525\n"
     ]
    }
   ],
   "source": [
    "#  0.52 accuracy를 보인 원래의 하이퍼파라미터(16.32) 에서 epoch 수 조정\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "#input_shape 입력값 RGB (28, 28, 3) \n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "#가위 바위 보 3가지로 최종 분기\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 학습\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "#test_accuracy 측정\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7271544a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 1s 21ms/step - loss: 9.8256 - accuracy: 0.3700\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 2.1046 - accuracy: 0.4000\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 1.0988 - accuracy: 0.4533\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.8864 - accuracy: 0.5867\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.8133 - accuracy: 0.6467\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.7061 - accuracy: 0.7000\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6126 - accuracy: 0.7567\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.5448 - accuracy: 0.8267\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.4720 - accuracy: 0.8567\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.4337 - accuracy: 0.9100\n",
      "10/10 - 0s - loss: 4.0871 - accuracy: 0.3200\n",
      "test_loss: 4.087060451507568 \n",
      "test_accuracy: 0.3199999928474426\n"
     ]
    }
   ],
   "source": [
    "# 16, 32, 32\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "#input_shape 입력값 RGB (28, 28, 3) \n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "#가위 바위 보 3가지로 최종 분기\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 학습\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "#test_accuracy 측정\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adadafb4",
   "metadata": {},
   "source": [
    "### 층의 깊이를 조절하는 것만으로는 accuracy를 높이는데 한계가 있어 보인다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf463dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 20, 20, 16)        3904      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 10, 10, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 6, 6, 32)          12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                9248      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 26,083\n",
      "Trainable params: 26,083\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 1s 34ms/step - loss: 18.2136 - accuracy: 0.3400\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 2.0915 - accuracy: 0.3867\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 1.1947 - accuracy: 0.3867\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.8170 - accuracy: 0.5967\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.5484 - accuracy: 0.7867\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 0.4774 - accuracy: 0.8000\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.3523 - accuracy: 0.8933\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 34ms/step - loss: 0.3006 - accuracy: 0.9167\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.3054 - accuracy: 0.8933\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.2096 - accuracy: 0.9533\n",
      "10/10 - 0s - loss: 4.8324 - accuracy: 0.4400\n",
      "test_loss: 4.832432746887207 \n",
      "test_accuracy: 0.4399999976158142\n"
     ]
    }
   ],
   "source": [
    "# 커널 크기 변경 9X9\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (9,9), activation='relu', input_shape=(28,28,3)))\n",
    "#input_shape 입력값 RGB (28, 28, 3) \n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (5,5), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "#가위 바위 보 3가지로 최종 분기\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 학습\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "#test_accuracy 측정\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1a0d352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 24, 24, 16)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 8, 8, 32)          12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                8208      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 22,307\n",
      "Trainable params: 22,307\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "10/10 [==============================] - 1s 24ms/step - loss: 17.9425 - accuracy: 0.3233\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 2.2379 - accuracy: 0.3433\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 1.4165 - accuracy: 0.4167\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 1.0786 - accuracy: 0.5233\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.8668 - accuracy: 0.6133\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.9334 - accuracy: 0.6233\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.9205 - accuracy: 0.6167\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.7276 - accuracy: 0.6767\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.6952 - accuracy: 0.6800\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.6661 - accuracy: 0.7033\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.6658 - accuracy: 0.6867\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.5427 - accuracy: 0.7467\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4832 - accuracy: 0.8133\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.4487 - accuracy: 0.8233\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.4306 - accuracy: 0.8400\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.3985 - accuracy: 0.8533\n",
      "Epoch 17/30\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.3642 - accuracy: 0.8667\n",
      "Epoch 18/30\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 0.3502 - accuracy: 0.8700\n",
      "Epoch 19/30\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.3325 - accuracy: 0.8800\n",
      "Epoch 20/30\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.3065 - accuracy: 0.8933\n",
      "Epoch 21/30\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.2719 - accuracy: 0.9233\n",
      "Epoch 22/30\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.2433 - accuracy: 0.9300\n",
      "Epoch 23/30\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.2226 - accuracy: 0.9400\n",
      "Epoch 24/30\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.1823 - accuracy: 0.9633\n",
      "Epoch 25/30\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.2130 - accuracy: 0.9400\n",
      "Epoch 26/30\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.1950 - accuracy: 0.9367\n",
      "Epoch 27/30\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.1639 - accuracy: 0.9500\n",
      "Epoch 28/30\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.1579 - accuracy: 0.9533\n",
      "Epoch 29/30\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.1334 - accuracy: 0.9733\n",
      "Epoch 30/30\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.1106 - accuracy: 0.9800\n",
      "10/10 - 0s - loss: 4.6910 - accuracy: 0.3333\n",
      "test_loss: 4.691019058227539 \n",
      "test_accuracy: 0.3333333432674408\n"
     ]
    }
   ],
   "source": [
    "# 커널 크기 변경  5X5\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (5,5), activation='relu', input_shape=(28,28,3)))\n",
    "\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (5,5), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 학습\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=30)\n",
    "\n",
    "#test_accuracy 측정\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d73e62d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 22, 22, 16)        2368      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 11, 11, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 9, 9, 32)          4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                8208      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 15,267\n",
      "Trainable params: 15,267\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "10/10 [==============================] - 1s 26ms/step - loss: 10.7969 - accuracy: 0.3233\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 2.5498 - accuracy: 0.3433\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 1.8961 - accuracy: 0.3667\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 1.4937 - accuracy: 0.4133\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 1.2147 - accuracy: 0.4967\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 1.0335 - accuracy: 0.5400\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.7607 - accuracy: 0.6767\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.5642 - accuracy: 0.7633\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.4444 - accuracy: 0.8167\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.4058 - accuracy: 0.8400\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.5409 - accuracy: 0.7533\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.3597 - accuracy: 0.8400\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.2748 - accuracy: 0.9000\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.2885 - accuracy: 0.9000\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.2381 - accuracy: 0.9333\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.2050 - accuracy: 0.9300\n",
      "Epoch 17/30\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.3284 - accuracy: 0.8767\n",
      "Epoch 18/30\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.3065 - accuracy: 0.8967\n",
      "Epoch 19/30\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.1806 - accuracy: 0.9600\n",
      "Epoch 20/30\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.1282 - accuracy: 0.9733\n",
      "Epoch 21/30\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.1142 - accuracy: 0.9733\n",
      "Epoch 22/30\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.1124 - accuracy: 0.9800\n",
      "Epoch 23/30\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.1048 - accuracy: 0.9800\n",
      "Epoch 24/30\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0830 - accuracy: 0.9800\n",
      "Epoch 25/30\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0710 - accuracy: 0.9933\n",
      "Epoch 26/30\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0655 - accuracy: 0.9867\n",
      "Epoch 27/30\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0624 - accuracy: 0.9900\n",
      "Epoch 28/30\n",
      "10/10 [==============================] - 0s 26ms/step - loss: 0.0520 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0482 - accuracy: 0.9967\n",
      "Epoch 30/30\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0453 - accuracy: 0.9967\n",
      "10/10 - 0s - loss: 4.8568 - accuracy: 0.3800\n",
      "test_loss: 4.856821537017822 \n",
      "test_accuracy: 0.3799999952316284\n"
     ]
    }
   ],
   "source": [
    "# 커널 크기변경 7X7\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (7,7), activation='relu', input_shape=(28,28,3)))\n",
    "\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 학습\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=30)\n",
    "\n",
    "#test_accuracy 측정\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcbbb5f",
   "metadata": {},
   "source": [
    "###  kernel의 크기 증가\n",
    "- kernel의 크기가(3X3) 너무 작아 유의미한 feature를 잡아내지 못할 수 있음\n",
    "- (5X5)...(9X9)까지 늘려 시험해 보았으나 테스트 정확도에서 유의미한 차이는 보이지 않았다\n",
    "\n",
    "### 학습 Epoch 횟수를 늘려 학습\n",
    "- 일정 횟수(위에서는30)를 넘어가면 학습데이터에 과적합(over-fitted)되어 오히려 test 데이터에 대하여 accracy가 떨어지는 경향을 나타내는 것으로 보임.\n",
    "- 학습 자료의 양 자체가 작고, \n",
    "- 뽑아낼 유의미한 feature의 수가 적은 것으로 판단\n",
    "\n",
    "### kernel의 크기와 Epoch 수를 조절 하여 결과를 확인해 보았으나, 크게 accuracy의 변화는 보이지 않았다.\n",
    "\n",
    "### 제공된 이미지 원본 데이터를 확인\n",
    "- 데이터 자체가 육안으로 보았을 때도 굉장히 불분명하고 질(해상도)이 좋지 않음\n",
    "- 직접 사진을 찍은 가위, 바위 보 손모양 사진을 가지고 진행시도(가위,바위,보 각각 700장씩 2100장)\n",
    "- 기존의 제공된 데이터셋의 수(300)가 적어서 다양한 feature뽑아 내고, 효과적으로 구분할 수 있는 학습이 되지 않았을 것 같은 점도 고려\n",
    "- 데이터셋의 사진 수를 7배 늘려 학습을 진행.\n",
    "- 데이터의 over-fitting 을 극복하기 위해 다양한 모양과 위치의 손 사진과 7명의 각기다른 사람의 손 사진을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a271c1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700  images to be resized.\n",
      "700  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "700  images to be resized.\n",
      "700  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "700  images to be resized.\n",
      "700  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 직접 찍은 데이터 불러오기\n",
    "\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# 28X28 사이즈로 변환\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/N_data/scissors\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/N_data/rock\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/N_data/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16101b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 2100 입니다.\n",
      "x_train shape: (2100, 28, 28, 3)\n",
      "y_train shape: (2100,)\n"
     ]
    }
   ],
   "source": [
    "# 각 가위, 바위, 보 에 0,1,2 label을 붙여 load_data로 불러오기\n",
    "\n",
    "def load_data(img_path, number_of_data=2100):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissors/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/N_data\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc6c08a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 이미지 확인\n",
    "\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38583bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "66/66 [==============================] - 2s 22ms/step - loss: 6.2523 - accuracy: 0.3562\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 1s 22ms/step - loss: 1.4304 - accuracy: 0.4310\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 1s 22ms/step - loss: 1.1670 - accuracy: 0.4886\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 1s 22ms/step - loss: 1.1863 - accuracy: 0.5024\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 1s 22ms/step - loss: 1.0360 - accuracy: 0.5310\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 1s 22ms/step - loss: 0.9389 - accuracy: 0.5795\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 1s 22ms/step - loss: 0.9184 - accuracy: 0.5876\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 1s 22ms/step - loss: 0.9037 - accuracy: 0.5952\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 1s 22ms/step - loss: 0.8291 - accuracy: 0.6329\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 1s 23ms/step - loss: 0.8016 - accuracy: 0.6424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62df4364f0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모델 설계및 학습\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0855acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 22, 22, 16)        2368      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 11, 11, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 5, 5, 32)          25120     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 31,715\n",
      "Trainable params: 31,715\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 4.0602 - accuracy: 0.3995\n",
      "Epoch 2/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0799 - accuracy: 0.4686\n",
      "Epoch 3/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.9511 - accuracy: 0.5619\n",
      "Epoch 4/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.8839 - accuracy: 0.5933\n",
      "Epoch 5/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.8053 - accuracy: 0.6505\n",
      "Epoch 6/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.7373 - accuracy: 0.6843\n",
      "Epoch 7/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.8929 - accuracy: 0.5900\n",
      "Epoch 8/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.8984 - accuracy: 0.5895\n",
      "Epoch 9/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.8322 - accuracy: 0.6257\n",
      "Epoch 10/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.7531 - accuracy: 0.6657\n",
      "Epoch 11/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.8143 - accuracy: 0.6410\n",
      "Epoch 12/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.7711 - accuracy: 0.6571\n",
      "Epoch 13/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.7654 - accuracy: 0.6762\n",
      "Epoch 14/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.7024 - accuracy: 0.7033\n",
      "Epoch 15/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.6456 - accuracy: 0.7181\n",
      "Epoch 16/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.6211 - accuracy: 0.7452\n",
      "Epoch 17/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.6301 - accuracy: 0.7338\n",
      "Epoch 18/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.5882 - accuracy: 0.7652\n",
      "Epoch 19/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.5917 - accuracy: 0.7610\n",
      "Epoch 20/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.5462 - accuracy: 0.7762\n",
      "Epoch 21/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.5414 - accuracy: 0.7800\n",
      "Epoch 22/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.4800 - accuracy: 0.8167\n",
      "Epoch 23/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.5012 - accuracy: 0.8019\n",
      "Epoch 24/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.5809 - accuracy: 0.7576\n",
      "Epoch 25/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.4719 - accuracy: 0.8138\n",
      "Epoch 26/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.4820 - accuracy: 0.8095\n",
      "Epoch 27/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.4985 - accuracy: 0.7990\n",
      "Epoch 28/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.4285 - accuracy: 0.8290\n",
      "Epoch 29/50\n",
      "66/66 [==============================] - 2s 32ms/step - loss: 0.5135 - accuracy: 0.7857\n",
      "Epoch 30/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.4424 - accuracy: 0.8214\n",
      "Epoch 31/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.3805 - accuracy: 0.8457\n",
      "Epoch 32/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.3869 - accuracy: 0.8486\n",
      "Epoch 33/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.3566 - accuracy: 0.8576\n",
      "Epoch 34/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.3418 - accuracy: 0.8710\n",
      "Epoch 35/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.3120 - accuracy: 0.8857\n",
      "Epoch 36/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.3219 - accuracy: 0.8776\n",
      "Epoch 37/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.3250 - accuracy: 0.8748\n",
      "Epoch 38/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.3340 - accuracy: 0.8724\n",
      "Epoch 39/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.3468 - accuracy: 0.8590\n",
      "Epoch 40/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.2876 - accuracy: 0.8910\n",
      "Epoch 41/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.3644 - accuracy: 0.8590\n",
      "Epoch 42/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.2818 - accuracy: 0.8876\n",
      "Epoch 43/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.2635 - accuracy: 0.8990\n",
      "Epoch 44/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.2551 - accuracy: 0.9062\n",
      "Epoch 45/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.2681 - accuracy: 0.9000\n",
      "Epoch 46/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.2945 - accuracy: 0.8819\n",
      "Epoch 47/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.2537 - accuracy: 0.8967\n",
      "Epoch 48/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.3415 - accuracy: 0.8719\n",
      "Epoch 49/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.2872 - accuracy: 0.8957\n",
      "Epoch 50/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.2149 - accuracy: 0.9224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62df33e700>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 accuracy 가 0.3333 매우 떨어져 학습 하이퍼 파리미터 조정\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (7,7), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (7,7), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "672d219b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 5.1639 - accuracy: 0.4467\n",
      "test_loss: 5.163941860198975 \n",
      "test_accuracy: 0.4466666579246521\n"
     ]
    }
   ],
   "source": [
    "# 학습 accuracy 0.86\n",
    "# kernel 7X7로 설정 \n",
    "# 이미지크기 28X28 에서 손모양이 차지하는 공간이 약 10X10 내부에 들어 가는 것으로 보임\n",
    "# 하위 epoch 에서 accuracy가  steady-state에 도달 되는 것으로 보아 50이면 충분\n",
    "# 뽑아낼 feature 수와 분류 알고리즘 복잡도 조정\n",
    "# 그전에 test로 accuracy 확인 해봄 이모델으로\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")\n",
    "\n",
    "# accuracy 0.43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "034d21e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 22, 22, 32)        4736      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 5, 5, 32)          50208     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 57,059\n",
      "Trainable params: 57,059\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 2.6695 - accuracy: 0.3490\n",
      "Epoch 2/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 1.0571 - accuracy: 0.4371\n",
      "Epoch 3/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 1.0413 - accuracy: 0.4443\n",
      "Epoch 4/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 1.0020 - accuracy: 0.4952\n",
      "Epoch 5/50\n",
      "66/66 [==============================] - 3s 43ms/step - loss: 1.0037 - accuracy: 0.5152\n",
      "Epoch 6/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.9474 - accuracy: 0.5600\n",
      "Epoch 7/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.9475 - accuracy: 0.5395\n",
      "Epoch 8/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.9593 - accuracy: 0.5438\n",
      "Epoch 9/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 1.0037 - accuracy: 0.4795\n",
      "Epoch 10/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 1.0990 - accuracy: 0.3371\n",
      "Epoch 11/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.9127 - accuracy: 0.5567\n",
      "Epoch 12/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.8590 - accuracy: 0.6090\n",
      "Epoch 13/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.8215 - accuracy: 0.6267\n",
      "Epoch 14/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.8043 - accuracy: 0.6524\n",
      "Epoch 15/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.7609 - accuracy: 0.6714\n",
      "Epoch 16/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.7801 - accuracy: 0.6581\n",
      "Epoch 17/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.7938 - accuracy: 0.6429\n",
      "Epoch 18/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.7359 - accuracy: 0.6671\n",
      "Epoch 19/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.7263 - accuracy: 0.6776\n",
      "Epoch 20/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.6400 - accuracy: 0.7162\n",
      "Epoch 21/50\n",
      "66/66 [==============================] - 3s 43ms/step - loss: 0.6080 - accuracy: 0.7476\n",
      "Epoch 22/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.6135 - accuracy: 0.7405\n",
      "Epoch 23/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.5605 - accuracy: 0.7681\n",
      "Epoch 24/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.5833 - accuracy: 0.7610\n",
      "Epoch 25/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.5528 - accuracy: 0.7676\n",
      "Epoch 26/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.5296 - accuracy: 0.7810\n",
      "Epoch 27/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.5114 - accuracy: 0.7924\n",
      "Epoch 28/50\n",
      "66/66 [==============================] - 3s 44ms/step - loss: 0.4953 - accuracy: 0.8071\n",
      "Epoch 29/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.4780 - accuracy: 0.8057\n",
      "Epoch 30/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.5920 - accuracy: 0.7486\n",
      "Epoch 31/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.5170 - accuracy: 0.7914\n",
      "Epoch 32/50\n",
      "66/66 [==============================] - 3s 43ms/step - loss: 0.4130 - accuracy: 0.8452\n",
      "Epoch 33/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.5517 - accuracy: 0.7700\n",
      "Epoch 34/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.4347 - accuracy: 0.8238\n",
      "Epoch 35/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.4240 - accuracy: 0.8314\n",
      "Epoch 36/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.3888 - accuracy: 0.8543\n",
      "Epoch 37/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.3841 - accuracy: 0.8462\n",
      "Epoch 38/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.4441 - accuracy: 0.8333\n",
      "Epoch 39/50\n",
      "66/66 [==============================] - 3s 43ms/step - loss: 0.4090 - accuracy: 0.8319\n",
      "Epoch 40/50\n",
      "66/66 [==============================] - 3s 43ms/step - loss: 0.3696 - accuracy: 0.8486\n",
      "Epoch 41/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.3630 - accuracy: 0.8576\n",
      "Epoch 42/50\n",
      "66/66 [==============================] - 3s 43ms/step - loss: 0.3661 - accuracy: 0.8576\n",
      "Epoch 43/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.3295 - accuracy: 0.8795\n",
      "Epoch 44/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.4049 - accuracy: 0.8357\n",
      "Epoch 45/50\n",
      "66/66 [==============================] - 3s 43ms/step - loss: 0.3578 - accuracy: 0.8624\n",
      "Epoch 46/50\n",
      "66/66 [==============================] - 3s 43ms/step - loss: 0.3341 - accuracy: 0.8633\n",
      "Epoch 47/50\n",
      "66/66 [==============================] - 3s 42ms/step - loss: 0.4225 - accuracy: 0.8276\n",
      "Epoch 48/50\n",
      "66/66 [==============================] - 3s 43ms/step - loss: 0.3677 - accuracy: 0.8529\n",
      "Epoch 49/50\n",
      "66/66 [==============================] - 3s 43ms/step - loss: 0.3507 - accuracy: 0.8533\n",
      "Epoch 50/50\n",
      "66/66 [==============================] - 3s 43ms/step - loss: 0.2685 - accuracy: 0.8919\n",
      "10/10 - 0s - loss: 6.6742 - accuracy: 0.4167\n",
      "test_loss: 6.674233913421631 \n",
      "test_accuracy: 0.4166666567325592\n"
     ]
    }
   ],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (7,7), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (7,7), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=50)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")\n",
    "\n",
    "# test accuracy 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "197655e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 20, 20, 8)         1952      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 10, 10, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 2, 2, 16)          10384     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 1, 1, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 12,659\n",
      "Trainable params: 12,659\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 2.8065 - accuracy: 0.3110\n",
      "Epoch 2/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3333\n",
      "Epoch 3/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3333\n",
      "Epoch 4/50\n",
      "66/66 [==============================] - 2s 32ms/step - loss: 1.0987 - accuracy: 0.3238\n",
      "Epoch 5/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0986 - accuracy: 0.3224\n",
      "Epoch 6/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3210\n",
      "Epoch 7/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3333\n",
      "Epoch 8/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3276\n",
      "Epoch 9/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0986 - accuracy: 0.3290\n",
      "Epoch 10/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3248\n",
      "Epoch 11/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3181\n",
      "Epoch 12/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3262\n",
      "Epoch 13/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0988 - accuracy: 0.3200\n",
      "Epoch 14/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3286\n",
      "Epoch 15/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3105\n",
      "Epoch 16/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3214\n",
      "Epoch 17/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3090\n",
      "Epoch 18/50\n",
      "66/66 [==============================] - 2s 32ms/step - loss: 1.0987 - accuracy: 0.3295\n",
      "Epoch 19/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3362\n",
      "Epoch 20/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3333\n",
      "Epoch 21/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3119\n",
      "Epoch 22/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3310\n",
      "Epoch 23/50\n",
      "66/66 [==============================] - 2s 32ms/step - loss: 1.0987 - accuracy: 0.3257\n",
      "Epoch 24/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3243\n",
      "Epoch 25/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3143\n",
      "Epoch 26/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0988 - accuracy: 0.3114\n",
      "Epoch 27/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3181\n",
      "Epoch 28/50\n",
      "66/66 [==============================] - 2s 33ms/step - loss: 1.0987 - accuracy: 0.3319\n",
      "Epoch 29/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3133\n",
      "Epoch 30/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3090\n",
      "Epoch 31/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3333\n",
      "Epoch 32/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3319\n",
      "Epoch 33/50\n",
      "66/66 [==============================] - 2s 32ms/step - loss: 1.0989 - accuracy: 0.3333\n",
      "Epoch 34/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3295\n",
      "Epoch 35/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3290\n",
      "Epoch 36/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3119\n",
      "Epoch 37/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3190\n",
      "Epoch 38/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3157\n",
      "Epoch 39/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3210\n",
      "Epoch 40/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0986 - accuracy: 0.3333\n",
      "Epoch 41/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3329\n",
      "Epoch 42/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3267\n",
      "Epoch 43/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3286\n",
      "Epoch 44/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3171\n",
      "Epoch 45/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3110\n",
      "Epoch 46/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3243\n",
      "Epoch 47/50\n",
      "66/66 [==============================] - 2s 32ms/step - loss: 1.0987 - accuracy: 0.3171\n",
      "Epoch 48/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0988 - accuracy: 0.3119\n",
      "Epoch 49/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3200\n",
      "Epoch 50/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0987 - accuracy: 0.3133\n",
      "10/10 - 0s - loss: 1.1114 - accuracy: 0.2633\n",
      "test_loss: 1.1114096641540527 \n",
      "test_accuracy: 0.2633333206176758\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼 파라미터 변경 (8, 16, 16) 커널 9X9 epoch= 50\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(8, (9,9), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(16, (9,9), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=50)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9eb063f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 22, 22, 16)        2368      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 11, 11, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 5, 5, 32)          25120     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 35,939\n",
      "Trainable params: 35,939\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 3.1095 - accuracy: 0.3557\n",
      "Epoch 2/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0790 - accuracy: 0.4448\n",
      "Epoch 3/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 1.0264 - accuracy: 0.4981\n",
      "Epoch 4/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 1.0287 - accuracy: 0.4843\n",
      "Epoch 5/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.9891 - accuracy: 0.5124\n",
      "Epoch 6/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.9751 - accuracy: 0.5348\n",
      "Epoch 7/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.9073 - accuracy: 0.5771\n",
      "Epoch 8/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.8467 - accuracy: 0.6133\n",
      "Epoch 9/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.8359 - accuracy: 0.6348\n",
      "Epoch 10/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.8264 - accuracy: 0.6314\n",
      "Epoch 11/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.7257 - accuracy: 0.6800\n",
      "Epoch 12/50\n",
      "66/66 [==============================] - 2s 32ms/step - loss: 0.7451 - accuracy: 0.6833\n",
      "Epoch 13/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.7685 - accuracy: 0.6667\n",
      "Epoch 14/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.7355 - accuracy: 0.6757\n",
      "Epoch 15/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.6756 - accuracy: 0.6995\n",
      "Epoch 16/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.6846 - accuracy: 0.7048\n",
      "Epoch 17/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.6397 - accuracy: 0.7357\n",
      "Epoch 18/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.5707 - accuracy: 0.7643\n",
      "Epoch 19/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.6358 - accuracy: 0.7286\n",
      "Epoch 20/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.5833 - accuracy: 0.7571\n",
      "Epoch 21/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.5451 - accuracy: 0.7733\n",
      "Epoch 22/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.5765 - accuracy: 0.7690\n",
      "Epoch 23/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.5158 - accuracy: 0.7919\n",
      "Epoch 24/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.5122 - accuracy: 0.7895\n",
      "Epoch 25/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.4785 - accuracy: 0.8019\n",
      "Epoch 26/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.4715 - accuracy: 0.8081\n",
      "Epoch 27/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.4583 - accuracy: 0.8257\n",
      "Epoch 28/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.5282 - accuracy: 0.7810\n",
      "Epoch 29/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.4939 - accuracy: 0.7986\n",
      "Epoch 30/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.4448 - accuracy: 0.8205\n",
      "Epoch 31/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.4389 - accuracy: 0.8167\n",
      "Epoch 32/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.4676 - accuracy: 0.8067\n",
      "Epoch 33/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.4252 - accuracy: 0.8329\n",
      "Epoch 34/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.4369 - accuracy: 0.8219\n",
      "Epoch 35/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.4791 - accuracy: 0.8086\n",
      "Epoch 36/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.4828 - accuracy: 0.8057\n",
      "Epoch 37/50\n",
      "66/66 [==============================] - 2s 32ms/step - loss: 0.4012 - accuracy: 0.8395\n",
      "Epoch 38/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.3622 - accuracy: 0.8571\n",
      "Epoch 39/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.3858 - accuracy: 0.8476\n",
      "Epoch 40/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.3876 - accuracy: 0.8462\n",
      "Epoch 41/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.3155 - accuracy: 0.8752\n",
      "Epoch 42/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.2862 - accuracy: 0.8962\n",
      "Epoch 43/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.3155 - accuracy: 0.8795\n",
      "Epoch 44/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.3401 - accuracy: 0.8719\n",
      "Epoch 45/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.2947 - accuracy: 0.8810\n",
      "Epoch 46/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.3051 - accuracy: 0.8833\n",
      "Epoch 47/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.3323 - accuracy: 0.8776\n",
      "Epoch 48/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.2788 - accuracy: 0.8886\n",
      "Epoch 49/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.2685 - accuracy: 0.8910\n",
      "Epoch 50/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.2587 - accuracy: 0.9000\n",
      "10/10 - 0s - loss: 4.3341 - accuracy: 0.3433\n",
      "test_loss: 4.334127426147461 \n",
      "test_accuracy: 0.34333333373069763\n"
     ]
    }
   ],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (7,7), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (7,7), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=50)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "deb42ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_26 (Conv2D)           (None, 22, 22, 16)        2368      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 11, 11, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 5, 5, 32)          25120     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 35,939\n",
      "Trainable params: 35,939\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "66/66 [==============================] - 3s 31ms/step - loss: 2.8576 - accuracy: 0.3467\n",
      "Epoch 2/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0554 - accuracy: 0.4533\n",
      "Epoch 3/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.9357 - accuracy: 0.5486\n",
      "Epoch 4/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 1.0736 - accuracy: 0.3838\n",
      "Epoch 5/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 1.0530 - accuracy: 0.4219\n",
      "Epoch 6/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0774 - accuracy: 0.3895\n",
      "Epoch 7/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0407 - accuracy: 0.4433\n",
      "Epoch 8/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 1.0208 - accuracy: 0.4695\n",
      "Epoch 9/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 1.0037 - accuracy: 0.4724\n",
      "Epoch 10/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.9142 - accuracy: 0.5424\n",
      "Epoch 11/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 1.0343 - accuracy: 0.4262\n",
      "Epoch 12/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.8706 - accuracy: 0.5829\n",
      "Epoch 13/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.8597 - accuracy: 0.6043\n",
      "Epoch 14/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.7380 - accuracy: 0.6762\n",
      "Epoch 15/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.7154 - accuracy: 0.6771\n",
      "Epoch 16/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.7192 - accuracy: 0.6686\n",
      "Epoch 17/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.6890 - accuracy: 0.7005\n",
      "Epoch 18/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.7305 - accuracy: 0.6781\n",
      "Epoch 19/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.5880 - accuracy: 0.7495\n",
      "Epoch 20/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.6340 - accuracy: 0.7190\n",
      "Epoch 21/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.5917 - accuracy: 0.7476\n",
      "Epoch 22/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.5060 - accuracy: 0.7962\n",
      "Epoch 23/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.5014 - accuracy: 0.7924\n",
      "Epoch 24/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.4708 - accuracy: 0.8043\n",
      "Epoch 25/50\n",
      "66/66 [==============================] - 2s 33ms/step - loss: 0.4635 - accuracy: 0.8052\n",
      "Epoch 26/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.4095 - accuracy: 0.8343\n",
      "Epoch 27/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.3506 - accuracy: 0.8624\n",
      "Epoch 28/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.3729 - accuracy: 0.8524\n",
      "Epoch 29/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.3249 - accuracy: 0.8724\n",
      "Epoch 30/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.2999 - accuracy: 0.8833\n",
      "Epoch 31/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.3416 - accuracy: 0.8714\n",
      "Epoch 32/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.3070 - accuracy: 0.8814\n",
      "Epoch 33/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.2968 - accuracy: 0.8829\n",
      "Epoch 34/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.2326 - accuracy: 0.9138\n",
      "Epoch 35/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.2590 - accuracy: 0.8986\n",
      "Epoch 36/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.2613 - accuracy: 0.8990\n",
      "Epoch 37/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.2376 - accuracy: 0.9110\n",
      "Epoch 38/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.3250 - accuracy: 0.8714\n",
      "Epoch 39/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.3008 - accuracy: 0.8871\n",
      "Epoch 40/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.1914 - accuracy: 0.9271\n",
      "Epoch 41/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.3425 - accuracy: 0.8624\n",
      "Epoch 42/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.2717 - accuracy: 0.8838\n",
      "Epoch 43/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.1699 - accuracy: 0.9414\n",
      "Epoch 44/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.1442 - accuracy: 0.9471\n",
      "Epoch 45/50\n",
      "66/66 [==============================] - 2s 32ms/step - loss: 0.1320 - accuracy: 0.9505\n",
      "Epoch 46/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.1235 - accuracy: 0.9619\n",
      "Epoch 47/50\n",
      "66/66 [==============================] - 2s 30ms/step - loss: 0.1220 - accuracy: 0.9562\n",
      "Epoch 48/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.1701 - accuracy: 0.9343\n",
      "Epoch 49/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.1280 - accuracy: 0.9510\n",
      "Epoch 50/50\n",
      "66/66 [==============================] - 2s 31ms/step - loss: 0.0981 - accuracy: 0.9719\n",
      "10/10 - 0s - loss: 7.3881 - accuracy: 0.2800\n",
      "test_loss: 7.388120174407959 \n",
      "test_accuracy: 0.2800000011920929\n"
     ]
    }
   ],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (7,7), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (7,7), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=50)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc82e88",
   "metadata": {},
   "source": [
    "### 데이터 셋의 양을 증가 시켜 학습했지만, 오히려 제공된 test sample 에 대한 accuracy 가 떨어졌다.\n",
    "- 범용적인 가위바위보 이미지 분류에 대한 모델 학습이 이루어 지지 않았다. (원하는 정도의 accuray 달성 못함)\n",
    "- 2100장의 데이터셋자체중 일부(20%)를 test셋으로 설정, 2100장의 이미지 데이터 모집단 안에서 accuracy 측정\n",
    "- (일종의 validation 느낌)\n",
    "- 데이터의 over-fitting 을 극복하기 위해 정규화를 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "417d5156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn 의 트레인 테스트 스플릿 모듈을 이용해 데이터 셋 분리\n",
    "# 대문자 X Y 로 할당\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=17 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b54bd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 7, 7, 32)          25120     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 64)                18496     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 44,259\n",
      "Trainable params: 44,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "42/42 [==============================] - 2s 37ms/step - loss: 6.8868 - accuracy: 0.3296 - val_loss: 1.8436 - val_accuracy: 0.3542\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.5653 - accuracy: 0.4062 - val_loss: 1.9084 - val_accuracy: 0.4196\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.4911 - accuracy: 0.4249 - val_loss: 1.8074 - val_accuracy: 0.3690\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.1778 - accuracy: 0.4762 - val_loss: 1.1459 - val_accuracy: 0.5357\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1704 - accuracy: 0.4918 - val_loss: 1.3847 - val_accuracy: 0.4196\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0773 - accuracy: 0.5022 - val_loss: 1.0052 - val_accuracy: 0.5417\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9427 - accuracy: 0.5588 - val_loss: 0.9183 - val_accuracy: 0.5833\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.8584 - accuracy: 0.6049 - val_loss: 0.9794 - val_accuracy: 0.6012\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8522 - accuracy: 0.6101 - val_loss: 0.9633 - val_accuracy: 0.5625\n",
      "Epoch 10/50\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.8133 - accuracy: 0.6295 - val_loss: 0.8486 - val_accuracy: 0.6190\n",
      "Epoch 11/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7601 - accuracy: 0.6525 - val_loss: 0.9066 - val_accuracy: 0.5833\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7589 - accuracy: 0.6533 - val_loss: 0.7954 - val_accuracy: 0.6250\n",
      "Epoch 13/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7006 - accuracy: 0.6964 - val_loss: 0.7950 - val_accuracy: 0.6339\n",
      "Epoch 14/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7102 - accuracy: 0.6860 - val_loss: 0.7995 - val_accuracy: 0.6310\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6623 - accuracy: 0.7195 - val_loss: 0.7742 - val_accuracy: 0.6399\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6421 - accuracy: 0.7277 - val_loss: 0.7941 - val_accuracy: 0.6458\n",
      "Epoch 17/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6600 - accuracy: 0.7150 - val_loss: 0.8082 - val_accuracy: 0.6637\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.6286 - accuracy: 0.7336 - val_loss: 0.7632 - val_accuracy: 0.6518\n",
      "Epoch 19/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6264 - accuracy: 0.7507 - val_loss: 0.7724 - val_accuracy: 0.6429\n",
      "Epoch 20/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6535 - accuracy: 0.7225 - val_loss: 0.8031 - val_accuracy: 0.6250\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5918 - accuracy: 0.7507 - val_loss: 0.7713 - val_accuracy: 0.6369\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6324 - accuracy: 0.7240 - val_loss: 0.7675 - val_accuracy: 0.6637\n",
      "Epoch 23/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5740 - accuracy: 0.7634 - val_loss: 0.7665 - val_accuracy: 0.6607\n",
      "Epoch 24/50\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.5571 - accuracy: 0.7701 - val_loss: 0.7652 - val_accuracy: 0.6577\n",
      "Epoch 25/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5250 - accuracy: 0.7902 - val_loss: 0.7135 - val_accuracy: 0.6935\n",
      "Epoch 26/50\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.5098 - accuracy: 0.7991 - val_loss: 0.7258 - val_accuracy: 0.6845\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.4883 - accuracy: 0.8177 - val_loss: 0.6995 - val_accuracy: 0.6756\n",
      "Epoch 28/50\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.4887 - accuracy: 0.8110 - val_loss: 0.7184 - val_accuracy: 0.7054\n",
      "Epoch 29/50\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.4620 - accuracy: 0.8289 - val_loss: 0.6943 - val_accuracy: 0.6875\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.4660 - accuracy: 0.8162 - val_loss: 0.6731 - val_accuracy: 0.7054\n",
      "Epoch 31/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4386 - accuracy: 0.8333 - val_loss: 0.6806 - val_accuracy: 0.7054\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.4295 - accuracy: 0.8326 - val_loss: 0.6623 - val_accuracy: 0.7054\n",
      "Epoch 33/50\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.4063 - accuracy: 0.8542 - val_loss: 0.6594 - val_accuracy: 0.7143\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3787 - accuracy: 0.8683 - val_loss: 0.6823 - val_accuracy: 0.7054\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3528 - accuracy: 0.8847 - val_loss: 0.6642 - val_accuracy: 0.7113\n",
      "Epoch 36/50\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.3721 - accuracy: 0.8720 - val_loss: 0.6674 - val_accuracy: 0.7232\n",
      "Epoch 37/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3681 - accuracy: 0.8616 - val_loss: 0.6893 - val_accuracy: 0.6935\n",
      "Epoch 38/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3507 - accuracy: 0.8757 - val_loss: 0.6523 - val_accuracy: 0.7440\n",
      "Epoch 39/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3518 - accuracy: 0.8705 - val_loss: 0.6700 - val_accuracy: 0.7321\n",
      "Epoch 40/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3101 - accuracy: 0.8929 - val_loss: 0.6287 - val_accuracy: 0.7232\n",
      "Epoch 41/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2946 - accuracy: 0.9055 - val_loss: 0.6479 - val_accuracy: 0.7292\n",
      "Epoch 42/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2687 - accuracy: 0.9144 - val_loss: 0.6338 - val_accuracy: 0.7262\n",
      "Epoch 43/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2731 - accuracy: 0.9159 - val_loss: 0.6609 - val_accuracy: 0.7054\n",
      "Epoch 44/50\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.2679 - accuracy: 0.9211 - val_loss: 0.6832 - val_accuracy: 0.7173\n",
      "Epoch 45/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2719 - accuracy: 0.9107 - val_loss: 0.6903 - val_accuracy: 0.7321\n",
      "Epoch 46/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2486 - accuracy: 0.9204 - val_loss: 0.6683 - val_accuracy: 0.7292\n",
      "Epoch 47/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2351 - accuracy: 0.9263 - val_loss: 0.6477 - val_accuracy: 0.7351\n",
      "Epoch 48/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2247 - accuracy: 0.9323 - val_loss: 0.6371 - val_accuracy: 0.7530\n",
      "Epoch 49/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2154 - accuracy: 0.9375 - val_loss: 0.6979 - val_accuracy: 0.7411\n",
      "Epoch 50/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2042 - accuracy: 0.9368 - val_loss: 0.7122 - val_accuracy: 0.7321\n",
      "14/14 - 0s - loss: 0.7649 - accuracy: 0.7524\n",
      "test_loss: 0.7648659348487854 \n",
      "test_accuracy: 0.7523809671401978\n"
     ]
    }
   ],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (7,7), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=50, validation_split=0.2) #train 내에서 validation 0.2잡아서 수행\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, Y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc53c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss: 0.2042 - accuracy: 0.9368 - val_loss: 0.7122 - val_accuracy: 0.7321\n",
    "# test_loss: 0.7648659348487854 test_accuracy: 0.7523809671401978"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d07e988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# over-fitting 방지하기위해 정규화\n",
    "X_train_norm = X_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "X_test_norm = X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d331f891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_30 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 7, 7, 32)          25120     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 64)                18496     \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 44,259\n",
      "Trainable params: 44,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "42/42 [==============================] - 2s 33ms/step - loss: 1.1021 - accuracy: 0.3333 - val_loss: 1.0978 - val_accuracy: 0.3482\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0999 - accuracy: 0.3237 - val_loss: 1.0984 - val_accuracy: 0.3363\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0988 - accuracy: 0.3170 - val_loss: 1.0984 - val_accuracy: 0.3482\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0987 - accuracy: 0.3162 - val_loss: 1.0984 - val_accuracy: 0.3363\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0987 - accuracy: 0.3259 - val_loss: 1.0984 - val_accuracy: 0.3482\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0990 - accuracy: 0.3356 - val_loss: 1.0983 - val_accuracy: 0.3482\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0988 - accuracy: 0.2946 - val_loss: 1.0986 - val_accuracy: 0.3482\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0985 - val_accuracy: 0.3482\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0988 - accuracy: 0.3147 - val_loss: 1.0985 - val_accuracy: 0.3482\n",
      "Epoch 10/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0985 - val_accuracy: 0.3482\n",
      "Epoch 11/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0984 - val_accuracy: 0.3482\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0988 - accuracy: 0.3103 - val_loss: 1.0985 - val_accuracy: 0.3482\n",
      "Epoch 13/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0985 - val_accuracy: 0.3482\n",
      "Epoch 14/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0984 - val_accuracy: 0.3482\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0985 - val_accuracy: 0.3482\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0988 - accuracy: 0.3170 - val_loss: 1.0986 - val_accuracy: 0.3482\n",
      "Epoch 17/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0985 - val_accuracy: 0.3482\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0985 - val_accuracy: 0.3482\n",
      "Epoch 19/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0985 - val_accuracy: 0.3482\n",
      "Epoch 20/50\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0985 - val_accuracy: 0.3482\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0986 - val_accuracy: 0.3482\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0985 - val_accuracy: 0.3482\n",
      "Epoch 23/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0985 - val_accuracy: 0.3482\n",
      "Epoch 24/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0985 - val_accuracy: 0.3482\n",
      "Epoch 25/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0988 - accuracy: 0.3356 - val_loss: 1.0984 - val_accuracy: 0.3482\n",
      "Epoch 26/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0988 - accuracy: 0.3207 - val_loss: 1.0985 - val_accuracy: 0.3482\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0989 - accuracy: 0.3356 - val_loss: 1.0985 - val_accuracy: 0.3482\n",
      "Epoch 28/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0986 - val_accuracy: 0.3482\n",
      "Epoch 29/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0987 - accuracy: 0.3237 - val_loss: 1.0987 - val_accuracy: 0.3155\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0988 - accuracy: 0.3341 - val_loss: 1.0985 - val_accuracy: 0.3482\n",
      "Epoch 31/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0987 - accuracy: 0.3088 - val_loss: 1.0986 - val_accuracy: 0.3482\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0984 - val_accuracy: 0.3482\n",
      "Epoch 33/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0987 - accuracy: 0.3170 - val_loss: 1.0985 - val_accuracy: 0.3482\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0984 - val_accuracy: 0.3482\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0986 - accuracy: 0.3356 - val_loss: 1.0985 - val_accuracy: 0.3482\n",
      "Epoch 36/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0985 - val_accuracy: 0.3482\n",
      "Epoch 37/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0984 - val_accuracy: 0.3482\n",
      "Epoch 38/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0986 - val_accuracy: 0.3482\n",
      "Epoch 39/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0984 - val_accuracy: 0.3482\n",
      "Epoch 40/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0985 - val_accuracy: 0.3482\n",
      "Epoch 41/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0985 - val_accuracy: 0.3482\n",
      "Epoch 42/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0984 - val_accuracy: 0.3482\n",
      "Epoch 43/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0984 - val_accuracy: 0.3482\n",
      "Epoch 44/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0985 - val_accuracy: 0.3482\n",
      "Epoch 45/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0987 - accuracy: 0.3192 - val_loss: 1.0985 - val_accuracy: 0.3482\n",
      "Epoch 46/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0985 - val_accuracy: 0.3482\n",
      "Epoch 47/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0984 - val_accuracy: 0.3482\n",
      "Epoch 48/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0985 - val_accuracy: 0.3482\n",
      "Epoch 49/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0985 - val_accuracy: 0.3482\n",
      "Epoch 50/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0987 - accuracy: 0.3356 - val_loss: 1.0985 - val_accuracy: 0.3482\n",
      "14/14 - 0s - loss: 1.0988 - accuracy: 0.3143\n",
      "test_loss: 1.0987683534622192 \n",
      "test_accuracy: 0.3142857253551483\n"
     ]
    }
   ],
   "source": [
    "# 정규화한 X\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (7,7), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_norm, Y_train, epochs=50, validation_split=0.2) #train 내에서 validation 0.2잡아서 수행\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test_norm, Y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")\n",
    "\n",
    "#test_loss: 1.0987683534622192 test_accuracy: 0.3142857253551483 모델 학습과정에서 낮은 분포가뽑힘 독립시행이기때문에 여러번시도 필요\n",
    "# 위와같은 결과가 나올 확률은 낮다고 생각 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38c29d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_32 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 7, 7, 32)          25120     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 64)                18496     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 44,259\n",
      "Trainable params: 44,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "42/42 [==============================] - 2s 34ms/step - loss: 6.7941 - accuracy: 0.3460 - val_loss: 1.2734 - val_accuracy: 0.3720\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.2113 - accuracy: 0.4487 - val_loss: 1.2794 - val_accuracy: 0.4256\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.1280 - accuracy: 0.4710 - val_loss: 1.0795 - val_accuracy: 0.5268\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.9636 - accuracy: 0.5528 - val_loss: 0.9757 - val_accuracy: 0.5625\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8129 - accuracy: 0.6414 - val_loss: 0.8701 - val_accuracy: 0.6190\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7766 - accuracy: 0.6644 - val_loss: 0.8277 - val_accuracy: 0.6577\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6724 - accuracy: 0.7061 - val_loss: 0.8243 - val_accuracy: 0.6548\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6558 - accuracy: 0.7277 - val_loss: 0.7723 - val_accuracy: 0.6369\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.5797 - accuracy: 0.7604 - val_loss: 0.7815 - val_accuracy: 0.6637\n",
      "Epoch 10/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.5646 - accuracy: 0.7679 - val_loss: 0.8302 - val_accuracy: 0.6310\n",
      "Epoch 11/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5271 - accuracy: 0.7909 - val_loss: 0.7084 - val_accuracy: 0.6756\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5096 - accuracy: 0.7857 - val_loss: 0.6863 - val_accuracy: 0.7083\n",
      "Epoch 13/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4717 - accuracy: 0.8207 - val_loss: 0.7444 - val_accuracy: 0.6875\n",
      "Epoch 14/50\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.4184 - accuracy: 0.8363 - val_loss: 0.7012 - val_accuracy: 0.7054\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4037 - accuracy: 0.8415 - val_loss: 0.7532 - val_accuracy: 0.6875\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3911 - accuracy: 0.8490 - val_loss: 0.6735 - val_accuracy: 0.7262\n",
      "Epoch 17/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3641 - accuracy: 0.8728 - val_loss: 0.6643 - val_accuracy: 0.7381\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3400 - accuracy: 0.8713 - val_loss: 0.6956 - val_accuracy: 0.7321\n",
      "Epoch 19/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3164 - accuracy: 0.8854 - val_loss: 0.6895 - val_accuracy: 0.7054\n",
      "Epoch 20/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2839 - accuracy: 0.8988 - val_loss: 0.6606 - val_accuracy: 0.7560\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2473 - accuracy: 0.9174 - val_loss: 0.6059 - val_accuracy: 0.7679\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2221 - accuracy: 0.9375 - val_loss: 0.7839 - val_accuracy: 0.6905\n",
      "Epoch 23/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2489 - accuracy: 0.9159 - val_loss: 0.7018 - val_accuracy: 0.7232\n",
      "Epoch 24/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2005 - accuracy: 0.9442 - val_loss: 0.6156 - val_accuracy: 0.7589\n",
      "Epoch 25/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2064 - accuracy: 0.9308 - val_loss: 0.6680 - val_accuracy: 0.7292\n",
      "Epoch 26/50\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.1826 - accuracy: 0.9382 - val_loss: 0.6879 - val_accuracy: 0.7619\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1556 - accuracy: 0.9501 - val_loss: 0.6785 - val_accuracy: 0.7619\n",
      "Epoch 28/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1426 - accuracy: 0.9606 - val_loss: 0.6743 - val_accuracy: 0.7530\n",
      "Epoch 29/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1571 - accuracy: 0.9472 - val_loss: 0.6408 - val_accuracy: 0.7619\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1326 - accuracy: 0.9643 - val_loss: 0.7183 - val_accuracy: 0.7470\n",
      "Epoch 31/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1178 - accuracy: 0.9702 - val_loss: 0.6931 - val_accuracy: 0.7768\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1086 - accuracy: 0.9732 - val_loss: 0.6813 - val_accuracy: 0.7708\n",
      "Epoch 33/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1312 - accuracy: 0.9650 - val_loss: 0.7239 - val_accuracy: 0.7560\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0973 - accuracy: 0.9747 - val_loss: 0.6762 - val_accuracy: 0.7649\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0782 - accuracy: 0.9859 - val_loss: 0.6986 - val_accuracy: 0.7768\n",
      "Epoch 36/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0609 - accuracy: 0.9896 - val_loss: 0.7021 - val_accuracy: 0.7738\n",
      "Epoch 37/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0636 - accuracy: 0.9896 - val_loss: 0.7468 - val_accuracy: 0.7887\n",
      "Epoch 38/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0487 - accuracy: 0.9970 - val_loss: 0.7433 - val_accuracy: 0.7768\n",
      "Epoch 39/50\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.0403 - accuracy: 0.9948 - val_loss: 0.7575 - val_accuracy: 0.7649\n",
      "Epoch 40/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0392 - accuracy: 0.9955 - val_loss: 0.7226 - val_accuracy: 0.7887\n",
      "Epoch 41/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0307 - accuracy: 0.9985 - val_loss: 0.7337 - val_accuracy: 0.7798\n",
      "Epoch 42/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0284 - accuracy: 0.9985 - val_loss: 0.7647 - val_accuracy: 0.7917\n",
      "Epoch 43/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0262 - accuracy: 0.9993 - val_loss: 0.7492 - val_accuracy: 0.7857\n",
      "Epoch 44/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.8074 - val_accuracy: 0.7798\n",
      "Epoch 45/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.7335 - val_accuracy: 0.7917\n",
      "Epoch 46/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0176 - accuracy: 0.9993 - val_loss: 0.8443 - val_accuracy: 0.7946\n",
      "Epoch 47/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0159 - accuracy: 0.9993 - val_loss: 0.7794 - val_accuracy: 0.7976\n",
      "Epoch 48/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.8081 - val_accuracy: 0.7946\n",
      "Epoch 49/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.8313 - val_accuracy: 0.7768\n",
      "Epoch 50/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.7956 - val_accuracy: 0.7887\n",
      "14/14 - 0s - loss: 0.9327 - accuracy: 0.7857\n",
      "test_loss: 0.9326665997505188 \n",
      "test_accuracy: 0.7857142686843872\n"
     ]
    }
   ],
   "source": [
    "# 정규화 하지 않은 X  trial 2\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (7,7), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=50, validation_split=0.2) #train 내에서 validation 0.2잡아서 수행\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, Y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")\n",
    "\n",
    "#test_loss: 0.9326665997505188 test_accuracy: 0.7857142686843872"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "20b291cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_34 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 7, 7, 32)          25120     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 64)                18496     \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 44,259\n",
      "Trainable params: 44,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "42/42 [==============================] - 2s 35ms/step - loss: 1.1045 - accuracy: 0.3385 - val_loss: 1.0961 - val_accuracy: 0.3482\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0976 - accuracy: 0.3415 - val_loss: 1.0946 - val_accuracy: 0.3482\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0867 - accuracy: 0.4345 - val_loss: 1.0801 - val_accuracy: 0.4196\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0672 - accuracy: 0.4442 - val_loss: 1.0473 - val_accuracy: 0.4524\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0400 - accuracy: 0.4940 - val_loss: 1.0230 - val_accuracy: 0.4851\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9971 - accuracy: 0.5253 - val_loss: 0.9749 - val_accuracy: 0.5268\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9466 - accuracy: 0.5632 - val_loss: 0.9189 - val_accuracy: 0.5625\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.8963 - accuracy: 0.5885 - val_loss: 0.8787 - val_accuracy: 0.5893\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8690 - accuracy: 0.6019 - val_loss: 0.8821 - val_accuracy: 0.5952\n",
      "Epoch 10/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.8395 - accuracy: 0.6176 - val_loss: 0.8300 - val_accuracy: 0.6042\n",
      "Epoch 11/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8322 - accuracy: 0.6228 - val_loss: 0.8487 - val_accuracy: 0.6161\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7991 - accuracy: 0.6548 - val_loss: 0.8053 - val_accuracy: 0.6101\n",
      "Epoch 13/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7788 - accuracy: 0.6555 - val_loss: 0.8652 - val_accuracy: 0.6101\n",
      "Epoch 14/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7768 - accuracy: 0.6600 - val_loss: 0.7938 - val_accuracy: 0.6101\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7464 - accuracy: 0.6756 - val_loss: 0.7764 - val_accuracy: 0.6280\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7474 - accuracy: 0.6667 - val_loss: 0.7817 - val_accuracy: 0.6042\n",
      "Epoch 17/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7157 - accuracy: 0.6949 - val_loss: 0.7752 - val_accuracy: 0.6161\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7026 - accuracy: 0.6949 - val_loss: 0.7936 - val_accuracy: 0.6518\n",
      "Epoch 19/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7082 - accuracy: 0.6935 - val_loss: 0.7564 - val_accuracy: 0.6310\n",
      "Epoch 20/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6813 - accuracy: 0.7202 - val_loss: 0.7186 - val_accuracy: 0.6905\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6629 - accuracy: 0.7217 - val_loss: 0.7092 - val_accuracy: 0.6696\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6431 - accuracy: 0.7433 - val_loss: 0.6745 - val_accuracy: 0.7054\n",
      "Epoch 23/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6328 - accuracy: 0.7374 - val_loss: 0.7397 - val_accuracy: 0.6815\n",
      "Epoch 24/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6188 - accuracy: 0.7478 - val_loss: 0.6389 - val_accuracy: 0.7292\n",
      "Epoch 25/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5907 - accuracy: 0.7664 - val_loss: 0.6373 - val_accuracy: 0.7173\n",
      "Epoch 26/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5744 - accuracy: 0.7812 - val_loss: 0.6277 - val_accuracy: 0.7321\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.5725 - accuracy: 0.7768 - val_loss: 0.6373 - val_accuracy: 0.7351\n",
      "Epoch 28/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.5520 - accuracy: 0.7924 - val_loss: 0.6101 - val_accuracy: 0.7173\n",
      "Epoch 29/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.5309 - accuracy: 0.8013 - val_loss: 0.6351 - val_accuracy: 0.7232\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5211 - accuracy: 0.7939 - val_loss: 0.5986 - val_accuracy: 0.7619\n",
      "Epoch 31/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5122 - accuracy: 0.8065 - val_loss: 0.5719 - val_accuracy: 0.7768\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4907 - accuracy: 0.8162 - val_loss: 0.6630 - val_accuracy: 0.7292\n",
      "Epoch 33/50\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.4779 - accuracy: 0.8296 - val_loss: 0.6565 - val_accuracy: 0.7143\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4813 - accuracy: 0.8274 - val_loss: 0.5760 - val_accuracy: 0.7708\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.4684 - accuracy: 0.8192 - val_loss: 0.5630 - val_accuracy: 0.7827\n",
      "Epoch 36/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.4298 - accuracy: 0.8415 - val_loss: 0.5755 - val_accuracy: 0.7560\n",
      "Epoch 37/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.4199 - accuracy: 0.8542 - val_loss: 0.5544 - val_accuracy: 0.7857\n",
      "Epoch 38/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.4178 - accuracy: 0.8452 - val_loss: 0.6541 - val_accuracy: 0.7411\n",
      "Epoch 39/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.4011 - accuracy: 0.8512 - val_loss: 0.5231 - val_accuracy: 0.8065\n",
      "Epoch 40/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3843 - accuracy: 0.8624 - val_loss: 0.5424 - val_accuracy: 0.7619\n",
      "Epoch 41/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3691 - accuracy: 0.8668 - val_loss: 0.5311 - val_accuracy: 0.7946\n",
      "Epoch 42/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3703 - accuracy: 0.8661 - val_loss: 0.5063 - val_accuracy: 0.8065\n",
      "Epoch 43/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3623 - accuracy: 0.8653 - val_loss: 0.4889 - val_accuracy: 0.8036\n",
      "Epoch 44/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.3391 - accuracy: 0.8772 - val_loss: 0.4938 - val_accuracy: 0.8185\n",
      "Epoch 45/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3358 - accuracy: 0.8713 - val_loss: 0.5128 - val_accuracy: 0.8036\n",
      "Epoch 46/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.3198 - accuracy: 0.8854 - val_loss: 0.5216 - val_accuracy: 0.7946\n",
      "Epoch 47/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.3105 - accuracy: 0.8765 - val_loss: 0.5243 - val_accuracy: 0.7917\n",
      "Epoch 48/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3153 - accuracy: 0.8839 - val_loss: 0.4959 - val_accuracy: 0.8125\n",
      "Epoch 49/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3168 - accuracy: 0.8847 - val_loss: 0.5348 - val_accuracy: 0.7887\n",
      "Epoch 50/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2910 - accuracy: 0.8951 - val_loss: 0.4805 - val_accuracy: 0.8274\n",
      "14/14 - 0s - loss: 0.5437 - accuracy: 0.8119\n",
      "test_loss: 0.5436578392982483 \n",
      "test_accuracy: 0.811904788017273\n"
     ]
    }
   ],
   "source": [
    "# 정규화한 X 모델링과 테스트 trial 2\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (7,7), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_norm, Y_train, epochs=50, validation_split=0.2) #train 내에서 validation 0.2잡아서 수행\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test_norm, Y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f88cab4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_39 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 7, 7, 32)          25120     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 64)                18496     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 44,259\n",
      "Trainable params: 44,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "42/42 [==============================] - 2s 34ms/step - loss: 1.0978 - accuracy: 0.3564 - val_loss: 1.0928 - val_accuracy: 0.3155\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0655 - accuracy: 0.4464 - val_loss: 1.0606 - val_accuracy: 0.3661\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0282 - accuracy: 0.4807 - val_loss: 0.9783 - val_accuracy: 0.5149\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9791 - accuracy: 0.5179 - val_loss: 0.9534 - val_accuracy: 0.5119\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.9352 - accuracy: 0.5528 - val_loss: 0.9230 - val_accuracy: 0.5744\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.9125 - accuracy: 0.5848 - val_loss: 0.9260 - val_accuracy: 0.6012\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.8720 - accuracy: 0.6079 - val_loss: 0.8749 - val_accuracy: 0.6161\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8482 - accuracy: 0.6332 - val_loss: 0.8140 - val_accuracy: 0.6310\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.8136 - accuracy: 0.6302 - val_loss: 0.7913 - val_accuracy: 0.6518\n",
      "Epoch 10/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8082 - accuracy: 0.6376 - val_loss: 0.7837 - val_accuracy: 0.6339\n",
      "Epoch 11/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7682 - accuracy: 0.6518 - val_loss: 0.7565 - val_accuracy: 0.6458\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7399 - accuracy: 0.6555 - val_loss: 0.7635 - val_accuracy: 0.6131\n",
      "Epoch 13/50\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.7521 - accuracy: 0.6652 - val_loss: 0.7881 - val_accuracy: 0.6429\n",
      "Epoch 14/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7412 - accuracy: 0.6905 - val_loss: 0.7168 - val_accuracy: 0.6994\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7112 - accuracy: 0.6912 - val_loss: 0.7300 - val_accuracy: 0.6964\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6795 - accuracy: 0.7121 - val_loss: 0.6940 - val_accuracy: 0.6875\n",
      "Epoch 17/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6745 - accuracy: 0.7254 - val_loss: 0.7054 - val_accuracy: 0.6756\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6571 - accuracy: 0.7217 - val_loss: 0.6854 - val_accuracy: 0.6845\n",
      "Epoch 19/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6306 - accuracy: 0.7463 - val_loss: 0.6506 - val_accuracy: 0.7143\n",
      "Epoch 20/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6071 - accuracy: 0.7567 - val_loss: 0.6622 - val_accuracy: 0.6994\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.5870 - accuracy: 0.7641 - val_loss: 0.6464 - val_accuracy: 0.7083\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5710 - accuracy: 0.7731 - val_loss: 0.6118 - val_accuracy: 0.7440\n",
      "Epoch 23/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.5545 - accuracy: 0.7760 - val_loss: 0.6506 - val_accuracy: 0.7024\n",
      "Epoch 24/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5593 - accuracy: 0.7716 - val_loss: 0.6547 - val_accuracy: 0.6875\n",
      "Epoch 25/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.5414 - accuracy: 0.7798 - val_loss: 0.6152 - val_accuracy: 0.7262\n",
      "Epoch 26/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.5020 - accuracy: 0.7946 - val_loss: 0.5825 - val_accuracy: 0.7708\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.4708 - accuracy: 0.8118 - val_loss: 0.5610 - val_accuracy: 0.7232\n",
      "Epoch 28/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.4646 - accuracy: 0.8289 - val_loss: 0.5714 - val_accuracy: 0.7321\n",
      "Epoch 29/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4521 - accuracy: 0.8229 - val_loss: 0.5746 - val_accuracy: 0.7589\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4572 - accuracy: 0.8118 - val_loss: 0.5495 - val_accuracy: 0.7560\n",
      "Epoch 31/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.4310 - accuracy: 0.8341 - val_loss: 0.5259 - val_accuracy: 0.7679\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.4043 - accuracy: 0.8519 - val_loss: 0.5439 - val_accuracy: 0.7679\n",
      "Epoch 33/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3959 - accuracy: 0.8557 - val_loss: 0.5220 - val_accuracy: 0.7887\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3776 - accuracy: 0.8557 - val_loss: 0.5192 - val_accuracy: 0.8006\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.3637 - accuracy: 0.8676 - val_loss: 0.5091 - val_accuracy: 0.8065\n",
      "Epoch 36/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.3419 - accuracy: 0.8772 - val_loss: 0.5164 - val_accuracy: 0.7946\n",
      "Epoch 37/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3374 - accuracy: 0.8810 - val_loss: 0.5128 - val_accuracy: 0.8125\n",
      "Epoch 38/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.3035 - accuracy: 0.8973 - val_loss: 0.4658 - val_accuracy: 0.8333\n",
      "Epoch 39/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2980 - accuracy: 0.8936 - val_loss: 0.4506 - val_accuracy: 0.8274\n",
      "Epoch 40/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2771 - accuracy: 0.9167 - val_loss: 0.4729 - val_accuracy: 0.8244\n",
      "Epoch 41/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2815 - accuracy: 0.9025 - val_loss: 0.4573 - val_accuracy: 0.8333\n",
      "Epoch 42/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2509 - accuracy: 0.9196 - val_loss: 0.4480 - val_accuracy: 0.8185\n",
      "Epoch 43/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2657 - accuracy: 0.9070 - val_loss: 0.4936 - val_accuracy: 0.8185\n",
      "Epoch 44/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2419 - accuracy: 0.9286 - val_loss: 0.4495 - val_accuracy: 0.8304\n",
      "Epoch 45/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2489 - accuracy: 0.9204 - val_loss: 0.5495 - val_accuracy: 0.8095\n",
      "Epoch 46/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2421 - accuracy: 0.9204 - val_loss: 0.4494 - val_accuracy: 0.8185\n",
      "Epoch 47/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2239 - accuracy: 0.9301 - val_loss: 0.5007 - val_accuracy: 0.7798\n",
      "Epoch 48/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2143 - accuracy: 0.9301 - val_loss: 0.4219 - val_accuracy: 0.8363\n",
      "Epoch 49/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1840 - accuracy: 0.9427 - val_loss: 0.4421 - val_accuracy: 0.8333\n",
      "Epoch 50/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1873 - accuracy: 0.9435 - val_loss: 0.4637 - val_accuracy: 0.8304\n"
     ]
    }
   ],
   "source": [
    "# 정규화한 X 모델링과 테스트 trial 3\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (7,7), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "hist = model.fit(X_train_norm, Y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test_norm, Y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d1f20389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 정규화한 데이터의 epoch 횟수에따른  train test 의 accuracy 와 loss\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "120d7eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_41 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 7, 7, 32)          25120     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 64)                18496     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 44,259\n",
      "Trainable params: 44,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "42/42 [==============================] - 2s 35ms/step - loss: 5.3404 - accuracy: 0.3690 - val_loss: 1.3121 - val_accuracy: 0.4137\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.3609 - accuracy: 0.4085 - val_loss: 1.1077 - val_accuracy: 0.4554\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.1522 - accuracy: 0.4583 - val_loss: 1.0737 - val_accuracy: 0.4524\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 1.0351 - accuracy: 0.4948 - val_loss: 1.0171 - val_accuracy: 0.4940\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.9508 - accuracy: 0.5580 - val_loss: 0.9527 - val_accuracy: 0.5357\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0583 - accuracy: 0.4888 - val_loss: 1.0047 - val_accuracy: 0.5030\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.9330 - accuracy: 0.5714 - val_loss: 0.9780 - val_accuracy: 0.5149\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.8735 - accuracy: 0.6071 - val_loss: 0.9210 - val_accuracy: 0.5923\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8414 - accuracy: 0.6057 - val_loss: 0.8664 - val_accuracy: 0.6012\n",
      "Epoch 10/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.8038 - accuracy: 0.6503 - val_loss: 0.9005 - val_accuracy: 0.5893\n",
      "Epoch 11/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7500 - accuracy: 0.6704 - val_loss: 0.8039 - val_accuracy: 0.6399\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7278 - accuracy: 0.6830 - val_loss: 0.8478 - val_accuracy: 0.5923\n",
      "Epoch 13/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.7301 - accuracy: 0.6763 - val_loss: 0.7786 - val_accuracy: 0.6429\n",
      "Epoch 14/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.7053 - accuracy: 0.6949 - val_loss: 0.7604 - val_accuracy: 0.6637\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6583 - accuracy: 0.7188 - val_loss: 0.7289 - val_accuracy: 0.6905\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6681 - accuracy: 0.7128 - val_loss: 0.7582 - val_accuracy: 0.6488\n",
      "Epoch 17/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6256 - accuracy: 0.7396 - val_loss: 0.7048 - val_accuracy: 0.6905\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.6347 - accuracy: 0.7366 - val_loss: 0.7440 - val_accuracy: 0.6815\n",
      "Epoch 19/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6112 - accuracy: 0.7336 - val_loss: 0.7090 - val_accuracy: 0.6875\n",
      "Epoch 20/50\n",
      "42/42 [==============================] - 1s 32ms/step - loss: 0.5725 - accuracy: 0.7626 - val_loss: 0.7739 - val_accuracy: 0.6399\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5585 - accuracy: 0.7604 - val_loss: 0.6705 - val_accuracy: 0.7113\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5320 - accuracy: 0.7939 - val_loss: 0.7312 - val_accuracy: 0.6964\n",
      "Epoch 23/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.5728 - accuracy: 0.7537 - val_loss: 0.7107 - val_accuracy: 0.6905\n",
      "Epoch 24/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.5365 - accuracy: 0.7939 - val_loss: 0.6490 - val_accuracy: 0.7440\n",
      "Epoch 25/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4905 - accuracy: 0.7954 - val_loss: 0.6283 - val_accuracy: 0.7381\n",
      "Epoch 26/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.5050 - accuracy: 0.8006 - val_loss: 0.6722 - val_accuracy: 0.7262\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.4899 - accuracy: 0.8103 - val_loss: 0.6570 - val_accuracy: 0.7113\n",
      "Epoch 28/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4494 - accuracy: 0.8237 - val_loss: 0.6401 - val_accuracy: 0.7321\n",
      "Epoch 29/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4536 - accuracy: 0.8229 - val_loss: 0.6464 - val_accuracy: 0.7500\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4486 - accuracy: 0.8304 - val_loss: 0.6351 - val_accuracy: 0.7292\n",
      "Epoch 31/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4225 - accuracy: 0.8385 - val_loss: 0.6175 - val_accuracy: 0.7470\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3998 - accuracy: 0.8527 - val_loss: 0.6226 - val_accuracy: 0.7440\n",
      "Epoch 33/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.4002 - accuracy: 0.8467 - val_loss: 0.6547 - val_accuracy: 0.7351\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.3889 - accuracy: 0.8624 - val_loss: 0.6293 - val_accuracy: 0.7292\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3664 - accuracy: 0.8609 - val_loss: 0.6041 - val_accuracy: 0.7560\n",
      "Epoch 36/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3539 - accuracy: 0.8765 - val_loss: 0.6349 - val_accuracy: 0.7411\n",
      "Epoch 37/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3754 - accuracy: 0.8527 - val_loss: 0.7658 - val_accuracy: 0.7024\n",
      "Epoch 38/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3508 - accuracy: 0.8676 - val_loss: 0.6831 - val_accuracy: 0.7321\n",
      "Epoch 39/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3832 - accuracy: 0.8683 - val_loss: 0.7392 - val_accuracy: 0.7173\n",
      "Epoch 40/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.3686 - accuracy: 0.8519 - val_loss: 0.7157 - val_accuracy: 0.7262\n",
      "Epoch 41/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.3389 - accuracy: 0.8854 - val_loss: 0.6851 - val_accuracy: 0.7113\n",
      "Epoch 42/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.3325 - accuracy: 0.8743 - val_loss: 0.6573 - val_accuracy: 0.7440\n",
      "Epoch 43/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.3225 - accuracy: 0.8810 - val_loss: 0.7319 - val_accuracy: 0.7411\n",
      "Epoch 44/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2925 - accuracy: 0.9010 - val_loss: 0.6341 - val_accuracy: 0.7351\n",
      "Epoch 45/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2794 - accuracy: 0.9055 - val_loss: 0.6537 - val_accuracy: 0.7649\n",
      "Epoch 46/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2795 - accuracy: 0.9040 - val_loss: 0.7110 - val_accuracy: 0.7530\n",
      "Epoch 47/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2921 - accuracy: 0.9048 - val_loss: 0.7022 - val_accuracy: 0.7351\n",
      "Epoch 48/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2562 - accuracy: 0.9167 - val_loss: 0.7153 - val_accuracy: 0.7202\n",
      "Epoch 49/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2853 - accuracy: 0.8996 - val_loss: 0.7980 - val_accuracy: 0.7351\n",
      "Epoch 50/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2610 - accuracy: 0.9055 - val_loss: 0.7411 - val_accuracy: 0.7321\n",
      "14/14 - 0s - loss: 0.7645 - accuracy: 0.7667\n",
      "test_loss: 0.764460027217865 \n",
      "test_accuracy: 0.7666666507720947\n"
     ]
    }
   ],
   "source": [
    "# 정규화하지 않은 X 모델링과 테스트 trial 3\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (7,7), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "hist = model.fit(X_train, Y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, Y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")\n",
    "\n",
    "#test_loss: 0.764460027217865 test_accuracy: 0.7666666507720947"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ef711838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Accuracy')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f296c997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화 하였을때 over-fitting 이 줄어드는 것을 알수 있었다. (원인 discussion 필요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0cabb89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_43 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 7, 7, 32)          25120     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 64)                18496     \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 44,259\n",
      "Trainable params: 44,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "42/42 [==============================] - 2s 33ms/step - loss: 1.0879 - accuracy: 0.3557 - val_loss: 1.0693 - val_accuracy: 0.3869\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 1.0406 - accuracy: 0.4762 - val_loss: 0.9941 - val_accuracy: 0.4970\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.9670 - accuracy: 0.5320 - val_loss: 0.9561 - val_accuracy: 0.4970\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.9251 - accuracy: 0.5580 - val_loss: 0.8898 - val_accuracy: 0.5714\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.8503 - accuracy: 0.6310 - val_loss: 0.8495 - val_accuracy: 0.6042\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.8289 - accuracy: 0.6153 - val_loss: 0.8104 - val_accuracy: 0.6012\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7698 - accuracy: 0.6615 - val_loss: 0.7781 - val_accuracy: 0.6220\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7769 - accuracy: 0.6540 - val_loss: 0.8016 - val_accuracy: 0.6131\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7338 - accuracy: 0.6719 - val_loss: 0.7489 - val_accuracy: 0.6756\n",
      "Epoch 10/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7081 - accuracy: 0.6994 - val_loss: 0.7977 - val_accuracy: 0.6071\n",
      "Epoch 11/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.7198 - accuracy: 0.7024 - val_loss: 0.7469 - val_accuracy: 0.6756\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.6668 - accuracy: 0.7210 - val_loss: 0.7667 - val_accuracy: 0.6310\n",
      "Epoch 13/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.6347 - accuracy: 0.7455 - val_loss: 0.6763 - val_accuracy: 0.6935\n",
      "Epoch 14/50\n",
      "42/42 [==============================] - 1s 33ms/step - loss: 0.5917 - accuracy: 0.7686 - val_loss: 0.6634 - val_accuracy: 0.7024\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.5648 - accuracy: 0.7790 - val_loss: 0.6429 - val_accuracy: 0.7381\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.5636 - accuracy: 0.7753 - val_loss: 0.6714 - val_accuracy: 0.7083\n",
      "Epoch 17/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.5387 - accuracy: 0.7924 - val_loss: 0.6773 - val_accuracy: 0.7202\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.5047 - accuracy: 0.8103 - val_loss: 0.5825 - val_accuracy: 0.7470\n",
      "Epoch 19/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.4591 - accuracy: 0.8251 - val_loss: 0.5946 - val_accuracy: 0.7708\n",
      "Epoch 20/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.4524 - accuracy: 0.8348 - val_loss: 0.5756 - val_accuracy: 0.7649\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.4031 - accuracy: 0.8586 - val_loss: 0.6438 - val_accuracy: 0.7321\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.3969 - accuracy: 0.8534 - val_loss: 0.5626 - val_accuracy: 0.7798\n",
      "Epoch 23/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.3896 - accuracy: 0.8519 - val_loss: 0.5387 - val_accuracy: 0.7976\n",
      "Epoch 24/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.3495 - accuracy: 0.8728 - val_loss: 0.5715 - val_accuracy: 0.7708\n",
      "Epoch 25/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.3726 - accuracy: 0.8661 - val_loss: 0.5652 - val_accuracy: 0.7560\n",
      "Epoch 26/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.3200 - accuracy: 0.8958 - val_loss: 0.5232 - val_accuracy: 0.8155\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.2876 - accuracy: 0.8996 - val_loss: 0.4981 - val_accuracy: 0.7946\n",
      "Epoch 28/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2877 - accuracy: 0.8966 - val_loss: 0.4465 - val_accuracy: 0.8333\n",
      "Epoch 29/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2467 - accuracy: 0.9182 - val_loss: 0.5114 - val_accuracy: 0.7976\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2322 - accuracy: 0.9234 - val_loss: 0.5381 - val_accuracy: 0.8095\n",
      "Epoch 31/50\n",
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2616 - accuracy: 0.9092 - val_loss: 0.6723 - val_accuracy: 0.7440\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.2159 - accuracy: 0.9286 - val_loss: 0.4685 - val_accuracy: 0.8423\n",
      "Epoch 33/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1970 - accuracy: 0.9435 - val_loss: 0.4583 - val_accuracy: 0.8542\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1899 - accuracy: 0.9405 - val_loss: 0.4823 - val_accuracy: 0.8095\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1804 - accuracy: 0.9382 - val_loss: 0.4678 - val_accuracy: 0.8482\n",
      "Epoch 36/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1665 - accuracy: 0.9479 - val_loss: 0.4309 - val_accuracy: 0.8571\n",
      "Epoch 37/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1337 - accuracy: 0.9658 - val_loss: 0.4433 - val_accuracy: 0.8304\n",
      "Epoch 38/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.1324 - accuracy: 0.9606 - val_loss: 0.4550 - val_accuracy: 0.8512\n",
      "Epoch 39/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1256 - accuracy: 0.9658 - val_loss: 0.4440 - val_accuracy: 0.8482\n",
      "Epoch 40/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1384 - accuracy: 0.9539 - val_loss: 0.5434 - val_accuracy: 0.8393\n",
      "Epoch 41/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1382 - accuracy: 0.9554 - val_loss: 0.4493 - val_accuracy: 0.8571\n",
      "Epoch 42/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.1200 - accuracy: 0.9650 - val_loss: 0.4404 - val_accuracy: 0.8482\n",
      "Epoch 43/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0924 - accuracy: 0.9792 - val_loss: 0.4590 - val_accuracy: 0.8542\n",
      "Epoch 44/50\n",
      "42/42 [==============================] - 1s 31ms/step - loss: 0.0791 - accuracy: 0.9821 - val_loss: 0.4629 - val_accuracy: 0.8512\n",
      "Epoch 45/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0813 - accuracy: 0.9784 - val_loss: 0.4432 - val_accuracy: 0.8631\n",
      "Epoch 46/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0750 - accuracy: 0.9844 - val_loss: 0.4726 - val_accuracy: 0.8631\n",
      "Epoch 47/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0773 - accuracy: 0.9821 - val_loss: 0.4617 - val_accuracy: 0.8690\n",
      "Epoch 48/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0564 - accuracy: 0.9911 - val_loss: 0.4490 - val_accuracy: 0.8631\n",
      "Epoch 49/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0515 - accuracy: 0.9955 - val_loss: 0.5039 - val_accuracy: 0.8601\n",
      "Epoch 50/50\n",
      "42/42 [==============================] - 1s 30ms/step - loss: 0.0483 - accuracy: 0.9918 - val_loss: 0.4851 - val_accuracy: 0.8542\n",
      "test_loss: 0.4613056778907776 \n",
      "test_accuracy: 0.8595238327980042\n"
     ]
    }
   ],
   "source": [
    "# 정규화한 X 모델링과 테스트 trial 4\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (7,7), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "hist = model.fit(X_train_norm, Y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test_norm, Y_test, verbose=0)\n",
    "print(f\"test_loss: {test_loss} \")\n",
    "print(f\"test_accuracy: {test_accuracy}\")\n",
    "\n",
    "#test_loss: 0.4613056778907776 test_accuracy: 0.8595238327980042"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ccd021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 를 n번 독립시행해서 test_accuracy 의 평균과 표준 편차를 구하면 정규 분포를 따를 것이라고 생각한다\n",
    "# test_accuracy 가 0.6 이상인 확률을 구하면 될 것 같다\n",
    "# 한번의 시행에서 0.6 이상의 test_accuracy가 나왔다고 하여 이모델이 항상 0.6을 넘는다고 생각할 수는 없다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
