{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7669629f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f69d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "384bfe06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 197463\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144364</th>\n",
       "      <td>Would you like to come to my party?</td>\n",
       "      <td>Voudrais-tu venir à ma fête ?</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15411</th>\n",
       "      <td>My wife was mad.</td>\n",
       "      <td>Ma femme était folle.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188116</th>\n",
       "      <td>In a town with only one barber, who shaves the...</td>\n",
       "      <td>Dans une ville avec un seul coiffeur pour homm...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138977</th>\n",
       "      <td>Where have you been all afternoon?</td>\n",
       "      <td>Où as-tu été toute l'après-midi ?</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142597</th>\n",
       "      <td>Save it on the external hard drive.</td>\n",
       "      <td>Enregistre-le sur le disque dur externe.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      eng  \\\n",
       "144364                Would you like to come to my party?   \n",
       "15411                                    My wife was mad.   \n",
       "188116  In a town with only one barber, who shaves the...   \n",
       "138977                 Where have you been all afternoon?   \n",
       "142597                Save it on the external hard drive.   \n",
       "\n",
       "                                                      fra  \\\n",
       "144364                      Voudrais-tu venir à ma fête ?   \n",
       "15411                               Ma femme était folle.   \n",
       "188116  Dans une ville avec un seul coiffeur pour homm...   \n",
       "138977                  Où as-tu été toute l'après-midi ?   \n",
       "142597           Enregistre-le sur le disque dur externe.   \n",
       "\n",
       "                                                       cc  \n",
       "144364  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "15411   CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "188116  CC-BY 2.0 (France) Attribution: tatoeba.org #9...  \n",
       "138977  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "142597  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#샘플 데이터 불러옴\n",
    "import os\n",
    "file_path = os.getenv('HOME')+'/aiffel/translator_seq2seq/data/fra.txt'\n",
    "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(5) #샘플 5개 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27aadd93",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15005</th>\n",
       "      <td>It looked awful.</td>\n",
       "      <td>Ça avait l'air atroce.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420</th>\n",
       "      <td>I'm finicky.</td>\n",
       "      <td>Je suis méticuleuse.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>En route !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26151</th>\n",
       "      <td>The tank is empty.</td>\n",
       "      <td>La cuve est vide.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31857</th>\n",
       "      <td>That was very good.</td>\n",
       "      <td>Ce fut très bon.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       eng                     fra\n",
       "15005     It looked awful.  Ça avait l'air atroce.\n",
       "3420          I'm finicky.    Je suis méticuleuse.\n",
       "2                      Go.              En route !\n",
       "26151   The tank is empty.       La cuve est vide.\n",
       "31857  That was very good.        Ce fut très bon."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3번째 열은 불필요하므로 제거하고, 훈련 데이터는 33000개의 샘플로 줄임\n",
    "lines = lines[['eng', 'fra']][:33000] # 33000개 샘플 사용 3000개는 추후 테스트 샘플로 사용\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16212b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20187</th>\n",
       "      <td>Please stay here.</td>\n",
       "      <td>\\t Veuillez rester ici. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Duck!</td>\n",
       "      <td>\\t À terre ! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13198</th>\n",
       "      <td>Behave yourself.</td>\n",
       "      <td>\\t Comporte-toi bien. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go.</td>\n",
       "      <td>\\t Bouge ! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6227</th>\n",
       "      <td>Try it again.</td>\n",
       "      <td>\\t Essaye à nouveau. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     eng                         fra\n",
       "20187  Please stay here.  \\t Veuillez rester ici. \\n\n",
       "26                 Duck!             \\t À terre ! \\n\n",
       "13198   Behave yourself.    \\t Comporte-toi bien. \\n\n",
       "3                    Go.               \\t Bouge ! \\n\n",
       "6227       Try it again.     \\t Essaye à nouveau. \\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰 추가\n",
    "sos_token = '\\t'\n",
    "eos_token = '\\n'\n",
    "lines.fra = lines.fra.apply(lambda x : '\\t '+ x + ' \\n')\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0808ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 데이터 프레임 칼럼을 리스트화\n",
    "eng_list = lines['eng'].to_list()\n",
    "fra_list = lines['fra'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "836d65ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go.', 'Go.', 'Go.', 'Go.', 'Hi.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be952286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 구두점을 단어와 분리\n",
    "import re, string\n",
    "\n",
    "def punc(s): return re.sub(f\"([{string.punctuation}])\", r' \\1 ', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94e556bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_el = [punc(i) for i in eng_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba2d77e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go . ', 'Go . ', 'Go . ', 'Go . ', 'Hi . ']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_el[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07098c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_fl = [punc(i) for i in fra_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ef2859d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\t Va  !  \\n',\n",
       " '\\t Marche .  \\n',\n",
       " '\\t En route  !  \\n',\n",
       " '\\t Bouge  !  \\n',\n",
       " '\\t Salut  !  \\n']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_fl[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdae8bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[29, 1], [29, 1], [29, 1]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 소문자로 바꾸고 띄어쓰기 단위로 토큰화 \n",
    "eng_tokenizer = Tokenizer(char_level=False, filters='', lower =True)   # 단어 단위로 Tokenizer를 생성합니다. 소문자로 바꾸고 필터(구두점제거)\n",
    "eng_tokenizer.fit_on_texts(p_el)               # 33000개의 행을 가진 p_el의 각 요소들에 토큰화를 수행\n",
    "input_text = eng_tokenizer.texts_to_sequences(p_el)    # 단어를 숫자값 인덱스로 변환하여 저장\n",
    "input_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c98f84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 76, 10, 2], [1, 345, 3, 2], [1, 27, 486, 10, 2]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fra_tokenizer = Tokenizer(char_level=False, filters='', lower =True)   # 단어 단위로 Tokenizer를 생성합니다. 소문자로 바꾸고 필터(구두점제거)\n",
    "fra_tokenizer.fit_on_texts(p_fl)               # 33000개의 행을 가진 p_fl의 각 요소들에 토큰화를 수행\n",
    "target_text = fra_tokenizer.texts_to_sequences(p_fl)    # 단어를 숫자값 인덱스로 변환하여 저장\n",
    "target_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b94507c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어장의 크기 : 4713\n",
      "프랑스어 단어장의 크기 : 9467\n"
     ]
    }
   ],
   "source": [
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3434e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 시퀀스의 최대 길이 10\n",
      "프랑스어 시퀀스의 최대 길이 20\n"
     ]
    }
   ],
   "source": [
    "max_eng_seq_len = max([len(line) for line in input_text])\n",
    "max_fra_seq_len = max([len(line) for line in target_text])\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6303d198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n",
      "영어 단어장의 크기 : 4713\n",
      "프랑스어 단어장의 크기 : 9467\n",
      "영어 시퀀스의 최대 길이 10\n",
      "프랑스어 시퀀스의 최대 길이 20\n"
     ]
    }
   ],
   "source": [
    "#전체적인 통계정보를 한꺼번에 출력\n",
    "\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cda2fa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = input_text\n",
    "# 종료 토큰 제거\n",
    "decoder_input = [[ char for char in line if char != fra_tokenizer.word_index[eos_token] ] for line in target_text] \n",
    "# 시작 토큰 제거\n",
    "decoder_target = [[ char for char in line if char != fra_tokenizer.word_index[sos_token] ] for line in target_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1847d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 76, 10], [1, 345, 3], [1, 27, 486, 10]]\n",
      "[[76, 10, 2], [345, 3, 2], [27, 486, 10, 2]]\n"
     ]
    }
   ],
   "source": [
    "print(decoder_input[:3])\n",
    "print(decoder_target[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ac8d292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (33000, 10)\n",
      "프랑스어 입력데이터의 크기(shape) : (33000, 20)\n",
      "프랑스어 출력데이터의 크기(shape) : (33000, 20)\n"
     ]
    }
   ],
   "source": [
    "#데이터의 크기 확인\n",
    "encoder_input = pad_sequences(encoder_input, maxlen = max_eng_seq_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen = max_fra_seq_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen = max_fra_seq_len, padding='post')\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a21a6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29  1  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7e956fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (33000, 10, 4713)\n",
      "프랑스어 입력데이터의 크기(shape) : (33000, 20, 9467)\n",
      "프랑스어 출력데이터의 크기(shape) : (33000, 20, 9467)\n"
     ]
    }
   ],
   "source": [
    "# 벡터화 원핫 인코딩\n",
    "encoder_input = to_categorical(encoder_input)\n",
    "decoder_input = to_categorical(decoder_input)\n",
    "decoder_target = to_categorical(decoder_target)\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1dfe1955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 학습데이터의 크기(shape) : (33000, 10, 4713)\n",
      "프랑스어 학습 입력데이터의 크기(shape) : (33000, 20, 9467)\n",
      "프랑스어 학습 출력데이터의 크기(shape) : (33000, 20, 9467)\n"
     ]
    }
   ],
   "source": [
    "# validation 생성 3000건 나머지 학습데이터로\n",
    "n_of_val = 3000\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('영어 학습데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 학습 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 학습 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bfad299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#프랑수아 숄레의 케라스의 seq2seq 구현 가이드 게시물인 A ten-minute introduction to sequence-to-sequence learning를 참고\n",
    "#도구 임포트\n",
    "\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "637c34ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#임베딩 층 구현\n",
    "from tensorflow.keras.layers import Input, Embedding, Masking\n",
    "\n",
    "# 인코더에서 사용할 임베딩 층 사용 예시(영어) 임베딩 벡터의 차원(word_vec_dim)을 16으로 설정 하이퍼 파라미터\n",
    "word_vec_dim = 8\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(eng_vocab_size, word_vec_dim )(encoder_inputs)\n",
    "# hidden size가 16인 인코더의 LSTM 셀 생성\n",
    "encoder_lstm = LSTM(units = 16, return_state=True)\n",
    "# hidden state와 cell state를 다음 time step으로 전달하기 위해서 별도 저장.\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a923119c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#디코더 설계\n",
    "# 입력 텐서 생성. word_vec_dim 16 동일\n",
    "\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb =  Embedding(fra_vocab_size, word_vec_dim )(encoder_inputs)\n",
    "# hidden size가 16인 인코더의 LSTM 셀 생성\n",
    "decoder_lstm = LSTM(units = 16, return_sequences = True, return_state=True)\n",
    "# decoder_outputs는 모든 time step의 hidden state\n",
    "decoder_outputs, _, _= decoder_lstm(dec_emb, initial_state = encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d751fe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#디코더의 출력층 설계\n",
    "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac4fb31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 8)      37704       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 8)      75736       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 16), (None,  1600        embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 16), ( 1600        embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 9467)   160939      lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 277,579\n",
      "Trainable params: 277,579\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#매 time step마다의 다중 클래스 분류 문제이므로 프랑스어 단어장으로부터 한 가지 문자만 선택하도록 합니다. Dense의 인자로 프랑스어 단어장의 크기를 기재하고, 활성화 함수로 소프트맥스 함수를 사용. 최종적으로 인코더와 디코더를 연결해서 하나의 모델로 만들어줍니다. Model의 Input과 Output의 정의를 유심히 살펴 주세요.\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff55fc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "                    validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "                    batch_size=16, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3b6d29",
   "metadata": {},
   "source": [
    "# 회고\n",
    "\n",
    "- 지난 ex 6에서는 직접 구두점들을 설정하고 다루는 코드를 작성하여 사용하였으나,\n",
    "- 이번에는 string 내장 함수를 사용하여 구두점 작업을 하였다.\n",
    "- sentence to sentence 의 번역기 코드를 작성해 볼 수 있었다.\n",
    "- 직접 임베딩 레이어를 추가하여 단어의 임베딩 깊이를 조절해 볼 수 있었다.\n",
    "- 영어를 인코딩 하여 어떤 x로 바꾸고 그 x를 디코딩하여 프랑스어로 바꾸는 알고리즘으로 러닝 모델을 작성해 보았다. \n",
    "- Total params를 최대한으로 줄여서 모델 학습을 시켜보려고 하였으나 클라우드 서버가 계속 다운이 되어 진행시키지 못했다.\n",
    "- 코드 자체의 문제인지 많은사람이 한꺼번에 코드를 돌려서 서버 리소스의 문제인지 확인을 하지 못하였다.\n",
    "- 지난번 데이터톤 때에도 느꼈지만 장비(GPU TPU등 연산장치 또는 머신러닝을 구현하는데 필요한 부수 장비)의 성능 및 발전도 머신러닝을 연구하고 발전시키는데 아주 중요한 부분임을 새삼 깨달았다\n",
    "- colab또는 좋은 머신러닝구현 환경을 사용하도록 준비를 해야겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a081d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
